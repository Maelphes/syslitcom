@Article{Castaneda2020,
  author   = {Castaneda, C. A. and Castillo, M. and Rojas-Vilca, J. L. and Fuentes, H. and Gomez, H. L.},
  journal  = {Rev Peru Med Exp Salud Publica},
  title    = {{COVID-19 in cancer patients: a systematic review}},
  year     = {2020},
  issn     = {1726-4634},
  number   = {4},
  pages    = {611--619},
  volume   = {37},
  abstract = {OBJECTIVE: Development of severe disease and death from COVID-19 is more 
frequent in patients with comorbidities. Some studies report an increased 
frequency of severe COVID-19 in cancer patients. This review aims to describe 
the risk of infection and developing severe COVID-19 in cancer patients.
MATERIALS AND METHODS: A systematic review was carried out through an exhaustive 
search of literature in PubMed and Scopus until May 2020. A secondary search was 
performed to include more studies.
RESULTS: The initial search identified 2,192 records, which included 17 
publications with at least 10 infected cancer patients. Also, 5 articles were 
added from the additional search of the references cited by those 17 
publications. Ten publications were from Chinese authors. Data analysis showed 
that COVID-19 infection is more frequent in cancer patients, and frequent 
therapeutic visits to the healthcare facility may be the cause. The presence of 
neoplasia predisposed patients to develop severe disease. Advanced age, 
associated comorbidities, advanced malignancy, and the presence of serum 
inflammatory markers increased the risk of developing severe disease. Initial 
studies indicate that the use of systemic treatment may also be a predisposing 
factor.
CONCLUSIONS: The risk of becoming infected by COVID-19 and developing severe 
disease is higher in the oncological population.},
  doi      = {10.17843/rpmesp.2020.374.5976},
  file     = {:Castaneda2020 - COVID 19 in Cancer Patients_ a Systematic Review.pdf:PDF},
  type     = {Journal Article},
  url      = {https://www.ncbi.nlm.nih.gov/pubmed/33566899},
}


@Misc{Rethlefsen2020,
  author       = {Rethlefsen, Melissa L. and Kirtley, Shona and Waffenschmidt, Siw and Ayala, Ana Patricia and Moher, David and Page, Matthew J. and Koffel, Jonathan B. and the PRISMA-S Group},
  howpublished = {Online},
  month        = feb,
  note         = {Last updated February 27, 2020},
  title        = {{PRISMA-S Checklist}},
  year         = {2020},
  file         = {:Rethlefsen2020 - PRISMA S Checklist.pdf:PDF},
}

@Book{JBIManual2020,
  editor    = {Aromataris, E. and Munn, Z.},
  publisher = {JBI},
  title     = {{JBI Manual for Evidence Synthesis}},
  year      = {2020},
  isbn      = {978-0-6488488-0-6},
  doi       = {10.46658/JBIMES-20-01},
  eprint    = {https://synthesismanual.jbi.global},
  file      = {:JBIManual2020 - JBI Manual for Evidence Synthesis.pdf:PDF},
  type      = {Book},
  url       = {https://synthesismanual.jbi.global},
}

@Article{Grant2009,
  author  = {Grant, M. J. and Booth, A.},
  journal = {Health Info Libr J},
  title   = {A typology of reviews: an analysis of 14 review types and associated methodologies},
  year    = {2009},
  issn    = {1471-1834},
  number  = {2},
  pages   = {91--108},
  volume  = {26},
  doi     = {10.1111/j.1471-1842.2009.00848.x},
  file    = {:Grant2009 - A Typology of Reviews_ an Analysis of 14 Review Types and Associated Methodologies.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/19490148},
}

@Article{Hutton2015,
  author  = {Hutton, B. and Salanti, G. and Caldwell, D. M. and Chaimani, A. and Schmid, C. H. and Cameron, C. and Ioannidis, J. P. and Straus, S. and Thorlund, K. and Jansen, J. P. and Mulrow, C. and Catala-Lopez, F. and Gotzsche, P. C. and Dickersin, K. and Boutron, I. and Altman, D. G. and Moher, D.},
  journal = {Ann Intern Med},
  title   = {{The PRISMA extension statement for reporting of systematic reviews incorporating network meta-analyses of health care interventions: checklist and explanations}},
  year    = {2015},
  issn    = {0003-4819},
  number  = {11},
  pages   = {777--84},
  volume  = {162},
  doi     = {10.7326/M14-2385},
  file    = {:Hutton2015 - The PRISMA Extension Statement for Reporting of Systematic Reviews Incorporating Network Meta Analyses of Health Care Interventions_ Checklist and Explanations.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/26030634},
}

@Article{McInnes2018,
  author  = {McInnes, Matthew D. F. and Moher, David and Thombs, Brett D. and McGrath, Trevor A. and Bossuyt, Patrick M. and the Prisma-D. T. A. Group},
  journal = {JAMA},
  title   = {{Preferred Reporting Items for a Systematic Review and Meta-analysis of Diagnostic Test Accuracy Studies: The PRISMA-DTA Statement}},
  year    = {2018},
  issn    = {1538-3598 (Electronic)
0098-7484 (Linking)},
  number  = {4},
  pages   = {388--396},
  volume  = {319},
  doi     = {10.1001/jama.2017.19163},
  file    = {:McInnes2018 - Preferred Reporting Items for a Systematic Review and Meta Analysis of Diagnostic Test Accuracy Studies_ the PRISMA DTA Statement.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/29362800},
}

@Article{Munn2018,
  author  = {Munn, Z. and Peters, M. D. J. and Stern, C. and Tufanaru, C. and McArthur, A. and Aromataris, E.},
  journal = {BMC Med Res Methodol},
  title   = {Systematic review or scoping review? Guidance for authors when choosing between a systematic or scoping review approach},
  year    = {2018},
  issn    = {1471-2288},
  number  = {1},
  pages   = {143},
  volume  = {18},
  doi     = {10.1186/s12874-018-0611-x},
  file    = {:Munn2018 - Systematic Review or Scoping Review_ Guidance for Authors When Choosing between a Systematic or Scoping Review Approach.pdf:PDF},
  type    = {Journal Article},
  url     = {https://pubmed.ncbi.nlm.nih.gov/30453902/},
}

@Article{Munn2018a,
  author  = {Munn, Z. and Stern, C. and Aromataris, E. and Lockwood, C. and Jordan, Z.},
  journal = {BMC Med Res Methodol},
  title   = {{What kind of systematic review should I conduct? A proposed typology and guidance for systematic reviewers in the medical and health sciences}},
  year    = {2018},
  issn    = {1471-2288},
  number  = {1},
  pages   = {5},
  volume  = {18},
  doi     = {10.1186/s12874-017-0468-4},
  file    = {:Munn2018a - What Kind of Systematic Review Should I Conduct_ a Proposed Typology and Guidance for Systematic Reviewers in the Medical and Health Sciences.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/29316881},
}

@Article{Page2021,
  author   = {Page, M. J. and McKenzie, J. E. and Bossuyt, P. M. and Boutron, I. and Hoffmann, T. C. and Mulrow, C. D. and Shamseer, L. and Tetzlaff, J. M. and Akl, E. A. and Brennan, S. E. and Chou, R. and Glanville, J. and Grimshaw, J. M. and Hrobjartsson, A. and Lalu, M. M. and Li, T. and Loder, E. W. and Mayo-Wilson, E. and McDonald, S. and McGuinness, L. A. and Stewart, L. A. and Thomas, J. and Tricco, A. C. and Welch, V. A. and Whiting, P. and Moher, D.},
  journal  = {PLoS Med},
  title    = {{The PRISMA 2020 statement: An updated guideline for reporting systematic reviews}},
  year     = {2021},
  issn     = {1549-1676 (Electronic)
1549-1277 (Linking)},
  number   = {3},
  pages    = {e1003583},
  volume   = {18},
  doi      = {10.1371/journal.pmed.1003583},
  file     = {:Page2021 - The PRISMA 2020 Statement_ an Updated Guideline for Reporting Systematic Reviews.pdf:PDF},
  fjournal = {PLoS medicine},
  type     = {Journal Article},
  url      = {https://www.ncbi.nlm.nih.gov/pubmed/33780438},
}

@Article{Pearson2015,
  author  = {Pearson, A. and White, H. and Bath-Hextall, F. and Salmond, S. and Apostolo, J. and Kirkpatrick, P.},
  journal = {Int J Evid Based Healthc},
  title   = {A mixed-methods approach to systematic reviews},
  year    = {2015},
  issn    = {1744-1609 (Electronic)
1744-1595 (Linking)},
  number  = {3},
  pages   = {121--31},
  volume  = {13},
  doi     = {10.1097/XEB.0000000000000052},
  file    = {:Pearson2015 - A Mixed Methods Approach to Systematic Reviews.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/26196082},
}

@Article{Sutton2019,
  author  = {Sutton, A. and Clowes, M. and Preston, L. and Booth, A.},
  journal = {Health Info Libr J},
  title   = {Meeting the review family: exploring review types and associated information retrieval requirements},
  year    = {2019},
  issn    = {1471-1834},
  number  = {3},
  pages   = {202--222},
  volume  = {36},
  doi     = {10.1111/hir.12276},
  file    = {:Sutton2019 - Meeting the Review Family_ Exploring Review Types and Associated Information Retrieval Requirements.pdf:PDF},
  type    = {Journal Article},
  url     = {https://pubmed.ncbi.nlm.nih.gov/31541534/},
}

@Article{Tricco2018,
  author  = {Tricco, A. C. and Lillie, E. and Zarin, W. and O'Brien, K. K. and Colquhoun, H. and Levac, D. and Moher, D. and Peters, M. D. J. and Horsley, T. and Weeks, L. and Hempel, S. and Akl, E. A. and Chang, C. and McGowan, J. and Stewart, L. and Hartling, L. and Aldcroft, A. and Wilson, M. G. and Garritty, C. and Lewin, S. and Godfrey, C. M. and Macdonald, M. T. and Langlois, E. V. and Soares-Weiser, K. and Moriarty, J. and Clifford, T. and Tuncalp, O. and Straus, S. E.},
  journal = {Ann Intern Med},
  title   = {{PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation}},
  year    = {2018},
  number  = {7},
  pages   = {467--473},
  volume  = {169},
  doi     = {10.7326/M18-0850},
  file    = {:Tricco2018 - PRISMA Extension for Scoping Reviews (PRISMA ScR)_ Checklist and Explanation.pdf:PDF},
  type    = {Journal Article},
  url     = {https://www.ncbi.nlm.nih.gov/pubmed/30178033},
}

@Article{Elm2019,
  author  = {von Elm, E. and Schreiber, G. and Haupt, C. C.},
  journal = {Z Evid Fortbild Qual Gesundhwes},
  title   = {{Methodische Anleitung für Scoping Reviews (JBI-Methodologie)}},
  year    = {2019},
  pages   = {1--7},
  volume  = {143},
  doi     = {10.1016/j.zefq.2019.05.004},
  file    = {:Elm2019 - Methodische Anleitung Für Scoping Reviews.pdf:PDF},
  type    = {Journal Article},
  url     = {https://pubmed.ncbi.nlm.nih.gov/31296451/},
}

@Article{Rethlefsen2021,
  author   = {Rethlefsen, Melissa L. and Kirtley, Shona and Waffenschmidt, Siw and Ayala, Ana Patricia and Moher, David and Page, Matthew J. and Koffel, Jonathan B. and Blunt, Heather and Brigham, Tara and Chang, Steven and Clark, Justin and Conway, Aislinn and Couban, Rachel and de Kock, Shelley and Farrah, Kelly and Fehrmann, Paul and Foster, Margaret and Fowler, Susan A. and Glanville, Julie and Harris, Elizabeth and Hoffecker, Lilian and Isojarvi, Jaana and Kaunelis, David and Ket, Hans and Levay, Paul and Lyon, Jennifer and McGowan, Jessie and Murad, M. Hassan and Nicholson, Joey and Pannabecker, Virginia and Paynter, Robin and Pinotti, Rachel and Ross-White, Amanda and Sampson, Margaret and Shields, Tracy and Stevens, Adrienne and Sutton, Anthea and Weinfurter, Elizabeth and Wright, Kath and Young, Sarah and the PRISMA-S Group},
  journal  = {Syst Rev},
  title    = {{PRISMA-S: an extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews}},
  year     = {2021},
  issn     = {2046-4053},
  number   = {1},
  pages    = {39},
  volume   = {10},
  abstract = {Literature searches underlie the foundations of systematic reviews and related review types. Yet, the literature searching component of systematic reviews and related review types is often poorly reported. Guidance for literature search reporting has been diverse, and, in many cases, does not offer enough detail to authors who need more specific information about reporting search methods and information sources in a clear, reproducible way. This document presents the PRISMA-S (Preferred Reporting Items for Systematic reviews and Meta-Analyses literature search extension) checklist, and explanation and elaboration.},
  doi      = {10.1186/s13643-020-01542-z},
  file     = {:Rethlefsen2021 - PRISMA S_ an Extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews.pdf:PDF},
  refid    = {Rethlefsen2021},
}

@Article{Page2021a,
  author       = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
  journal      = {BMJ},
  title        = {{The PRISMA 2020 statement: an updated guideline for reporting systematic reviews}},
  year         = {2021},
  volume       = {372},
  doi          = {10.1136/bmj.n71},
  elocation-id = {n71},
  file         = {:Page2021a - The PRISMA 2020 Statement_ an Updated Guideline for Reporting Systematic Reviews.pdf:PDF},
  publisher    = {BMJ Publishing Group Ltd},
  url          = {https://www.bmj.com/content/372/bmj.n71},
}

@Article{Harrison2020,
  author   = {Harrison, Hannah and Griffin, Simon J. and Kuhn, Isla and Usher-Smith, Juliet A.},
  journal  = {BMC Med Res Methodol},
  title    = {Software tools to support title and abstract screening for systematic reviews in healthcare: an evaluation},
  year     = {2020},
  issn     = {1471-2288},
  number   = {1},
  pages    = {7},
  volume   = {20},
  abstract = {Systematic reviews are vital to the pursuit of evidence-based medicine within healthcare. Screening titles and abstracts (T&Ab) for inclusion in a systematic review is an intensive, and often collaborative, step. The use of appropriate tools is therefore important. In this study, we identified and evaluated the usability of software tools that support T&Ab screening for systematic reviews within healthcare research.},
  doi      = {10.1186/s12874-020-0897-3},
  file     = {:Harrison2020 - Software Tools to Support Title and Abstract Screening for Systematic Reviews in Healthcare_ an Evaluation.pdf:PDF},
  refid    = {Harrison2020},
}

@Article{McKeown2021,
  author   = {McKeown, Sandra and Mir, Zuhaib M.},
  journal  = {Syst Rev},
  title    = {Considerations for conducting systematic reviews: evaluating the performance of different methods for de-duplicating references},
  year     = {2021},
  issn     = {2046-4053},
  number   = {1},
  pages    = {38},
  volume   = {10},
  abstract = {Systematic reviews involve searching multiple bibliographic databases to identify eligible studies. As this type of evidence synthesis is increasingly pursued, the use of various electronic platforms can help researchers improve the efficiency and quality of their research. We examined the accuracy and efficiency of commonly used electronic methods for flagging and removing duplicate references during this process.},
  doi      = {10.1186/s13643-021-01583-y},
  file     = {:McKeown2021 - Considerations for Conducting Systematic Reviews_ Evaluating the Performance of Different Methods for De Duplicating References.pdf:PDF},
  refid    = {McKeown2021},
}

@Article{jmla183,
  author   = {Wichor Bramer and Paul Bain},
  journal  = {J Med Libr Assoc},
  title    = {{Updating search strategies for systematic reviews using EndNote}},
  year     = {2017},
  issn     = {1558-9439},
  number   = {3},
  pages    = {285--289},
  volume   = {105},
  abstract = {A new method is described to update search strategies in multiple databases without the use of date limits. By deduplication of the most recent EndNote library with the EndNote library created at the time of the earlier search only recently added references or older references now retrieved by a changed search strategy remain.},
  doi      = {10.5195/jmla.2017.183},
  file     = {:jmla183 - Updating Search Strategies for Systematic Reviews Using EndNote.pdf:PDF},
  keywords = {Information Storage and Retrieval; Review Literature as Topic; Time Factors; Databases, Bibliographic},
  url      = {http://jmla.mlanet.org/ojs/jmla/article/view/183},
}

@Article{Bramer2016,
  author   = {Wichor Bramer and Dean Giustini and Gerdien de Jonge and Leslie Holland and Tanja Bekhuis},
  journal  = {J Med Libr Assoc},
  title    = {{De-duplication of database search results for systematic reviews in EndNote}},
  year     = {2016},
  issn     = {1558-9439},
  number   = {3},
  pages    = {240--243},
  volume   = {104},
  abstract = {When conducting exhaustive searches for systematic reviews, information professionals search multiple databases with overlapping content. They typically remove duplicate records to reduce the reviewers’ workload associated with screening titles and abstracts; sometimes the reviewers remove the duplicates.This article describes a de-duplication method.},
  doi      = {10.5195/jmla.2016.24},
  file     = {:Bramer2016 - De Duplication of Database Search Results for Systematic Reviews in EndNote.pdf:PDF},
  url      = {http://jmla.pitt.edu/ojs/jmla/article/view/24},
}

@Article{Golder2006,
  author   = {Golder, Su and McIntosh, Heather M. and Loke, Yoon},
  journal  = {BMC Med Res Methodol},
  title    = {Identifying systematic reviews of the adverse effects of health care interventions},
  year     = {2006},
  issn     = {1471-2288},
  number   = {1},
  pages    = {22},
  volume   = {6},
  abstract = {In order to carry out a methodological research survey of systematic reviews of adverse effects we needed to retrieve a sample of systematic reviews in which the primary outcome is an adverse effect or effects.},
  doi      = {10.1186/1471-2288-6-22},
  file     = {:Golder2006 - Identifying Systematic Reviews of the Adverse Effects of Health Care Interventions.pdf:PDF},
  refid    = {Golder2006},
}

@Article{Farrah2016,
  author    = {Farrah, Kelly and Mierzwinski-Urban, Monika and Cimon, Karen},
  journal   = {J Med Libr Assoc},
  title     = {Effectiveness of adverse effects search filters: drugs versus medical devices},
  year      = {2016},
  issn      = {1536-5050},
  month     = jul,
  number    = {27366123},
  pages     = {221--225},
  volume    = {104},
  abstract  = {OBJECTIVE: The study tested the performance of adverse effects search filters when searching for safety information on medical devices, procedures, and diagnostic tests in MEDLINE and Embase. METHODS: The sensitivity of 3 filters was determined using a sample of 631 references from 131 rapid reviews related to the safety of health technologies. The references were divided into 2 sets by type of intervention: drugs and nondrug health technologies. Keyword and indexing analysis were performed on references from the nondrug testing set that 1 or more of the filters did not retrieve. RESULTS: For all 3 filters, sensitivity was lower for nondrug health technologies (ranging from 53%-87%) than for drugs (88%-93%) in both databases. When tested on the nondrug health technologies set, sensitivity was lower in Embase (ranging from 53%-81%) than in MEDLINE (67%-87%) for all filters. Of the nondrug records that 1 or more of the filters missed, 39% of the missed MEDLINE records and 18% of the missed Embase records did not contain any indexing terms related to adverse events. Analyzing the titles and abstracts of nondrug records that were missed by any 1 filter, the most commonly used keywords related to adverse effects were: risk, complications, mortality, contamination, hemorrhage, and failure. CONCLUSIONS: In this study, adverse effects filters were less effective at finding information about the safety of medical devices, procedures, and tests compared to information about the safety of drugs.},
  comment   = {27366123[pmid]
PMC4915640[pmcid]},
  database  = {PubMed},
  doi       = {10.3163/1536-5050.104.3.007},
  file      = {:Farrah2016 - Effectiveness of Adverse Effects Search Filters_ Drugs Versus Medical Devices.pdf:PDF;APPENDIX B\: Selection of reports and included references:15-9454-1-SP.pdf:PDF;APPENDIX A\: Tested search filters:15-9453-1-SP.pdf:PDF},
  keywords  = {Bibliographic Databases, Controlled Vocabulary, Equipment and Supplies, Information Storage and Retrieval, Sensitivity and Specificity, *Drug-Related Side Effects and Adverse Reactions, Equipment and Supplies/*adverse effects, Humans, Information Storage and Retrieval/*methods, MEDLINE, Medical Subject Headings},
  language  = {eng},
  publisher = {Medical Library Association},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4915640/},
}

@Article{Lee2012,
  author   = {Lee, Edwin and Dobbins, Maureen and DeCorby, Kara and McRae, Lyndsey and Tirilis, Daiva and Husson, Heather},
  journal  = {BMC Med Res Methodol},
  title    = {An optimal search filter for retrieving systematic reviews and meta-analyses},
  year     = {2012},
  issn     = {1471-2288},
  number   = {1},
  pages    = {51},
  volume   = {12},
  abstract = {Health-evidence.ca is an online registry of systematic reviews evaluating the effectiveness of public health interventions. Extensive searching of bibliographic databases is required to keep the registry up to date. However, search filters have been developed to assist in searching the extensive amount of published literature indexed. Search filters can be designed to find literature related to a certain subject (i.e. content-specific filter) or particular study designs (i.e. methodological filter). The objective of this paper is to describe the development and validation of the health-evidence.ca Systematic Review search filter and to compare its performance to other available systematic review filters.},
  doi      = {10.1186/1471-2288-12-51},
  file     = {:Lee2012 - An Optimal Search Filter for Retrieving Systematic Reviews and Meta Analyses.pdf:PDF},
  refid    = {Lee2012},
}

@Misc{Bayer2021,
  author = {Bayer, O. and Cascant Ortolano, L. and Hoffmann, D. and Schweizer, S.},
  month  = apr,
  note   = {Version 2.0 beta [Internet]},
  title  = {{Praxisleitfaden Systematische Literaturrecherche der Universitätsmedizin Mainz}},
  year   = {2021},
  file   = {:Bayer2021 - Praxisleitfaden Systematische Literaturrecherche Der Universitätsmedizin Mainz.pdf:PDF},
  url    = {https://seafile.rlp.net/d/b87dc2b6b57a486a874d/files/?p=/Archiv alle Versionen /Praxisleitfaden-Systematische-Literaturrecherche-Version-2-0-beta.pdf},
}

@Article{Golder2006a,
  author             = {Golder, Su and McIntosh, Heather M. and Duffy, Steve and Glanville, Julie},
  journal            = {Health Info Libr J},
  title              = {{Developing efficient search strategies to identify reports of adverse effects in MEDLINE and EMBASE.}},
  year               = {2006},
  month              = mar,
  pages              = {3--12},
  volume             = {23},
  abstract           = {OBJECTIVE: This study aimed to assess the performance, in terms of sensitivity and precision, of different approaches to searching MEDLINE and EMBASE to identify studies of adverse effects. METHODS: Five approaches to searching for adverse effects evidence were identified: approach 1, using specified adverse effects; approach 2, using subheadings/qualifiers; approach 3, using text words; approach 4, using indexing terms; approach 5, searching for specific study designs. The sensitivity and precision of these five approaches, and combinations of these approaches, were compared in a case study using a systematic review of the adverse effects of seven anti-epileptic drugs. RESULTS: The most sensitive search strategy in MEDLINE (97.0%) required a combination of terms for specified adverse effects, floating subheadings, and text words for 'adverse effects'. In EMBASE, a combination of terms for specified adverse effects and text words for 'adverse effects' provided the most sensitive search strategy (98.6%). Both these search strategies yielded low precision (2.8%). CONCLUSIONS: A highly sensitive search in either database requires a combination of approaches, and has low precision. This suggests that better reporting and indexing of adverse effects is required and that an effective generic search filter may not yet be feasible.},
  address            = {England},
  article-doi        = {10.1111/j.1471-1842.2006.00634.x},
  article-pii        = {HIR634},
  completed          = {20060503},
  corporate          = {Centre for Reviews and Dissemination and UK Cochrane Centre Search Filters Design Group},
  doi                = {10.1111/j.1471-1842.2006.00634.x},
  file               = {:Golder2006a - Developing Efficient Search Strategies to Identify Reports of Adverse Effects in MEDLINE and EMBASE..pdf:PDF},
  history            = {2006/02/10 09:00 [entrez]},
  issue              = {1},
  keywords           = {Abstracting and Indexing/standards, Anticonvulsants/*adverse effects, Databases, Bibliographic/*statistics & numerical data, *Drug Prescriptions, Efficiency, Humans, Information Storage and Retrieval/*methods, MEDLINE/statistics & numerical data, Medical Subject Headings, Randomized Controlled Trials as Topic, Research Design, Sensitivity and Specificity, Subject Headings},
  language           = {eng},
  linking-issn       = {1471-1834},
  nlm-unique-id      = {100970070},
  owner              = {NLM},
  print-issn         = {1471-1834},
  publication-status = {ppublish},
  registry-number    = {0 (Anticonvulsants)},
  revised            = {20191210},
  source             = {Health Info Libr J. 2006 Mar;23(1):3-12. doi: 10.1111/j.1471-1842.2006.00634.x.},
  status             = {MEDLINE},
  subset             = {H},
  title-abbreviation = {Health Info Libr J},
}

@Article{McGowan2016,
  author   = {Jessie McGowan and Margaret Sampson and Douglas M. Salzwedel and Elise Cogo and Vicki Foerster and Carol Lefebvre},
  journal  = {J Clin Epidemiol},
  title    = {{PRESS Peer Review of Electronic Search Strategies: 2015 Guideline Statement}},
  year     = {2016},
  issn     = {0895-4356},
  pages    = {40--46},
  volume   = {75},
  abstract = {Objective
To develop an evidence-based guideline for Peer Review of Electronic Search Strategies (PRESS) for systematic reviews (SRs), health technology assessments, and other evidence syntheses.
Study Design and Setting
An SR, Web-based survey of experts, and consensus development forum were undertaken to identify checklists that evaluated or validated electronic literature search strategies and to determine which of their elements related to search quality or errors.
Results
Systematic review: No new search elements were identified for addition to the existing (2008–2010) PRESS 2015 Evidence-Based Checklist, and there was no evidence refuting any of its elements. Results suggested that structured PRESS could identify search errors and improve the selection of search terms. Web-based survey of experts: Most respondents felt that peer review should be undertaken after the MEDLINE search had been prepared but before it had been translated to other databases. Consensus development forum: Of the seven original PRESS elements, six were retained: translation of the research question; Boolean and proximity operators; subject headings; text word search; spelling, syntax and line numbers; and limits and filters. The seventh (skilled translation of the search strategy to additional databases) was removed, as there was consensus that this should be left to the discretion of searchers. An updated PRESS 2015 Guideline Statement was developed, which includes the following four documents: PRESS 2015 Evidence-Based Checklist, PRESS 2015 Recommendations for Librarian Practice, PRESS 2015 Implementation Strategies, and PRESS 2015 Guideline Assessment Form.
Conclusion
The PRESS 2015 Guideline Statement should help to guide and improve the peer review of electronic literature search strategies.},
  doi      = {10.1016/j.jclinepi.2016.01.021},
  file     = {:McGowan2016 - PRESS Peer Review of Electronic Search Strategies_ 2015 Guideline Statement.pdf:PDF;:McGowan2016 - PRESS Peer Review of Electronic Search Strategies_ 2015 Guideline Statement.docx:Word 2007+},
  keywords = {Peer review, Literature search, Information retrieval, Systematic review, Evidence synthesis, Guideline},
  url      = {https://www.sciencedirect.com/science/article/pii/S0895435616000585},
}

@Article{Glanville2019,
  author   = {Glanville, Julie and Foxlee, Ruth and Wisniewski, Susi and Noel-Storr, Anna and Edwards, Mary and Dooley, Gordon},
  journal  = {Health Info Libr J},
  title    = {{Translating the Cochrane EMBASE RCT filter from the Ovid interface to Embase.com: a case study}},
  year     = {2019},
  number   = {3},
  pages    = {264--277},
  volume   = {36},
  abstract = {Abstract Background Information specialists frequently translate search filters from one interface to another. Publications advise that translation can be complex and should be undertaken carefully. Objectives To investigate the issues arising when translating the Cochrane Embase RCT search filter from one interface (Ovid) to another (Embase.com). Methods We drafted a translation of the Cochrane Ovid RCT filter to run in Embase.com. We compared the line-by-line results of the Ovid filter with the results of the translation. We revised the filter. We identified differences between database versions including records with different publication years and subject headings. Some records were in Embase in one interface but not in the other. We encountered expected interface differences relating to proximity operators. We also encountered unexpected interface issues around truncation and the use of the original title or original abstract field. Discussion Filter conversion is challenging and time consuming revealing unexpected differences in interfaces and databases. Careful planning can pre-empt some issues, but others may only emerge during testing. We identified interface anomalies that have led database publishers to review aspects of the way their interfaces work. Conclusions Translators should be vigilant for known and unknown differences in both interfaces and database versions.},
  doi      = {10.1111/hir.12269},
  file     = {:Glanville2019 - Translating the Cochrane EMBASE RCT Filter from the Ovid Interface to Embase.com_ a Case Study.pdf:PDF},
  keywords = {bibliographic databases, database searching, EMBASE, information retrieval, information specialists, research methodology, search strategies},
}

@Article{Isojarvi2018,
  author   = {Isojarvi, Jaana and Wood, Hannah and Lefebvre, Carol and Glanville, Julie},
  journal  = {Res Syn Meth},
  title    = {Challenges of identifying unpublished data from clinical trials: Getting the best out of clinical trials registers and other novel sources},
  year     = {2018},
  number   = {4},
  pages    = {561--578},
  volume   = {9},
  abstract = {Clinical trial data are essential for assessments of the effectiveness of health care interventions. Information about ongoing or completed, but not yet formally published, trials has been more difficult to identify until the development of clinical trials registers and portals. This paper summarises research evidence on identifying sources of trial data, how and when to search those sources, and which future developments may enhance access to and retrieval of unpublished trial evidence. We conducted a literature search for relevant studies and provide a narrative review of the evidence from these studies. Clinical trial data can be found in resources including clinical trials registers, regulatory agency sources, health technology assessment websites and manufacturers' websites, and submissions for regulatory approval. The challenges of searching these resources are described. Trials registers are relatively unsophisticated in terms of their search interfaces, and searchers need to adapt to each individual register. There is overlap across registers, but little research on the degree and nature of overlap and how best to search. Despite these challenges, trials registers and other resources can be rich sources of additional unique trial data, which may not be available from journal reports. New initiatives, such as OpenTrials, aim to consolidate and link all structured data and documentation related to clinical trials. No single resource gives access to all trials, and multiple registers should be searched as sensitively as possible. Searching is challenging and should be adequately resourced. Information specialists should monitor new developments which may reduce the challenges over the coming years.},
  doi      = {10.1002/jrsm.1294},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1294},
  file     = {:Isojarvi2018 - Challenges of Identifying Unpublished Data from Clinical Trials_ Getting the Best Out of Clinical Trials Registers and Other Novel Sources.pdf:PDF},
  keywords = {information retrieval, clinical trials, trials registers, unpublished data},
}

@Article{Anderson1983,
  author    = {Jonathan Anderson},
  journal   = {J Reading},
  title     = {{Lix and Rix: Variations on a Little-known Readability Index}},
  year      = {1983},
  issn      = {0022-4103},
  number    = {6},
  pages     = {490--496},
  volume    = {26},
  eprint    = {http://www.jstor.org/stable/40031755},
  file      = {:Anderson1983 - Lix and Rix_ Variations on a Little Known Readability Index.pdf:PDF},
  publisher = {[Wiley, International Reading Association]},
  url       = {http://www.jstor.org/stable/40031755},
}

@Article{Selva2017,
  author   = {Selva, Anna and Solà, Ivan and Zhang, Yuan and Pardo-Hernandez, Hector and Haynes, R. Brian and Martínez García, Laura and Navarro, Tamara and Schünemann, Holger and Alonso-Coello, Pablo},
  journal  = {Health Qual Life Outcomes},
  title    = {Development and use of a content search strategy for retrieving studies on patients' views and preferences},
  year     = {2017},
  issn     = {1477-7525},
  number   = {1},
  pages    = {126},
  volume   = {15},
  abstract = {Identifying scientific literature addressing patients’ views and preferences is complex due to the wide range of studies that can be informative and the poor indexing of this evidence. Given the lack of guidance we developed a search strategy to retrieve this type of evidence.},
  doi      = {10.1186/s12955-017-0698-5},
  file     = {:Selva2017 - Development and Use of a Content Search Strategy for Retrieving Studies on Patients' Views and Preferences.pdf:PDF;:Selva2017 - Development and Use of a Content Search Strategy for Retrieving Studies on Patients' Views and Preferences.docx:Word 2007+},
  refid    = {Selva2017},
}

@Article{Bramer2017,
  journal   = {J Med Libr Assoc},
  title     = {Correction},
  year      = {2017},
  issn      = {1536-5050},
  month     = jan,
  number    = {28096754},
  pages     = {111--111},
  volume    = {105},
  abstract  = {[This corrects the article on p. 242 in vol. 104.].},
  comment   = {28096754[pmid]
PMC5234466[pmcid]},
  database  = {PubMed},
  doi       = {10.5195/jmla.2017.128},
  file      = {:2017 - Correction.pdf:PDF},
  language  = {eng},
  publisher = {Medical Library Association},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5234466/},
}

@Article{Booth2010,
  author    = {Booth, Andrew},
  journal   = {Int J Technol Assess Health Care},
  title     = {How much searching is enough? Comprehensive versus optimal retrieval for technology assessments},
  year      = {2010},
  number    = {4},
  pages     = {431--435},
  volume    = {26},
  doi       = {10.1017/S0266462310000966},
  file      = {:Booth2010 - How Much Searching Is Enough_ Comprehensive Versus Optimal Retrieval for Technology Assessments.pdf:PDF},
  publisher = {Cambridge University Press},
}

@Article{Tanon2010,
  author    = {Tanon, Affaud Anaïs and Champagne, F. and Contandriopoulos, A.-P. and Pomey, M.-P. and Vadeboncoeur, A. and Nguyen, H.},
  journal   = {BMJ Quality \& Safety},
  title     = {{Patient safety and systematic reviews: finding papers indexed in MEDLINE, EMBASE and CINAHL}},
  year      = {2010},
  issn      = {1475-3898},
  number    = {5},
  pages     = {452--461},
  volume    = {19},
  abstract  = {Objective To develop search strategies for identifying papers on patient safety in MEDLINE, EMBASE and CINAHL.Methods Six journals were electronically searched for papers on patient safety published between 2000 and 2006. Identified papers were divided into two gold standards: one to build and the other to validate the search strategies. Candidate terms for strategy construction were identified using a word frequency analysis of titles, abstracts and keywords used to index the papers in the databases. Searches were run for each one of the selected terms independently in every database. Sensitivity, precision and specificity were calculated for each candidate term. Terms with sensitivity greater than 10\% were combined to form the final strategies. The search strategies developed were run against the validation gold standard to assess their performance. A final step in the validation process was to compare the performance of each strategy to those of other strategies found in the literature.Results We developed strategies for all three databases that were highly sensitive (range 95\%{\textendash}100\%), precise (range 40\%{\textendash}60\%) and balanced (the product of sensitivity and precision being in the range of 30\%{\textendash}40\%). The strategies were very specific and outperformed those found in the literature.Conclusion The strategies we developed can meet the needs of users aiming to maximise either sensitivity or precision, or seeking a reasonable compromise between sensitivity and precision, when searching for papers on patient safety in MEDLINE, EMBASE or CINAHL.},
  doi       = {10.1136/qshc.2008.031401},
  eprint    = {https://qualitysafety.bmj.com/content/19/5/452.full.pdf},
  file      = {:Tanon2010 - Patient Safety and Systematic Reviews_ Finding Papers Indexed in MEDLINE, EMBASE and CINAHL.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
  url       = {https://qualitysafety.bmj.com/content/19/5/452},
}

@Article{Hinde2015,
  author   = {Hinde, Sebastian and Spackman, Eldon},
  journal  = {PharmacoEconomics},
  title    = {{Bidirectional Citation Searching to Completion: An Exploration of Literature Searching Methods}},
  year     = {2015},
  issn     = {1179-2027},
  number   = {1},
  pages    = {5--11},
  volume   = {33},
  abstract = {Literature reviews underpin the majority of research projects in the health sciences, and yet relatively little analysis has been published as to the most appropriate method to identify relevant literature, outside of specialist information journals. The method of applying keyword search queries to bibliographic databases using Boolean logic dominates literature reviews due to its easy application to the major online databases. However, it is recognised increasingly as being problematic where the research question cannot be clearly defined or requires an element of exploration, due to its reliance on author’s use of titling and keywords and is unable to identify topics other than those defined in the search query. This paper discusses the relative merits of a systematic citation searching approach as both an alternative and a concurrent method to keyword searching. A method of citation searching, both forwards and backwards, which is iterated to form a closed loop solution, is discussed. An illustrative example is presented of both methods, applying them to the topic of the UK National Institute for Health and Care Excellence (NICE) cost-effectiveness threshold. The case study finds the citation searching approach dominates the traditional keyword searching approach, finding 76 papers of relevance, including all 15 found by the alternative approach. Conceptually, and in the example presented, it is demonstrated that the proposed method can represent a dominant strategy to the more traditional approach in some situations, highlighting that, wherever possible, it is preferential to employ multiple methods of searching. However, it is clear that a better understanding is required as to how we can most efficiently search the ever-growing sea of literature.},
  doi      = {10.1007/s40273-014-0205-3},
  file     = {:Hinde2015 - Bidirectional Citation Searching to Completion_ an Exploration of Literature Searching Methods.pdf:PDF},
  refid    = {Hinde2015},
}

@Article{Waffenschmidt2020,
  author    = {Waffenschmidt, Siw and Navarro-Ruan, Tamara and Hobson, Nick and Hausner, Elke and Sauerland, Stefan and Haynes, R. Brian},
  journal   = {Res Syn Meth},
  title     = {{Development and validation of study filters for identifying controlled non-randomized studies in PubMed and Ovid MEDLINE}},
  year      = {2020},
  issn      = {1759-2879},
  month     = sep,
  number    = {5},
  pages     = {617--626},
  volume    = {11},
  abstract  = {A retrospective analysis published by the German Institute for Quality and Efficiency in Health Care (IQWiG) in 2018 concluded that no filter for non-randomized studies (NRS) achieved sufficient sensitivity (≥92%), a precondition for comprehensive information retrieval. New NRS filters are therefore required, taking into account the challenges related to this study type. Our evaluation focused on the development of study filters for NRS with a control group (?controlled NRS?), as this study type allows the calculation of an effect size. In addition, we assumed that due to the more explicit search syntax, controlled NRS are easier to identify than non-controlled ones, potentially resulting in better performance measures of study filters for controlled NRS. Our aim was to develop study filters for identifying controlled NRS in PubMed and Ovid MEDLINE. We developed two new search filters that can assist clinicians and researchers in identifying controlled NRS in PubMed and Ovid MEDLINE. The reference set was based on 2110 publications in Medline extracted from 271 Cochrane reviews and on 4333 irrelevant references. The first filter maximizes sensitivity (92.42%; specificity 79.67%, precision 68.49%) and should be used when a comprehensive search is needed. The second filter maximizes specificity (92.06%; precision 82.98%, sensitivity 80.94%) and should be used when a more focused search is sufficient.},
  comment   = {https://doi.org/10.1002/jrsm.1425},
  doi       = {10.1002/jrsm.1425},
  file      = {:Waffenschmidt2020 - Development and Validation of Study Filters for Identifying Controlled Non Randomized Studies in PubMed and Ovid MEDLINE.pdf:PDF},
  keywords  = {bibliographic databases, information storage and retrieval, MEDLINE, Non-randomized controlled trials as topic, review literature as topic},
  publisher = {John Wiley & Sons, Ltd},
}

@Article{Haynes1994,
  author   = {Haynes, R. Brian and Wilczynski, Nancy and McKibbon, K. Ann and Walker, Cynthia J. and Sinclair, John C.},
  journal  = {J Am Med Inform Assoc},
  title    = {{Developing Optimal Search Strategies for Detecting Clinically Sound Studies in MEDLINE}},
  year     = {1994},
  issn     = {1067-5027},
  month    = nov,
  number   = {6},
  pages    = {447--458},
  volume   = {1},
  abstract = {Objective: To develop optimal MEDLINE search strategies for retrieving sound clinical studies of the etiology, prognosis, diagnosis, prevention, or treatment of disorders in adult general medicine.Design: Analytic survey of operating characteristics of search strategies developed by computerized combinations of terms selected to detect studies meeting basic methodologic criteria for direct clinical use in adult general medicine.Measures: The sensitivities, specificities, precision, and accuracy of 134,264 unique combinations of search terms were determined by comparison with a manual review of all articles (the “gold standard”) in ten internal medicine and general medicine journals for 1986 and 1991.Results: Less than half of the studies of the topics of interest met basic criteria for scientific merit for testing clinical applications. Combinations of search terms reached peak sensitivities of 82% for sound studies of etiology, 92% for prognosis, 92% for diagnosis, and 99% for therapy in 1991. Compared with the best single terms, multiple terms increased sensitivity for sound studies by over 30% (absolute increase), but with some loss of specificity when sensitivity was maximized. For 1986, combinations reached peak sensitivities of 72% for etiology, 95% for prognosis, 86% for diagnosis, and 98% for therapy. When search terms were combined to maximize specificity, over 93% specificity was achieved for all purpose categories in both years. Compared with individual terms, combined terms achieved near-perfect specificity that was maintained with modest increases insensitivity in all purpose categories except therapy. Increases in accuracy were achieved by combining terms for all purpose categories, with peak accuracies reaching over 90% for therapy in 1986 and 1991.Conclusions: The retrieval of studies of important clinical topics cited in MEDLINE can be substantially enhanced by selected combinations of indexing terms and textwords.},
  doi      = {10.1136/jamia.1994.95153434},
  file     = {:Haynes1994 - Developing Optimal Search Strategies for Detecting Clinically Sound Studies in MEDLINE.pdf:PDF},
}

@Article{Cooper2017,
  author   = {Cooper, Chris and Booth, Andrew and Britten, Nicky and Garside, Ruth},
  journal  = {Syst Rev},
  title    = {A comparison of results of empirical studies of supplementary search techniques and recommendations in review methodology handbooks: a methodological review},
  year     = {2017},
  issn     = {2046-4053},
  number   = {1},
  pages    = {234},
  volume   = {6},
  abstract = {The purpose and contribution of supplementary search methods in systematic reviews is increasingly acknowledged. Numerous studies have demonstrated their potential in identifying studies or study data that would have been missed by bibliographic database searching alone.},
  doi      = {10.1186/s13643-017-0625-1},
  file     = {:Cooper2017 - A Comparison of Results of Empirical Studies of Supplementary Search Techniques and Recommendations in Review Methodology.pdf:PDF},
  refid    = {Cooper2017},
}

@Article{Belter2016,
  author    = {Belter, Christopher W.},
  journal   = {J Assn Inf Sci Tec},
  title     = {Citation analysis as a literature search method for systematic reviews},
  year      = {2016},
  issn      = {2330-1635},
  month     = nov,
  number    = {11},
  pages     = {2766--2777},
  volume    = {67},
  abstract  = {Systematic reviews are essential for evaluating biomedical treatment options, but the growing size and complexity of the available biomedical literature combined with the rigor of the systematic review method mean that systematic reviews are extremely difficult and labor-intensive to perform. In this article, I propose a method of searching the literature by systematically mining the various types of citation relationships between articles. I then test the method by comparing its precision and recall to that of 14 published systematic reviews. The method successfully retrieved 74% of the studies included in these reviews and 90% of the studies it could reasonably be expected to retrieve. The method also retrieved fewer than half of the total number of publications retrieved by these reviews and can be performed in substantially less time. This suggests that the proposed method offers a promising complement to traditional text-based methods of literature identification and retrieval for systematic reviews.},
  comment   = {https://doi.org/10.1002/asi.23605},
  doi       = {10.1002/asi.23605},
  file      = {:Belter2016 - Citation Analysis As a Literature Search Method for Systematic Reviews.pdf:PDF},
  keywords  = {bibliometrics, information retrieval},
  publisher = {John Wiley & Sons, Ltd},
}

@Article{Hirt2020,
  author  = {Hirt, J. and Nordhausen, T. and Appenzeller-Herzog, C. and Ewald, H.},
  journal = {F1000Res},
  title   = {Using citation tracking for systematic literature searching - study protocol for a scoping review of methodological studies and an expert survey},
  year    = {2020},
  number  = {1386},
  volume  = {9},
  doi     = {10.12688/f1000research.27337.1},
  file    = {:Hirt2020 - Using Citation Tracking for Systematic Literature Searching Study Protocol for a Scoping Review of Methodological Studies and an Expert Survey.pdf:PDF},
}

@Article{Glanville2008,
  author    = {Glanville, Julie and Bayliss, Sue and Booth, Andrew and Dundar, Yenal and Fernandes, Hasina and Fleeman, Nigel David and Foster, Louise and Fraser, Cynthia and Fry-Smith, Anne and Golder, Su and Lefebvre, Carol and Miller, Caroline and Paisley, Suzy and Payne, Liz and Price, Alison and Welch, Karen},
  journal   = {J Med Libr Assoc},
  title     = {So many filters, so little time: the development of a search filter appraisal checklist},
  year      = {2008},
  issn      = {1536-5050},
  month     = oct,
  number    = {18974813},
  pages     = {356--361},
  volume    = {96},
  abstract  = {OBJECTIVES: The authors developed a tool to assess the quality of search filters designed to retrieve records for studies with specific research designs (e.g., diagnostic studies). METHODS: The UK InterTASC Information Specialists' Sub-Group (ISSG), a group of experienced health care information specialists, reviewed the literature to evaluate existing search filter appraisal tools and determined that existing tools were inadequate for their needs. The group held consensus meetings to develop a new filter appraisal tool consisting of a search filter appraisal checklist and a structured abstract. ISSG members tested the final checklist using three published search filters. RESULTS: The detailed ISSG Search Filter Appraisal Checklist captures relevance criteria and methods used to develop and test search filters. The checklist includes categorical and descriptive responses and is accompanied by a structured abstract that provides a summary of key quality features of a filter. DISCUSSION: The checklist is a comprehensive appraisal tool that can assist health sciences librarians and others in choosing search filters. The checklist reports filter design methods and search performance measures, such as sensitivity and precision. The checklist can also aid filter developers by indicating information on core methods that should be reported to help assess filter suitability. The generalizability of the checklist for non-methods filters remains to be explored.},
  comment   = {18974813[pmid]
PMC2568852[pmcid]},
  database  = {PubMed},
  doi       = {10.3163/1536-5050.96.4.011},
  file      = {:Glanville2008 - So Many Filters, so Little Time_ the Development of a Search Filter Appraisal Checklist.pdf:PDF;:1-s2.0-S089543562031146X-main.pdf:PDF},
  keywords  = {Abstracting and Indexing/*methods, *Bibliography of Medicine, Humans, Information Storage and Retrieval/*methods, Librarians, Periodicals as Topic, Sensitivity and Specificity, *Subject Headings, *Terminology as Topic, United Kingdom},
  language  = {eng},
  publisher = {Medical Library Association},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2568852/},
}

@Article{Nagendrababu2020,
  author    = {Nagendrababu, V. and Dilokthornsakul, P. and Jinatongthai, P. and Veettil, S. K. and Pulikkotil, S. J. and Duncan, H. F. and Dummer, P. M. H.},
  journal   = {Int Endod J},
  title     = {Glossary for systematic reviews and meta-analyses},
  year      = {2020},
  issn      = {0143-2885},
  month     = feb,
  number    = {2},
  pages     = {232--249},
  volume    = {53},
  abstract  = {Abstract A systematic review aims to answer a focussed research question through a structured review of the evidence, using a predefined methodology, which often includes a meta-analysis. A meta-analysis is a statistical method used to combine the effect estimates from the individual studies included in a systematic review. Systematic reviews and meta-analyses are positioned at the highest level in the hierarchy of clinical evidence. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement was introduced in 2009 to help authors improve the quality and reliability of systematic reviews and meta-analyses. Recently, the volume of systematic reviews and meta-analyses in the field of Endodontology has increased; however, the quality of the published manuscripts has been reported to be sub-optimal, which does not take account of the systematic reviews that were rejected because of more obvious deficiencies. The aim of this paper is to present a comprehensive glossary of terminology commonly used in systematic reviews and meta-analyses in an attempt to provide easily understood definitions and explanations to assist authors when reporting systematic reviews and meta-analyses and to allow those wishing to read them to become better informed.},
  comment   = {https://doi.org/10.1111/iej.13217},
  doi       = {10.1111/iej.13217},
  file      = {:Nagendrababu2020 - Glossary for Systematic Reviews and Meta Analyses.pdf:PDF},
  keywords  = {glossary, meta-analyses, systematic reviews},
  publisher = {John Wiley & Sons, Ltd},
}

@Article{Bramer2018,
  author    = {Bramer, Wichor M. and de Jonge, Gerdien B. and Rethlefsen, Melissa L. and Mast, Frans and Kleijnen, Jos},
  journal   = {J Med Libr Assoc},
  title     = {A systematic approach to searching: an efficient and complete method to develop literature searches},
  year      = {2018},
  month     = oct,
  number    = {4},
  pages     = {531--541},
  volume    = {106},
  abstract  = {Creating search strategies for systematic reviews, finding the best balance between sensitivity and specificity, and translating search strategies between databases is challenging. Several methods describe standards for systematic search strategies, but a consistent approach for creating an exhaustive search strategy has not yet been fully described in enough detail to be fully replicable. The authors have established a method that describes step by step the process of developing a systematic search strategy as needed in the systematic review. This method describes how single-line search strategies can be prepared in a text document by typing search syntax (such as field codes, parentheses, and Boolean operators) before copying and pasting search terms (keywords and free-text synonyms) that are found in the thesaurus. To help ensure term completeness, we developed a novel optimization technique that is mainly based on comparing the results retrieved by thesaurus terms with those retrieved by the free-text search words to identify potentially relevant candidate search terms. Macros in Microsoft Word have been developed to convert syntaxes between databases and interfaces almost automatically. This method helps information specialists in developing librarian-mediated searches for systematic reviews as well as medical and health care practitioners who are searching for evidence to answer clinical questions. The described method can be used to create complex and comprehensive search strategies for different databases and interfaces, such as those that are needed when searching for relevant references for systematic reviews, and will assist both information specialists and practitioners when they are searching the biomedical literature.},
  doi       = {10.5195/jmla.2018.283},
  file      = {:Bramer2018 - A Systematic Approach to Searching_ an Efficient and Complete Method to Develop Literature Searches.pdf:PDF;:283-3831-3-SP.pdf:PDF},
  keywords  = {Review Literature as Topic; Databases, Bibliographic; Information Storage and Retrieval; Vocabulary, Controlled},
  publisher = {University Library System, University of Pittsburgh},
  url       = {http://jmla.pitt.edu/ojs/jmla/article/view/283},
}

@Article{Methley2014,
  author   = {Methley, Abigail M. and Campbell, Stephen and Chew-Graham, Carolyn and McNally, Rosalind and Cheraghi-Sohi, Sudeh},
  journal  = {BMC Health Serv Res},
  title    = {{PICO, PICOS and SPIDER: a comparison study of specificity and sensitivity in three search tools for qualitative systematic reviews}},
  year     = {2014},
  issn     = {1472-6963},
  number   = {1},
  pages    = {579},
  volume   = {14},
  abstract = {Qualitative systematic reviews are increasing in popularity in evidence based health care. Difficulties have been reported in conducting literature searches of qualitative research using the PICO search tool. An alternative search tool, entitled SPIDER, was recently developed for more effective searching of qualitative research, but remained untested beyond its development team.},
  doi      = {10.1186/s12913-014-0579-0},
  file     = {:Methley2014 - PICO, PICOS and SPIDER_ a Comparison Study of Specificity and Sensitivity in Three Search Tools for Qualitative Systematic Reviews.pdf:PDF},
  refid    = {Methley2014},
}

@Article{Eriksen2018,
  author   = {Eriksen, Mette Brandt and Frandsen, Tove Faber},
  journal  = {J Med Libr Assoc},
  title    = {{The impact of patient, intervention, comparison, outcome (PICO) as a search strategy tool on literature search quality: a systematic review}},
  year     = {2018},
  month    = oct,
  number   = {4},
  pages    = {420--431},
  volume   = {106},
  abstract = {Objective:  This review aimed to determine if the use of the patient, intervention, comparison, outcome (PICO) model as a search strategy tool affects the quality of a literature search.   Methods:  A comprehensive literature search was conducted in PubMed, Embase, CINAHL, PsycINFO, Cochrane Library, Web of Science, Library and Information Science Abstracts (LISA), Scopus, and the National Library of Medicine (NLM) catalog up until January 9, 2017. Reference lists were scrutinized, and citation searches were performed on the included studies. The primary outcome was the quality of literature searches and the secondary outcome was time spent on the literature search when the PICO model was used as a search strategy tool, compared to the use of another conceptualizing tool or unguided searching.   Results:  A total of 2,163 records were identified, and after removal of duplicates and initial screening, 22 full-text articles were assessed. Of these, 19 studies were excluded and 3 studies were included, data were extracted, risk of bias was assessed, and a qualitative analysis was conducted. The included studies compared PICO to the PIC truncation or links to related articles in PubMed, PICOS, and sample, phenomenon of interest, design, evaluation, research type (SPIDER). One study compared PICO to unguided searching. Due to differences in intervention, no quantitative analysis was performed.   Conclusions:  Only few studies exist that assess the effect of the PICO model vis-a-vis other available models or even vis-a-vis the use of no model. Before implications for current practice can be drawn, well-designed studies are needed to evaluate the role of the tool used to devise a search strategy.    This article has been approved for the  Medical Library Association’s Independent Reading Program .},
  doi      = {10.5195/jmla.2018.345},
  file     = {:Eriksen2018 - The Impact of Patient, Intervention, Comparison, Outcome (PICO) As a Search Strategy Tool on Literature Search Quality_ a Systematic Review.pdf:PDF},
  keywords = {PICO Model; Search Strategy Tools; Literature Search; Evidence-Based Medicine; Systematic Reviews},
  url      = {http://jmla.pitt.edu/ojs/jmla/article/view/345/690},
}

@Proceedings{WHO1997,
  title        = {{Guidelines in Health Care Practice: report on the WHO Meeting, Schloss Velen, Borken, Germany, 26--28 January 1997}},
  year         = {1997},
  address      = {Scherfigsvej 8, DK-2100 Copenhagen Ø, Denmark},
  month        = jan,
  organization = {World Health Organization. Regional Office for Europe.},
  author       = {{World Health Organization. Regional Office for Europe.}},
  eprint       = {https://apps.who.int/iris/handle/10665/107628},
  file         = {:WHO1997 - GUIDELINES iN HEALTH CARE PRACTICE Report on a WHO Meeting.pdf:PDF},
  keywords     = {DELIVERY OF HEALTH CARE TRENDS, HEALTH PLANNING GUIDELINES, HEALTH CARE REFORM, EUROPE, NEW ZEALAND, UNITED STATES},
  url          = {https://www.euro.who.int/__data/assets/pdf_file/0011/118379/E53492.pdf},
}

@Manual{Nordhausen2020,
  title        = {{RefHunter. Manual zur Literaturrecherche in Fachdatenbanken}},
  author       = {Nordhausen, Thomas and Hirt, Julian},
  edition      = {5.},
  month        = oct,
  organization = {{Martin-Luther-Universität Halle-Wittenberg}, {OST -- Ostschweizer Fachhochschule}},
  year         = {2020},
  eprint       = {https://refhunter.eu/manual},
  file         = {:- RefHunter. Manual Zur Literaturrecherche in Fachdatenbanken.pdf:PDF},
  howpublished = {Online},
  url          = {https://refhunter.eu/manual},
}

@Misc{USNLM2021,
  author       = {{United States National Library of Medicine}},
  howpublished = {Online},
  month        = mar,
  title        = {{NLM Products and Services}},
  year         = {2022},
  organization = {United States National Library of Medicine},
  url          = {https://eresources.nlm.nih.gov/nlm_eresources},
}

@Article{Murad2014,
  author   = {Murad, Mohammad Hassan and Montori, Victor M. and Ioannidis, John P. A. and Jaeschke, Roman and Devereaux, P. J. and Prasad, Kameshwar and Neumann, Ignacio and Carrasco-Labra, Alonso and Agoritsas, Thomas and Hatala, Rose and Meade, Maureen O. and Wyer, Peter and Cook, Deborah J. and Guyatt, Gordon},
  journal  = {JAMA},
  title    = {{How to Read a Systematic Review and Meta-analysis and Apply the Results to Patient Care: Users’ Guides to the Medical Literature}},
  year     = {2014},
  number   = {2},
  pages    = {171--179},
  volume   = {312},
  abstract = {Clinical decisions should be based on the totality of the best evidence and not the results of individual studies. When clinicians apply the results of a systematic review or meta-analysis to patient care, they should start by evaluating the credibility of the methods of the systematic review, ie, the extent to which these methods have likely protected against misleading results. Credibility depends on whether the review addressed a sensible clinical question; included an exhaustive literature search; demonstrated reproducibility of the selection and assessment of studies; and presented results in a useful manner. For reviews that are sufficiently credible, clinicians must decide on the degree of confidence in the estimates that the evidence warrants (quality of evidence). Confidence depends on the risk of bias in the body of evidence; the precision and consistency of the results; whether the results directly apply to the patient of interest; and the likelihood of reporting bias. Shared decision making requires understanding of the estimates of magnitude of beneficial and harmful effects, and confidence in those estimates.},
  doi      = {10.1001/jama.2014.5559},
  file     = {:Murad2014 - How to Read a Systematic Review and Meta Analysis and Apply the Results to Patient Care_ Users’ Guides to the Medical Literature.pdf:PDF},
}

@Article{PME2011,
  author    = {{The PLoS Medicine Editors}},
  journal   = {PLoS Med},
  title     = {{Best Practice in Systematic Reviews: The Importance of Protocols and Registration}},
  year      = {2011},
  month     = feb,
  number    = {2},
  pages     = {1--2},
  volume    = {8},
  doi       = {10.1371/journal.pmed.1001009},
  file      = {:Editors2011 - Best Practice in Systematic Reviews_ the Importance of Protocols and Registration.pdf:PDF},
  fjournal  = {PLoS medicine},
  publisher = {Public Library of Science},
}

@Article{Shamseer2015,
  author       = {Shamseer, Larissa and Moher, David and Clarke, Mike and Ghersi, Davina and Liberati, Alessandro and Petticrew, Mark and Shekelle, Paul and Stewart, Lesley A.},
  journal      = {BMJ},
  title        = {{Preferred Reporting Items for Systematic Review and Meta-analysis Protocols (PRISMA-P) 2015: elaboration and explanation}},
  year         = {2015},
  volume       = {349},
  abstract     = {Protocols of systematic reviews and meta-analyses allow for planning and documentation of review methods, act as a guard against arbitrary decision making during review conduct, enable readers to assess for the presence of selective reporting against completed reviews, and, when made publicly available, reduce duplication of efforts and potentially prompt collaboration. Evidence documenting the existence of selective reporting and excessive duplication of reviews on the same or similar topics is accumulating and many calls have been made in support of the documentation and public availability of review protocols. Several efforts have emerged in recent years to rectify these problems, including development of an international register for prospective reviews (PROSPERO) and launch of the first open access journal dedicated to the exclusive publication of systematic review products, including protocols (BioMed Central{\textquoteright}s Systematic Reviews). Furthering these efforts and building on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-analyses) guidelines, an international group of experts has created a guideline to improve the transparency, accuracy, completeness, and frequency of documented systematic review and meta-analysis protocols{\textemdash}PRISMA-P (for protocols) 2015. The PRISMA-P checklist contains 17 items considered to be essential and minimum components of a systematic review or meta-analysis protocol.This PRISMA-P 2015 Explanation and Elaboration paper provides readers with a full understanding of and evidence about the necessity of each item as well as a model example from an existing published protocol. This paper should be read together with the PRISMA-P 2015 statement. Systematic review authors and assessors are strongly encouraged to make use of PRISMA-P when drafting and appraising review protocols.},
  doi          = {10.1136/bmj.g7647},
  elocation-id = {g7647},
  eprint       = {https://www.bmj.com/content/349/bmj.g7647.full.pdf},
  file         = {:Shamseer2015 - Preferred Reporting Items for Systematic Review and Meta Analysis Protocols (PRISMA P) 2015_ Elaboration and Explanation.pdf:PDF},
  publisher    = {BMJ Publishing Group Ltd},
  url          = {https://www.bmj.com/content/349/bmj.g7647},
}

@Article{Moher2015,
  author   = {Moher, David and Shamseer, Larissa and Clarke, Mike and Ghersi, Davina and Liberati, Alessandro and Petticrew, Mark and Shekelle, Paul and Stewart, Lesley A. and the PRISMA-P Group},
  journal  = {Syst Rev},
  title    = {{Preferred Reporting Items for Systematic Review and Meta-analysis Protocols (PRISMA-P) 2015 statement}},
  year     = {2015},
  issn     = {2046-4053},
  number   = {1},
  pages    = {1},
  volume   = {4},
  abstract = {Systematic reviews should build on a protocol that describes the rationale, hypothesis, and planned methods of the review; few reviews report whether a protocol exists. Detailed, well-described protocols can facilitate the understanding and appraisal of the review methods, as well as the detection of modifications to methods and selective reporting in completed reviews. We describe the development of a reporting guideline, the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols 2015 (PRISMA-P 2015). PRISMA-P consists of a 17-item checklist intended to facilitate the preparation and reporting of a robust protocol for the systematic review. Funders and those commissioning reviews might consider mandating the use of the checklist to facilitate the submission of relevant protocol information in funding applications. Similarly, peer reviewers and editors can use the guidance to gauge the completeness and transparency of a systematic review protocol submitted for publication in a journal or other medium.},
  doi      = {10.1186/2046-4053-4-1},
  file     = {:Moher2015 - Preferred Reporting Items for Systematic Review and Meta Analysis Protocols (PRISMA P) 2015 Statement.pdf:PDF;:PRISMA-P-checklist.pdf:PDF;:Moher2015 - Preferred Reporting Items for Systematic Review and Meta Analysis Protocols (PRISMA P) 2015 Statement.doc:Word},
  refid    = {Moher2015},
}

@Article{Page2018,
  author   = {Page, Matthew J. and McKenzie, Joanne E. and Higgins, Julian P. T.},
  journal  = {BMJ Open},
  title    = {Tools for assessing risk of reporting biases in studies and syntheses of studies: a systematic review},
  year     = {2018},
  month    = mar,
  number   = {3},
  pages    = {e019703},
  volume   = {8},
  abstract = {Background Several scales, checklists and domain-based tools for assessing risk of reporting biases exist, but it is unclear how much they vary in content and guidance. We conducted a systematic review of the content and measurement properties of such tools.Methods We searched for potentially relevant articles in Ovid MEDLINE, Ovid Embase, Ovid PsycINFO and Google Scholar from inception to February 2017. One author screened all titles, abstracts and full text articles, and collected data on tool characteristics.Results We identified 18 tools that include an assessment of the risk of reporting bias. Tools varied in regard to the type of reporting bias assessed (eg, bias due to selective publication, bias due to selective non-reporting), and the level of assessment (eg, for the study as a whole, a particular result within a study or a particular synthesis of studies). Various criteria are used across tools to designate a synthesis as being at ‘high’ risk of bias due to selective publication (eg, evidence of funnel plot asymmetry, use of non-comprehensive searches). However, the relative weight assigned to each criterion in the overall judgement is unclear for most of these tools. Tools for assessing risk of bias due to selective non-reporting guide users to assess a study, or an outcome within a study, as ‘high’ risk of bias if no results are reported for an outcome. However, assessing the corresponding risk of bias in a synthesis that is missing the non-reported outcomes is outside the scope of most of these tools. Inter-rater agreement estimates were available for five tools.Conclusion There are several limitations of existing tools for assessing risk of reporting biases, in terms of their scope, guidance for reaching risk of bias judgements and measurement properties. Development and evaluation of a new, comprehensive tool could help overcome present limitations.},
  doi      = {10.1136/bmjopen-2017-019703},
  file     = {:Page2018 - Tools for Assessing Risk of Reporting Biases in Studies and Syntheses of Studies_ a Systematic Review.pdf:PDF},
  url      = {http://bmjopen.bmj.com/content/8/3/e019703.abstract},
}

@Article{Guyatt2011,
  author    = {Guyatt, Gordon and Oxman, Andrew D. and Akl, Elie A. and Kunz, Regina and Vist, Gunn and Brozek, Jan and Norris, Susan and Falck-Ytter, Yngve and Glasziou, Paul and deBeer, Hans and Jaeschke, Roman and Rind, David and Meerpohl, Joerg and Dahm, Philipp and Schünemann, Holger J.},
  journal   = {J Clin Epidemiol},
  title     = {{GRADE guidelines: 1. Introduction--GRADE evidence profiles and summary of findings tables}},
  year      = {2011},
  issn      = {0895-4356},
  month     = apr,
  number    = {4},
  pages     = {383--394},
  volume    = {64},
  abstract  = {This article is the first of a series providing guidance for use of the Grading of Recommendations Assessment, Development, and Evaluation (GRADE) system of rating quality of evidence and grading strength of recommendations in systematic reviews, health technology assessments (HTAs), and clinical practice guidelines addressing alternative management options. The GRADE process begins with asking an explicit question, including specification of all important outcomes. After the evidence is collected and summarized, GRADE provides explicit criteria for rating the quality of evidence that include study design, risk of bias, imprecision, inconsistency, indirectness, and magnitude of effect.Recommendations are characterized as strong or weak (alternative terms conditional or discretionary) according to the quality of the supporting evidence and the balance between desirable and undesirable consequences of the alternative management options. GRADE suggests summarizing evidence in succinct, transparent, and informative summary of findings tables that show the quality of evidence and the magnitude of relative and absolute effects for each important outcome and/or as evidence profiles that provide, in addition, detailed information about the reason for the quality of evidence rating.Subsequent articles in this series will address GRADE?s approach to formulating questions, assessing quality of evidence, and developing recommendations.},
  comment   = {doi: 10.1016/j.jclinepi.2010.04.026},
  doi       = {10.1016/j.jclinepi.2010.04.026},
  file      = {:Guyatt2011 - GRADE Guidelines_ 1. Introduction GRADE Evidence Profiles and Summary of Findings Tables.pdf:PDF},
  publisher = {Elsevier},
}

@Book{Schuenemann2013,
  author    = {Schünemann, Holger and Brożek, Jan and Guyatt, Gordon and Oxman, Andrew},
  publisher = {The GRADE Working Group},
  title     = {{GRADE handbook for grading quality of evidence and strength of recommendations}},
  year      = {2013},
  month     = oct,
  booktitle = {The GRADE Handbook},
  date      = {2013-10},
  eprint    = {https://gradepro.org/handbook},
  url       = {https://gradepro.org/handbook},
}

@Article{Guyatt2008,
  author   = {Guyatt, Gordon H. and Oxman, Andrew D. and Kunz, Regina and Vist, Gunn E. and Falck-Ytter, Yngve and Schünemann, Holger J.},
  journal  = {BMJ},
  title    = {What is “quality of evidence” and why is it important to clinicians?},
  year     = {2008},
  month    = may,
  number   = {7651},
  pages    = {995},
  volume   = {336},
  abstract = {Guideline developers use a bewildering variety of systems to rate the quality of the evidence underlying their recommendations. Some are facile, some confused, and others sophisticated but complexIn 2004 the Grading of Recommendations Assessment, Development and Evaluation (GRADE) Working Group presented its initial proposal for patient management.1 In this second of a series of five articles focusing on the GRADE approach to developing and presenting recommendations we show how GRADE has built on previous systems to create a highly structured, transparent, and informative system for rating quality of evidence.Summary pointsA guideline’s formulation should include a clear question with specification of all outcomes of importance to patientsGRADE offers four levels of evidence quality: high, moderate, low, and very lowRandomised trials begin as high quality evidence and observational studies as low quality evidenceQuality may be downgraded as a result of limitations in study design or implementation, imprecision of estimates (wide confidence intervals), variability in results, indirectness of evidence, or publication biasQuality may be upgraded because of a very large magnitude of effect, a dose-response gradient, and if all plausible biases would reduce an apparent treatment effectCritical outcomes determine the overall quality of evidenceEvidence profiles provide simple, transparent summariesAny question addressing clinical management has four components: patients, an intervention, a comparison, and the outcomes of interest.2 For example, consider the following: in patients with pancreatic carcinoma undergoing surgery what is the impact of a modified resection that preserves the pylorus compared with a standard wide tumour resection--variations of the Whipple procedure--on short term and long term mortality, blood transfusions, bile leaks, hospital stay, and problems with gastric emptying?Perhaps the most common error in formulating the question is a failure to include all the outcomes that are of importance to patients.3 Critics …},
  doi      = {10.1136/bmj.39490.551019.BE},
  file     = {:Guyatt2008 - What Is “quality of Evidence” and Why Is It Important to Clinicians_.pdf:PDF},
  url      = {http://www.bmj.com/content/336/7651/995.abstract},
}

@Article{Siddaway2019,
  author    = {Siddaway, Andy P. and Wood, Alex M. and Hedges, Larry V.},
  journal   = {Annu Rev Psychol},
  title     = {{How to Do a Systematic Review: A Best Practice Guide for Conducting and Reporting Narrative Reviews, Meta-Analyses, and Meta-Syntheses}},
  year      = {2019},
  issn      = {0066-4308},
  month     = jan,
  number    = {1},
  pages     = {747--770},
  volume    = {70},
  abstract  = {Systematic reviews are characterized by a methodical and replicable methodology and presentation. They involve a comprehensive search to locate all relevant published and unpublished work on a subject; a systematic integration of search results; and a critique of the extent, nature, and quality of evidence in relation to a particular research question. The best reviews synthesize studies to draw broad theoretical conclusions about what a literature means, linking theory to evidence and evidence to theory. This guide describes how to plan, conduct, organize, and present a systematic review of quantitative (meta-analysis) or qualitative (narrative review, meta-synthesis) information. We outline core standards and principles and describe commonly encountered problems. Although this guide targets psychological scientists, its high level of abstraction makes it potentially relevant to any subject area or discipline. We argue that systematic reviews are a key methodology for clarifying whether and how research findings replicate and for explaining possible inconsistencies, and we call for researchers to conduct systematic reviews to help elucidate whether there is a replication crisis.},
  comment   = {doi: 10.1146/annurev-psych-010418-102803},
  doi       = {10.1146/annurev-psych-010418-102803},
  file      = {:Siddaway2019 - How to Do a Systematic Review_ a Best Practice Guide for Conducting and Reporting Narrative Reviews, Meta Analyses, and Meta Syntheses.pdf:PDF},
  publisher = {Annual Reviews},
}

@Article{Stewart2015,
  author   = {Stewart, Lesley A. and Clarke, Mike and Rovers, Maroeska and Riley, Richard D. and Simmonds, Mark and Stewart, Gavin and Tierney, Jayne F. and for the PRISMA-IPD Development Group},
  journal  = {JAMA},
  title    = {{Preferred Reporting Items for a Systematic Review and Meta-analysis of Individual Participant Data: The PRISMA-IPD Statement}},
  year     = {2015},
  issn     = {0098-7484},
  month    = apr,
  number   = {16},
  pages    = {1657--1665},
  volume   = {313},
  abstract = {{Systematic reviews and meta-analyses of individual participant data (IPD) aim to collect, check, and reanalyze individual-level data from all studies addressing a particular research question and are therefore considered a gold standard approach to evidence synthesis. They are likely to be used with increasing frequency as current initiatives to share clinical trial data gain momentum and may be particularly important in reviewing controversial therapeutic areas.To develop PRISMA-IPD as a stand-alone extension to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) Statement, tailored to the specific requirements of reporting systematic reviews and meta-analyses of IPD. Although developed primarily for reviews of randomized trials, many items will apply in other contexts, including reviews of diagnosis and prognosis.Development of PRISMA-IPD followed the EQUATOR Network framework guidance and used the existing standard PRISMA Statement as a starting point to draft additional relevant material. A web-based survey informed discussion at an international workshop that included researchers, clinicians, methodologists experienced in conducting systematic reviews and meta-analyses of IPD, and journal editors. The statement was drafted and iterative refinements were made by the project, advisory, and development groups. The PRISMA-IPD Development Group reached agreement on the PRISMA-IPD checklist and flow diagram by consensus.Compared with standard PRISMA, the PRISMA-IPD checklist includes 3 new items that address (1) methods of checking the integrity of the IPD (such as pattern of randomization, data consistency, baseline imbalance, and missing data), (2) reporting any important issues that emerge, and (3) exploring variation (such as whether certain types of individual benefit more from the intervention than others). A further additional item was created by reorganization of standard PRISMA items relating to interpreting results. Wording was modified in 23 items to reflect the IPD approach.PRISMA-IPD provides guidelines for reporting systematic reviews and meta-analyses of IPD.}},
  doi      = {10.1001/jama.2015.3656},
  eprint   = {https://jamanetwork.com/journals/jama/articlepdf/2279718/jsc150002.pdf},
  file     = {:Stewart2015 - Preferred Reporting Items for a Systematic Review and Meta Analysis of Individual Participant Data_ the PRISMA IPD Statement.pdf:PDF},
}

@Article{Damarell2013,
  author   = {Damarell, Raechel A. and Tieman, Jennifer J. and Sladek, Ruth M.},
  journal  = {BMC Med Res Methodol},
  title    = {{OvidSP Medline-to-PubMed search filter translation: a methodology for extending search filter range to include PubMed's unique content}},
  year     = {2013},
  issn     = {1471-2288},
  number   = {1},
  pages    = {86},
  volume   = {13},
  abstract = {PubMed translations of OvidSP Medline search filters offer searchers improved ease of access. They may also facilitate access to PubMed’s unique content, including citations for the most recently published biomedical evidence. Retrieving this content requires a search strategy comprising natural language terms (‘textwords’), rather than Medical Subject Headings (MeSH). We describe a reproducible methodology that uses a validated PubMed search filter translation to create a textword-only strategy to extend retrieval to PubMed’s unique heart failure literature.},
  doi      = {10.1186/1471-2288-13-86},
  file     = {:Damarell2013 - OvidSP Medline to PubMed Search Filter Translation_ a Methodology for Extending Search Filter Range to Include PubMed's Unique Content.pdf:PDF},
  refid    = {Damarell2013},
}

@Article{Sackett1996,
  author    = {Sackett, David L. and Rosenberg, William M. C. and Gray, J. A. Muir and Haynes, R. Brian and Richardson, W. Scott},
  journal   = {BMJ},
  title     = {Evidence based medicine: what it is and what it isn{\textquoteright}t},
  year      = {1996},
  issn      = {0959-8138},
  number    = {7023},
  pages     = {71--72},
  volume    = {312},
  doi       = {10.1136/bmj.312.7023.71},
  file      = {:Sackett1996 - Evidence Based Medicine_ What It Is and What It Isn_t.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
  url       = {https://www.bmj.com/content/312/7023/71},
}

@Article{Akobeng2005,
  author    = {Akobeng, Anthony K.},
  journal   = {Arch Dis Child},
  title     = {Principles of evidence based medicine},
  year      = {2005},
  issn      = {0003-9888},
  number    = {8},
  pages     = {837--840},
  volume    = {90},
  abstract  = {Health care professionals are increasingly required to base clinical decisions on the best available evidence. Evidence based medicine (EBM) is a systematic approach to clinical problem solving which allows the integration of the best available research evidence with clinical expertise and patient values. This paper explains the concept of EBM and introduces the five step EBM model: formulation of answerable clinical questions; searching for evidence; critical appraisal; applicability of evidence; evaluation of performance. Subsequent articles will focus on the principles and critical appraisal of randomised controlled trials, systematic reviews, and meta-analyses, and provide a practical demonstration of the five step EBM model using a real life clinical scenario.},
  doi       = {10.1136/adc.2005.071761},
  file      = {:Akobeng2005 - Principles of Evidence Based Medicine.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
  url       = {https://adc.bmj.com/content/90/8/837},
}

@Article{Stillwell2010,
  author   = {Stillwell, Susan B. and Fineout-Overholt, Ellen and Melnyk, Bernadette Mazurek and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice, Step by Step: Asking the Clinical Question: A Key Step in Evidence-Based Practice}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {3},
  volume   = {110},
  abstract = {This is the third article in a series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000368959.11129.79},
  file     = {:Stillwell2010 - Evidence Based Practice, Step by Step_ Asking the Clinical Question_ a Key Step in Evidence Based Practice.pdf:PDF;:Stillwell2010 - Evidence Based Practice, Step by Step_ Asking the Clinical Question_ a Key Step in Evidence Based Practice.epub:ePUB},
  refid    = {00000446-201003000-00028},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/03000/Evidence_Based_Practice,_Step_by_Step__Asking_the.28.aspx},
}

@Manual{CochraneDEManual,
  title        = {{Manual systematische Recherche für Evidenzsynthesen und Leitlinien}},
  edition      = {2.1},
  organization = {Cochrane Deutschland Stiftung},
  year         = {2020},
  doi          = {10.6094/UNIFR/174468},
  file         = {:CochraneDEManual - Manual Systematische Recherche Für Evidenzsynthesen Und Leitlinien.pdf:PDF},
  keywords     = {Information Retrieval; Recherche; Online-Recherche; Evidenz-basierte Medizin; Medizin; Online-RessourceRecherche*; Evidenz-basierte Medizin*; Evidenz*; Medizin*},
  url          = {https://freidok.uni-freiburg.de/data/174468},
}

@Misc{cornell2021,
  author       = {{Cornell University Library}},
  howpublished = {Online},
  title        = {{What Type of Review is Right for You?}},
  year         = {2019},
  eprint       = {https://guides.library.cornell.edu/ld.php?content_id=52561085},
  file         = {:cornell2021 - What Type of Review Is Right for You.pdf:PDF},
  keywords     = {Decision Tree, Systematic Reviews, Evidence Synthesis},
  url          = {https://guides.library.cornell.edu/evidence-synthesis/service},
}

@Article{Paez2017,
  author             = {Paez, Arsenio},
  journal            = {J Evid Based Med},
  title              = {Gray literature: An important resource in systematic reviews.},
  year               = {2017},
  month              = aug,
  pages              = {233--240},
  volume             = {10},
  abstract           = {Systematic reviews aide the analysis and dissemination of evidence, using rigorous and transparent methods to generate empirically attained answers to focused research questions. Identifying all evidence relevant to the research questions is an essential component, and challenge, of systematic reviews. Gray literature, or evidence not published in commercial publications, can make important contributions to a systematic review. Gray literature can include academic papers, including theses and dissertations, research and committee reports, government reports, conference papers, and ongoing research, among others. It may provide data not found within commercially published literature, providing an important forum for disseminating studies with null or negative results that might not otherwise be disseminated. Gray literature may thusly reduce publication bias, increase reviews' comprehensiveness and timeliness, and foster a balanced picture of available evidence. Gray literature's diverse formats and audiences can present a significant challenge in a systematic search for evidence. However, the benefits of including gray literature may far outweigh the cost in time and resource needed to search for it, and it is important for it to be included in a systematic review or review of evidence. A carefully thought out gray literature search strategy may be an invaluable component of a systematic review. This narrative review provides guidance about the benefits of including gray literature in a systematic review, and sources for searching through gray literature. An illustrative example of a search for evidence within gray literature sources is presented to highlight the potential contributions of such a search to a systematic review. Benefits and challenges of gray literature search methods are discussed, and recommendations made.},
  address            = {England},
  article-doi        = {10.1111/jebm.12266},
  completed          = {20180404},
  doi                = {10.1111/jebm.12266},
  electronic-issn    = {1756-5391},
  file               = {:Paez2017 - Gray Literature_ an Important Resource in Systematic Reviews..pdf:PDF},
  history            = {2018/04/05 06:00 [medline]},
  issue              = {3},
  keywords           = {Humans, Publication Bias, *Publishing, Research Report, *Review Literature as Topic, evidence, gray literature, publication bias, search, systematic review},
  language           = {eng},
  linking-issn       = {1756-5391},
  location-id        = {10.1111/jebm.12266 [doi]},
  nlm-unique-id      = {101497477},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20181202},
  source             = {J Evid Based Med. 2017 Aug;10(3):233-240. doi: 10.1111/jebm.12266.},
  status             = {MEDLINE},
  subset             = {IM},
  termowner          = {NOTNLM},
  title-abbreviation = {J Evid Based Med},
}

@Book{Auger2017,
  author    = {Peter Auger},
  publisher = {De Gruyter Saur},
  title     = {{Information Sources in Grey Literature}},
  year      = {2017},
  isbn      = {9783110977233},
  doi       = {10.1515/9783110977233},
  file      = {:Auger2017 - Information Sources in Grey Literature.pdf:PDF},
}

@Article{Mahood2014,
  author   = {Mahood, Quenby and Van Eerd, Dwayne and Irvin, Emma},
  journal  = {Res Syn Meth},
  title    = {Searching for grey literature for systematic reviews: challenges and benefits},
  year     = {2014},
  number   = {3},
  pages    = {221--234},
  volume   = {5},
  abstract = {There is ongoing interest in including grey literature in systematic reviews. Including grey literature can broaden the scope to more relevant studies, thereby providing a more complete view of available evidence. Searching for grey literature can be challenging despite greater access through the Internet, search engines and online bibliographic databases. There are a number of publications that list sources for finding grey literature in systematic reviews. However, there is scant information about how searches for grey literature are executed and how it is included in the review process. This level of detail is important to ensure that reviews follow explicit methodology to be systematic, transparent and reproducible. The purpose of this paper is to provide a detailed account of one systematic review team's experience in searching for grey literature and including it throughout the review. We provide a brief overview of grey literature before describing our search and review approach. We also discuss the benefits and challenges of including grey literature in our systematic review, as well as the strengths and limitations to our approach. Detailed information about incorporating grey literature in reviews is important in advancing methodology as review teams adapt and build upon the approaches described. Copyright © 2013 John Wiley \& Sons, Ltd.},
  doi      = {10.1002/jrsm.1106},
  file     = {:Mahood2014 - Searching for Grey Literature for Systematic Reviews_ Challenges and Benefits.pdf:PDF},
  keywords = {grey literature, systematic reviews, literature searching},
}

@Article{Knelangen2018,
  author   = {Marco Knelangen and Elke Hausner and Maria-Inti Metzendorf and Sibylle Sturtz and Siw Waffenschmidt},
  journal  = {J Clin Epidemiol},
  title    = {Trial registry searches for randomized controlled trials of new drugs required registry-specific adaptation to achieve adequate sensitivity},
  year     = {2018},
  issn     = {0895-4356},
  pages    = {69--75},
  volume   = {94},
  abstract = {Objectives
To analyze the availability of randomized controlled trials (RCTs) of new drugs in trial registries and to develop and test different search strategies in ClinicalTrials.gov (CT.gov), the EU Clinical Trials Register (EU-CTR), and the International Clinical Trials Registry Platform (ICTRP).
Study Design and Setting
Information from dossiers submitted by pharmaceutical companies was analyzed regarding the registration of the included RCTs in CT.gov, EU-CTR and ICTRP; different search strategies were developed and tested to determine performance.
Results
A total of 192 (95%) of 203 RCTs on newly approved drugs were registered in CT.gov; the 11 nonregistered trials were completed before 2005 or represented non-RCTs. Simple searches for RCTs on 18 new drugs using the generic drug name yielded a sensitivity of 94% in CT.gov (EU-CTR: 71%; ICTRP: 60%). The main reason for study nondetection was the sole use of the drug code in the registry entries. Simple searches for RCTs on 13 conditions using reasonably inferred search terms yielded a sensitivity of 100% in CT.gov.
Conclusion
Almost all relevant RCTs on newly approved drugs will probably be identified in CT.gov alone. A sensitive search in CT.gov can be conducted using single search terms. The searches in ICTRP and EU-CTR should include several search terms (e.g., derived via text analysis).},
  doi      = {10.1016/j.jclinepi.2017.11.003},
  file     = {:Knelangen2018 - Trial Registry Searches for Randomized Controlled Trials of New Drugs Required Registry Specific Adaptation to Achieve Adequate Sensitivity.pdf:PDF},
  keywords = {Information storage and retrieval, Randomized controlled trials as topic, Registries, Pharmaceutical preparations},
  url      = {https://www.sciencedirect.com/science/article/pii/S0895435617303979},
}

@Article{Glanville2014,
  author    = {Glanville, Julie M. and Duffy, Steven and McCool, Rachael and Varley, Danielle},
  journal   = {J Med Libr Assoc},
  title     = {{Searching ClinicalTrials.gov and the International Clinical Trials Registry Platform to inform systematic reviews: what are the optimal search approaches?}},
  year      = {2014},
  issn      = {1536-5050},
  month     = jul,
  number    = {25031558},
  pages     = {177--183},
  volume    = {102},
  abstract  = {BACKGROUND: Since 2005, International Committee of Medical Journal Editors (ICMJE) member journals have required that clinical trials be registered in publicly available trials registers before they are considered for publication. OBJECTIVES: The research explores whether it is adequate, when searching to inform systematic reviews, to search for relevant clinical trials using only public trials registers and to identify the optimal search approaches in trials registers. METHODS: A search was conducted in ClinicalTrials.gov and the International Clinical Trials Registry Platform (ICTRP) for research studies that had been included in eight systematic reviews. Four search approaches (highly sensitive, sensitive, precise, and highly precise) were performed using the basic and advanced interfaces in both resources. RESULTS: On average, 84% of studies were not listed in either resource. The largest number of included studies was retrieved in ClinicalTrials.gov and ICTRP when a sensitive search approach was used in the basic interface. The use of the advanced interface maintained or improved sensitivity in 16 of 19 strategies for Clinicaltrials.gov and 8 of 18 for ICTRP. No single search approach was sensitive enough to identify all studies included in the 6 reviews. CONCLUSIONS: Trials registers cannot yet be relied upon as the sole means to locate trials for systematic reviews. Trials registers lag behind the major bibliographic databases in terms of their search interfaces. IMPLICATIONS: For systematic reviews, trials registers and major bibliographic databases should be searched. Trials registers should be searched using sensitive approaches, and both the registers consulted in this study should be searched.},
  comment   = {25031558[pmid]
PMC4076126[pmcid]},
  database  = {PubMed},
  doi       = {10.3163/1536-5050.102.3.007},
  file      = {:Glanville2014 - Searching ClinicalTrials.gov and the International Clinical Trials Registry Platform to Inform Systematic Reviews_ What Are the Optimal Search Approaches_.pdf:PDF},
  keywords  = {Abstracting and Indexing/statistics & numerical data, Clinical Trials as Topic/*statistics & numerical data, Evidence-Based Medicine, Humans, Information Dissemination, Information Storage and Retrieval/*methods, Randomized Controlled Trials as Topic, Registries, *Review Literature as Topic, Subject Headings},
  language  = {eng},
  publisher = {Medical Library Association},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4076126/},
}

@Article{FineoutOverholt2010,
  author   = {Fineout-Overholt, Ellen and Melnyk, Bernadette Mazurek and Stillwell, Susan B. and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice, Step by Step: Critical Appraisal of the Evidence: Part III}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {11},
  volume   = {110},
  abstract = {The process of synthesis: seeing similarities and differences across the body of evidence.},
  doi      = {10.1097/01.NAJ.0000390523.99066.b5},
  file     = {:FineoutOverholt2010 - Evidence Based Practice, Step by Step_ Critical Appraisal of the Evidence Part III.pdf:PDF},
  refid    = {00000446-201011000-00027},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/11000/Evidence_Based_Practice,_Step_by_Step__Critical.27.aspx},
}

@Article{FineoutOverholt2010a,
  author   = {Fineout-Overholt, Ellen and Melnyk, Bernadette Mazurek and Stillwell, Susan B. and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice, Step by Step: Critical Appraisal of the Evidence: Part II}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {9},
  volume   = {110},
  abstract = {This is the sixth article in a series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000388264.49427.f9},
  file     = {:FineoutOverholt2010a - Evidence Based Practice, Step by Step_ Critical Appraisal of the Evidence_ Part II_ Digging Deeper Examining the _keeper_ Studies..pdf:PDF},
  refid    = {00000446-201009000-00024},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/09000/Evidence_Based_Practice,_Step_by_Step__Critical.24.aspx},
}

@Article{FineoutOverholt2010b,
  author   = {Fineout-Overholt, Ellen and Melnyk, Bernadette Mazurek and Stillwell, Susan B. and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice Step by Step: Critical Appraisal of the Evidence: Part I}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {7},
  volume   = {110},
  abstract = {This is the fifth article in a series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000383935.22721.9c},
  file     = {:FineoutOverholt2010b - Evidence Based Practice Step by Step_ Critical Appraisal of the Evidence_ Part I.pdf:PDF},
  refid    = {00000446-201007000-00026},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/07000/Evidence_Based_Practice_Step_by_Step__Critical.26.aspx},
}

@Article{Stillwell2010a,
  author   = {Stillwell, Susan B. and Fineout-Overholt, Ellen and Melnyk, Bernadette Mazurek and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice, Step by Step: Searching for the Evidence}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {5},
  volume   = {110},
  abstract = {This is the fourth article in a series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000372071.24134.7e},
  file     = {:Stillwell2010a - Evidence Based Practice, Step by Step_ Searching for the Evidence.pdf:PDF},
  refid    = {00000446-201005000-00024},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/05000/Evidence_Based_Practice,_Step_by_Step__Searching.24.aspx},
}

@Article{Melnyk2010,
  author   = {Melnyk, Bernadette Mazurek and Fineout-Overholt, Ellen and Stillwell, Susan B. and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice: Step by Step: The Seven Steps of Evidence-Based Practice}},
  year     = {2010},
  issn     = {0002-936X},
  number   = {1},
  volume   = {110},
  abstract = {This is the second article in a new series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000366056.06605.d2},
  file     = {:Melnyk2010 - Evidence Based Practice_ Step by Step_ the Seven Steps of Evidence Based Practice.pdf:PDF},
  refid    = {00000446-201001000-00030},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2010/01000/Evidence_Based_Practice__Step_by_Step__The_Seven.30.aspx},
}

@Article{Melnyk2009,
  author   = {Melnyk, Bernadette Mazurek and Fineout-Overholt, Ellen and Stillwell, Susan B. and Williamson, Kathleen M.},
  journal  = {Am J Nurs},
  title    = {{Evidence-Based Practice: Step by Step: Igniting a Spirit of Inquiry}},
  year     = {2009},
  issn     = {0002-936X},
  number   = {11},
  volume   = {109},
  abstract = {This is the first article in a new series from the Arizona State University College of Nursing and Health Innovation's Center for the Advancement of Evidence-Based Practice. Evidence-based practice (EBP) is a problem-solving approach to the delivery of health care that integrates the best evidence from studies and patient care data with clinician expertise and patient preferences and values. When delivered in a context of caring and in a supportive organizational culture, the highest quality of care and best patient outcomes can be achieved.},
  doi      = {10.1097/01.NAJ.0000363354.53883.58},
  file     = {:Melnyk2009 - Evidence Based Practice_ Step by Step_ Igniting a Spirit of Inquiry.pdf:PDF},
  refid    = {00000446-200911000-00028},
  url      = {https://journals.lww.com/ajnonline/Fulltext/2009/11000/Evidence_Based_Practice__Step_by_Step__Igniting_a.28.aspx},
}

@InCollection{Cummings2013,
  author    = {Cummings, Steven R. and Browner, Warren S. and Hulley, Stephen B.},
  booktitle = {{Designing Clinical Research}},
  publisher = {Lippincott Williams \& Wilkins},
  title     = {{Conceiving the Research Question and Developing the Study Plan}},
  year      = {2013},
  address   = {Philadelphia},
  chapter   = {2},
  edition   = {4.},
  editor    = {Hulley, Stephen B. and Cummings, Steven R. and Browner, Warren S. and Grady, Deborah G. and Newman, Thomas B.},
  isbn      = {978-1-60831-804-9},
  pages     = {14--22},
  file      = {:Cummings2013 - Conceiving the Research Question and Developing the Study Plan.pdf:PDF},
  language  = {English},
  url       = {https://swisscovery.slsp.ch/permalink/41SLSP_UBE/99pfpl/alma99117040391205511},
}

@Article{Haynes2004,
  author    = {Haynes, R. Brian and Wilczynski, Nancy L.},
  journal   = {BMJ},
  title     = {{Optimal search strategies for retrieving scientifically strong studies of diagnosis from Medline: analytical survey}},
  year      = {2004},
  issn      = {0959-8138},
  month     = apr,
  number    = {7447},
  pages     = {1040},
  volume    = {328},
  abstract  = {Objective To develop optimal search strategies in Medline for retrieving sound clinical studies on the diagnosis of health disorders. Design Analytical survey. Setting Medline, 2000. Participants 170 journals for 2000 of which 161 were indexed in Medline. Main outcome measures The sensitivity, specificity, precision ({\textquotedblleft}positive predictive value{\textquotedblright}), and accuracy of 4862 unique terms in 17 287 combinations were determined by comparison with a hand search of all articles (the {\textquotedblleft}gold standard{\textquotedblright}) in 161 journals published during 2000 (49 028 articles). Results Only 147 (18.9\%) of 778 articles about diagnostic tests met basic criteria for scientific merit. Combinations of search terms reached peak sensitivities of 98.6\% at a specificity of 74.3\%. Compared with best single terms, best multiple terms increased sensitivity forsound studies by 6.8\% (absolute increase), while also increasing specificity (absolute increase 6.0\%) when sensitivity was maximised. When terms were combined to maximise specificity, the singleterm, specificity.tw. (98.4\%), outperformed combinations of terms. The strategies newly reported in this paper outperformed other validated search strategies except for one strategy that had slightly higher sensitivity (99.3\% v 98.6\%) but lower specificity (54.7\% v 74.3\%). Conclusion New empirical search strategies in Medline can optimise retrieval of articles reporting high quality clinical studies of diagnosis.},
  doi       = {10.1136/bmj.38068.557998.EE},
  file      = {:Haynes2004 - Optimal Search Strategies for Retrieving Scientifically Strong Studies of Diagnosis from Medline_ Analytical Survey.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
  url       = {https://www.bmj.com/content/328/7447/1040},
}

@Book{mecir2022,
  author       = {Higgins, Julian P. T. and Lasserson, Toby and Chandler, Jackie and Tovey, David and Thomas, James and Flemyng, Ella and Churchill, Rachel},
  publisher    = {Cochrane},
  title        = {{Methodological Expectations of Cochrane Intervention Reviews (MECIR)}},
  year         = {2022},
  address      = {London},
  month        = feb,
  eprint       = {https://community.cochrane.org/mecir-manual},
  file         = {:mecir2021 - Methodological Expectations of Cochrane Intervention Reviews.pdf:PDF},
  organization = {Cochrane},
  url          = {https://community.cochrane.org/mecir-manual},
}

@Book{cochranehandbook6.3,
  editor       = {Higgins, Julian P. T. and Thomas, James and Chandler, Jacqueline and Cumpston, Miranda and Li, Tianjing and Page, Matthew J. and Welch, Vivian A.},
  publisher    = {Cochrane},
  title        = {{Cochrane Handbook for Systematic Reviews of Interventions}},
  year         = {2022},
  edition      = {6.3},
  month        = feb,
  eprint       = {https://training.cochrane.org/handbook},
  organization = {Cochrane},
  url          = {https://training.cochrane.org/handbook},
}

@Book{JBIHandbook2019,
  editor    = {Porritt, Kylie and McArthur, Alexa and Lockwood, Craig and Munn, Zachary},
  publisher = {JBI},
  title     = {{JBI Handbook for Evidence Implementation}},
  year      = {2019},
  doi       = {10.46658/JBIIH-19-01},
  eprint    = {https://implementationmanual.jbi.global},
  file      = {:JBIHandbook2019 - JBI Handbook for Evidence Implementation.pdf:PDF},
  url       = {https://implementationmanual.jbi.global},
}

@InCollection{Twells2021,
  author    = {Twells, Laurie K.},
  booktitle = {Clinical Epidemiology: Practice and Methods},
  publisher = {Springer US},
  title     = {{Evidence-Based Decision-Making 1: Critical Appraisal}},
  year      = {2021},
  address   = {New York, NY},
  editor    = {Parfrey, Patrick S. and Barrett, Brendan J.},
  isbn      = {978-1-0716-1138-8},
  pages     = {389--404},
  abstract  = {This chapter provides an introduction to the concept of Evidence-based Medicine (EBM)Evidence-based medicine (EBM) including its history, rooted in Canada and its important role in modern medicine. The chapter introduces EBMEvidence-based medicine (EBM)and explains the process of conducting EBMEvidence-based medicine (EBM). The chapter starts with a description of the traditional hierarchy of evidence that exists in research with reference to the critical appraisalCritical appraisal tools often used to assess the quality or credibility of individual studies. It includes a section on assessing risk of biasBias in randomized clinical trials and non-randomized studies and guidelines for reporting study findings now fully captured in the EQUATOR Network. In addition, a section on GRADEGrades of Recommendation Assessment, Development and Evaluation (GRADE)(Grades of Recommendation Assessment, Development and EvaluationGrades of Recommendation Assessment, Development and Evaluation (GRADE)) and the process used to determine the quality of evidence when guiding clinical decisions or developing clinical practice guidelinesClinical practice guidelines (CPG) is included. In response to the substantial number of research syntheses being published, AMSTAR2, a tool used to critically appraise the quality and reporting of systematic reviews is described. The main focus of the chapter remains on how to critically appraise the medical literature, as one step in the EBMEvidence-based medicine (EBM)process. However, this process also includes an assessment of study biasBias and an understanding of reporting guidelinesReporting guidelines. At its basic level, critical appraisalCritical appraisal requires an understanding of the strengths and weaknesses of study designStudy designs and how these in turn impact the validityValidity and applicability of research findings. Strong critical appraisalCritical appraisal skills are critical to evidence-based decision-makingDecision making.},
  doi       = {10.1007/978-1-0716-1138-8_21},
  file      = {:Twells2021 - Evidence Based Decision Making 1_ Critical Appraisal.pdf:PDF;:Twells2021 - Evidence Based Decision Making 1_ Critical Appraisal.epub:ePUB},
}

@Article{Buccheri2017,
  author   = {Buccheri, Robin K. and Sharifi, Claire},
  journal  = {Worldviews Evid Based Nurs},
  title    = {{Critical Appraisal Tools and Reporting Guidelines for Evidence-Based Practice}},
  year     = {2017},
  number   = {6},
  pages    = {463--472},
  volume   = {14},
  abstract = {ABSTRACT Background Nurses engaged in evidence-based practice (EBP) have two important sets of tools: Critical appraisal tools and reporting guidelines. Critical appraisal tools facilitate the appraisal process and guide a consumer of evidence through an objective, analytical, evaluation process. Reporting guidelines, checklists of items that should be included in a publication or report, ensure that the project or guidelines are reported on with clarity, completeness, and transparency. Purpose The primary purpose of this paper is to help nurses understand the difference between critical appraisal tools and reporting guidelines. A secondary purpose is to help nurses locate the appropriate tool for the appraisal or reporting of evidence. Methods A systematic search was conducted to find commonly used critical appraisal tools and reporting guidelines for EBP in nursing. Rationale This article serves as a resource to help nurse navigate the often-overwhelming terrain of critical appraisal tools and reporting guidelines, and will help both novice and experienced consumers of evidence more easily select the appropriate tool(s) to use for critical appraisal and reporting of evidence. Having the skills to select the appropriate tool or guideline is an essential part of meeting EBP competencies for both practicing registered nurses and advanced practice nurses (Melnyk \& Gallagher-Ford, 2015; Melnyk, Gallagher-Ford, \& Fineout-Overholt, 2017). Results Nine commonly used critical appraisal tools and eight reporting guidelines were found and are described in this manuscript. Specific steps for selecting an appropriate tool as well as examples of each tool's use in a publication are provided. Linking Evidence to Action Practicing registered nurses and advance practice nurses must be able to critically appraise and disseminate evidence in order to meet EBP competencies. This article is a resource for understanding the difference between critical appraisal tools and reporting guidelines, and identifying and accessing appropriate tools or guidelines.},
  doi      = {10.1111/wvn.12258},
  file     = {:Buccheri2017 - Critical Appraisal Tools and Reporting Guidelines for Evidence Based Practice.pdf:PDF},
  keywords = {critical appraisal tools, evidence-based nursing, evidence-based practice, reporting guidelines},
}

@Article{Kassirer1995,
  author  = {Kassirer, Jerome P. and Angell, Marcia},
  journal = {N Engl J Med},
  title   = {{Redundant Publication: A Reminder}},
  year    = {1995},
  note    = {PMID: 7616995},
  number  = {7},
  pages   = {449--450},
  volume  = {333},
  doi     = {10.1056/NEJM199508173330709},
  file    = {:Kassirer1995 - Redundant Publication_ a Reminder.pdf:PDF},
}

@Article{Johnson2006,
  author   = {Johnson, Claire},
  journal  = {J Manipulative Physiol Ther},
  title    = {{Repetitive, Duplicate, and Redundant Publications: A Review for Authors and Readers}},
  year     = {2006},
  issn     = {0161-4754},
  number   = {7},
  pages    = {505--509},
  volume   = {29},
  abstract = {Repetitive, duplicate, and redundant publications are an important concern in the scientific literature. Their occurrence affects science and carries with it sanctions of consequence. This editorial provides a brief review of the definitions, classifications, impact, sanctions, and prevention strategies regarding repetitive, duplicate, and redundant publications.},
  doi      = {10.1016/j.jmpt.2006.07.001},
  file     = {:Johnson2006 - Repetitive, Duplicate, and Redundant Publications_ a Review for Authors and Readers.pdf:PDF},
}

@Article{Qi2013,
  author    = {Qi, Xingshun and Yang, Man and Ren, Weirong and Jia, Jia and Wang, Juan and Han, Guohong and Fan, Daiming},
  journal   = {PLoS One},
  title     = {{Find Duplicates among the PubMed, EMBASE, and Cochrane Library Databases in Systematic Review}},
  year      = {2013},
  month     = aug,
  number    = {8},
  pages     = {1--12},
  volume    = {8},
  abstract  = {Background Finding duplicates is an important phase of systematic review. However, no consensus regarding the methods to find duplicates has been provided. This study aims to describe a pragmatic strategy of combining auto- and hand-searching duplicates in systematic review and to evaluate the prevalence and characteristics of duplicates.  Methods and Findings Literatures regarding portal vein thrombosis (PVT) and Budd-Chiari syndrome (BCS) were searched by the PubMed, EMBASE, and Cochrane library databases. Duplicates included one index paper and one or more redundant papers. They were divided into type-I (duplicates among different databases) and type-II (duplicate publications in different journals/issues) duplicates. For type-I duplicates, reference items were further compared between index and redundant papers. Of 10936 papers regarding PVT, 2399 and 1307 were identified as auto- and hand-searched duplicates, respectively. The prevalence of auto- and hand-searched redundant papers was 11.0% (1201/10936) and 6.1% (665/10936), respectively. They included 3431 type-I and 275 type-II duplicates. Of 11403 papers regarding BCS, 3275 and 2064 were identified as auto- and hand-searched duplicates, respectively. The prevalence of auto- and hand-searched redundant papers was 14.4% (1640/11403) and 9.1% (1039/11403), respectively. They included 5053 type-I and 286 type-II duplicates. Most of type-I duplicates were identified by auto-searching method (69.5%, 2385/3431 in PVT literatures; 64.6%, 3263/5053 in BCS literatures). Nearly all type-II duplicates were identified by hand-searching method (94.9%, 261/275 in PVT literatures; 95.8%, 274/286 in BCS literatures). Compared with those identified by auto-searching method, type-I duplicates identified by hand-searching method had a significantly higher prevalence of wrong items (47/2385 versus 498/1046, p<0.0001 in PVT literatures; 30/3263 versus 778/1790, p<0.0001 in BCS literatures). Most of wrong items originated from EMBASE database.  Conclusion Given the inadequacy of a single strategy of auto-searching method, a combined strategy of auto- and hand-searching methods should be employed to find duplicates in systematic review.},
  doi       = {10.1371/journal.pone.0071838},
  file      = {:Qi2013 - Find Duplicates among the PubMed, EMBASE, and Cochrane Library Databases in Systematic Review.pdf:PDF},
  fjournal  = {PloS one},
  publisher = {Public Library of Science},
}

@Article{Ding2020,
  author   = {Ding, Ding and Nguyen, Binh and Gebel, Klaus and Bauman, Adrian and Bero, Lisa},
  journal  = {Int J Epidemiol},
  title    = {{Duplicate and salami publication: a prevalence study of journal policies}},
  year     = {2020},
  issn     = {0300-5771},
  month    = feb,
  number   = {1},
  pages    = {281--288},
  volume   = {49},
  abstract = {{Duplicate and salami publication are unethical, but are common practices with substantial consequences for science and society at large. Scientific journals are the ‘gatekeepers’ of the publication process. We investigated journal policies on duplicate and salami publication.In 2018, we performed a content analysis of policies of journals in the disciplines of ‘epidemiology and public health’ and ‘general and internal medicine’. Journal policies were searched, extracted, coded and cross-checked. The associations of disciplinary categories and journal impact factors with journal policies were examined using Poisson regression models with a robust error variance.A total of 209 journals, including 122 in epidemiology and public health and 87 in general and internal medicine, were sampled and their policies investigated. Overall, 18\\% of journals did not have any policies on either practice, 33\\% only referred to a generic guideline or checklist without explicit mention about either practice, 36\\% included policies on duplicate publication and only 13\\% included policies on both duplicate and salami publication. Having explicit journal policies did not differ by journal disciplinary categories (epidemiology and public health vs general and internal medicine) or impact factors. Further analysis of journals with explicit policies found that although duplicate publication is universally discouraged, policies on salami publication are inconsistent and lack specific definitions of inappropriate divisions of papers.Gaps exist in journal policies on duplicate and salami publication, characterized by an overall lack of explicit policies, inconsistency and confusion in definitions of bad practices, and lack of clearly defined consequences for non-compliance. Scientific publication and the academic reward systems must evolve to credit good research practice.}},
  doi      = {10.1093/ije/dyz187},
  file     = {:Ding2019 - Duplicate and Salami Publication_ a Prevalence Study of Journal Policies.pdf:PDF},
}

@Article{Kastner2009,
  author   = {Monika Kastner and Nancy L. Wilczynski and Ann K. McKibbon and Amit X. Garg and R. Brian Haynes},
  journal  = {J Clin Epidemiol},
  title    = {{Diagnostic test systematic reviews: Bibliographic search filters (“Clinical Queries”) for diagnostic accuracy studies perform well}},
  year     = {2009},
  issn     = {0895-4356},
  month    = sep,
  number   = {9},
  pages    = {974--981},
  volume   = {62},
  abstract = {Background
Systematic reviews of health care topics are valuable summaries of all pertinent studies on focused questions. However, finding all relevant primary studies for systematic reviews remains challenging.
Objectives
To determine the performance of the Clinical Queries sensitive search filter for diagnostic accuracy studies for retrieving studies for systematic reviews.
Methods
We compared the yield of the sensitive Clinical Queries diagnosis search filter for MEDLINE and EMBASE to retrieve studies in diagnostic accuracy systematic reviews reported in ACP Journal Club in 2006.
Results
Twelve of 22 diagnostic accuracy reviews (452 included studies) met the inclusion criteria. After excluding 11 studies not in MEDLINE or EMBASE, 95% of articles (417 of 441) were captured by the sensitive Clinical Queries diagnosis search filter (MEDLINE and EMBASE combined). Of 24 studies not retrieved by the filter, 22 were not diagnostic accuracy studies. Reanalysis of the Clinical Queries filter without these 22 nondiagnosis articles increased its performance to 99% (417 of 419). We found no substantive impact of the two articles missed by the Clinical Queries filter on the conclusions of the systematic reviews in which they were cited.
Conclusion
The sensitive Clinical Queries diagnostic search filter captured 99% of articles and 100% of substantive articles indexed in MEDLINE and EMBASE in diagnostic accuracy systematic reviews.},
  doi      = {10.1016/j.jclinepi.2008.11.006},
  file     = {:Kastner2009 - Diagnostic Test Systematic Reviews_ Bibliographic Search Filters (“Clinical Queries”) for Diagnostic Accuracy Studies Perform Well.pdf:PDF},
  keywords = {Information retrieval, Medical informatics, Systematic review, Diagnosis, Meta-analysis, Databases, bibliographic},
  url      = {https://www.sciencedirect.com/science/article/pii/S089543560800317X},
}

@Misc{rethlefsen_page_2021,
  author    = {Rethlefsen, Melissa and Page, Matthew J.},
  month     = nov,
  title     = {{PRISMA 2020 and PRISMA-S: Common Questions on Tracking Records and the Flow Diagram}},
  year      = {2021},
  doi       = {10.31222/osf.io/439ju},
  file      = {:rethlefsen_page_2021 - PRISMA 2020 and PRISMA S_ Common Questions on Tracking Records and the Flow Diagram.docx:Word 2007+},
  publisher = {MetaArXiv},
  url       = {https://osf.io/preprints/metaarxiv/439ju},
}

@Article{Page2021b,
  author       = {Page, Matthew J. and Moher, David and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and McKenzie, Joanne E.},
  journal      = {BMJ},
  title        = {{PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews}},
  year         = {2021},
  volume       = {372},
  doi          = {10.1136/bmj.n160},
  elocation-id = {n160},
  file         = {:Page2021b - PRISMA 2020 Explanation and Elaboration_ Updated Guidance and Exemplars for Reporting Systematic Reviews.pdf:PDF},
  publisher    = {BMJ Publishing Group Ltd},
  url          = {https://www.bmj.com/content/372/bmj.n160},
}

@Article{Moore,
  author   = {Moore, Robert Andrew and Fisher, Emma and Eccleston, Christopher},
  journal  = {Eur J Pain},
  title    = {Systematic reviews do not (yet) represent the ‘gold standard’ of evidence: A position paper},
  year     = {2022},
  abstract = {Abstract The low quality of included trials, insufficient rigour in review methodology, ignorance of key pain issues, small size, and over-optimistic judgements about the direction and magnitude of treatment effects all devalue systematic reviews, supposedly the ‘gold standard’ of evidence. Available evidence indicates that almost all systematic reviews in the published literature contain fatal flaws likely to make their conclusions incorrect and misleading. Only 3 in every 100 systematic reviews are deemed to have adequate methods and be clinically useful. Examples of research waste and questionable ethical standards abound: most trials have little hope of providing useful results, and systematic review of hopeless trials inspires no confidence. We argue that results of most systematic reviews should be dismissed. Forensically critical systematic reviews are essential tools to improve the quality of trials and should be encouraged and protected.},
  doi      = {10.1002/ejp.1905},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejp.1905},
  file     = {:Moore - Systematic Reviews Do Not (yet) Represent the ‘gold Standard’ of Evidence_ a Position Paper.pdf:PDF},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ejp.1905},
}

@Article{Heath,
  author   = {Heath, Andrea and Levay, Paul and Tuvey, Daniel},
  journal  = {Health Info Libr J},
  title    = {Literature searching methods or guidance and their application to public health topics: A narrative review},
  year     = {2021},
  abstract = {Abstract Background Information specialists conducting searches for systematic reviews need to consider key questions around which and how many sources to search. This is particularly important for public health topics where evidence may be found in diverse sources. Objectives The objective of this review is to give an overview of recent studies on information retrieval guidance and methods that could be applied to public health evidence and used to guide future searches. Methods A literature search was performed in core databases and supplemented by browsing health information journals and citation searching. Results were sifted and reviewed. Results Seventy-two papers were found and grouped into themes covering sources and search techniques. Public health topics were poorly covered in this literature. Discussion Many researchers follow the recommendations to search multiple databases. The review topic influences decisions about sources. Additional sources covering grey literature eliminate bias but are time-consuming and difficult to search systematically. Public health searching is complex, often requiring searches in multidisciplinary sources and using additional methods. Conclusions Search planning is advisable to enable decisions about which and how many sources to search. This could improve with more work on modelling search scenarios, particularly in public health topics, to examine where publications were found and guide future research.},
  doi      = {10.1111/hir.12414},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/hir.12414},
  file     = {:Heath - Literature Searching Methods or Guidance and Their Application to Public Health Topics_ a Narrative Review.pdf:PDF},
  keywords = {bibliographic databases, database searching, grey literature, information sources, information storage and retrieval, knowledge synthesis, literature searching, public health, supplementary searching, web sites},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/hir.12414},
}

@Article{SalvadorOlivan2021,
  author    = {Salvador-Oliván, José Antonio and Marco-Cuenca, Gonzalo and Arquero-Avilés, Rosario},
  journal   = {J Med Libr Assoc},
  title     = {{Development of an efficient search filter to retrieve systematic reviews from PubMed}},
  year      = {2021},
  issn      = {1558-9439},
  number    = {4},
  volume    = {109},
  doi       = {10.5195/jmla.2021.1223},
  file      = {:SalvadorOlivan2021 - Development of an Efficient Search Filter to Retrieve Systematic Reviews from PubMed.pdf:PDF;:SalvadorOlivan2021 - Development of an Efficient Search Filter to Retrieve Systematic Reviews from PubMed.docx:Word 2007+;:1223-Research Materials-10751-1-10-20210426.docx:Word 2007+;:1223-Research Materials-10752-1-10-20210426.docx:Word 2007+;:SalvadorOlivan2021 - Development of an Efficient Search Filter to Retrieve Systematic Reviews from PubMed.xlsx:Excel 2007+;:1223-Research Materials-10749-1-10-20210426.xlsx:Excel 2007+},
  publisher = {Journal of the Medical Library Association},
}

@Article{Mierden2021,
  author    = {van der Mierden, Stevie and Hooijmans, Carlijn R. and Tillema, Alice H. J. and Rehn, Simone and Bleich, André and Leenaars, Cathalijn H. C.},
  journal   = {Lab Anim},
  publisher = {SAGE Publications},
  title     = {{Laboratory animals search filter for different literature databases: PubMed, Embase, Web of Science and PsycINFO}},
  year      = {2021},
  issn      = {0023-6772},
  month     = sep,
  note      = {PMID: 34559023},
  abstract  = {Systematic reviews are important tools in animal research, but the ever-increasing number of studies makes retrieval of all relevant publications challenging. Search filters aid in retrieving as many animal studies as possible. In this paper we provide updated and expanded versions of the SYRCLE animal filters for PubMed and Embase. We provide the Embase filter for both Embase.com and via Ovid. Furthermore, we provide new animal search filters for Web of Science (WoS) and APA PsycINFO via psycnet.apa.org and via Ovid. Compared with previous versions, the new filters retrieved 0.5–47.1\% (19 references for PubMed, 837 for WoS) more references in a real-life example. All filters retrieved additional references, comprising multiple relevant reviews. A random sample from WoS found at least one potentially relevant primary study. These animal search filters facilitate identifying as many animal studies as possible while minimising the number of non-animal studies.},
  doi       = {10.1177/00236772211045485},
  file      = {:Mierden2021 - Laboratory Animals Search Filter for Different Literature Databases_ PubMed, Embase, Web of Science and PsycINFO.pdf:PDF},
}

@Book{ORegan2012,
  author    = {Gerard O'Regan},
  publisher = {Springer, London},
  title     = {{A Brief History of Computing}},
  year      = {2012},
  edition   = {Second},
  isbn      = {978-1-4471-2359-0},
  doi       = {10.1007/978-1-4471-2359-0},
  file      = {:ORegan2012 - A Brief History of Computing.pdf:PDF},
  keywords  = {History of Computing, general Popular Science, History of Science},
  pagetotal = {264},
}

@Article{Pitkin1998,
  author   = {Pitkin, Roy M. and Branagan, Mary Ann},
  journal  = {JAMA},
  title    = {{Can the Accuracy of Abstracts Be Improved by Providing Specific Instructions? A Randomized Controlled Trial}},
  year     = {1998},
  issn     = {0098-7484},
  month    = jul,
  number   = {3},
  pages    = {267--269},
  volume   = {280},
  abstract = {{Context.—The most-read section of a research article is the abstract, and therefore
it is especially important that the abstract be accurate.Objective.—To test the hypothesis that providing authors with specific instructions
about abstract accuracy will result in improved accuracy.Design.—Randomized controlled trial of an educational intervention specifying
3 types of common defects in abstracts of articles that had been reviewed
and were being returned to the authors with an invitation to revise.Mean Outcome Measure.—Proportion of abstracts containing 1 or more of the following defects:
inconsistency in data between abstract and body of manuscript (text, tables,
and figures), data or other information given in abstract but not in body,
and/or conclusions not justified by information in the abstract.Results.—Of 250 manuscripts randomized, 13 were never revised and 34 were lost
to follow-up, leaving a final comparison between 89 in the intervention group
and 114 in the control group. Abstracts were defective in 25 (28\\%) and 30
(26\\%) cases, respectively (P=.78). Among 55 defective
abstracts, 28 (51\\%) had inconsistencies, 16 (29\\%) contained data not present
in the body, 8 (15\\%) had both types of defects, and 3 (5\\%) contained unjustified
conclusions.Conclusions.—Defects in abstracts, particularly inconsistencies between abstract
and body and the presentation of data in abstract but not in body, occur frequently.
Specific instructions to authors who are revising their manuscripts are ineffective
in lowering this rate. Journals should include in their editing processes
specific and detailed attention to abstracts.}},
  doi      = {10.1001/jama.280.3.267},
  file     = {:Pitkin1998 - Can the Accuracy of Abstracts Be Improved by Providing Specific Instructions_ a Randomized Controlled Trial.pdf:PDF},
}

@Article{Cals2013,
  author  = {Cals, Jochen W. L. and Kotz, Daniel},
  journal = {J Clin Epidemiol},
  title   = {{Effective writing and publishing scientific papers, part II: title and abstract}},
  year    = {2013},
  issn    = {0895-4356},
  month   = jun,
  number  = {6},
  pages   = {585},
  volume  = {66},
  doi     = {10.1016/j.jclinepi.2013.01.005},
  file    = {:Cals2013 - Effective Writing and Publishing Scientific Papers, Part II_ Title and Abstract.pdf:PDF},
  url     = {https://www.sciencedirect.com/science/article/pii/S0895435613000218},
}

@Article{Wanner2019,
  author   = {Wanner, Amanda and Baumann, Niki},
  journal  = {Res Syn Meth},
  title    = {{Design and implementation of a tool for conversion of search strategies between PubMed and Ovid MEDLINE}},
  year     = {2019},
  number   = {2},
  pages    = {154--160},
  volume   = {10},
  abstract = {Background Both PubMed and Ovid MEDLINE contain records from the MEDLINE database. However, there are subtle differences in content, functionality, and search syntax between the two. There are many instances in which researchers may wish to search both interfaces, such as when conducting supplementary searching for a systematic review to retrieve a unique content from PubMed or when using a previously published search strategy from a different interface, but little guidance on how to best conduct these searches. The aim of this project is to describe differences in search functionality between Ovid MEDLINE and PubMed, provide guidance for converting search strategies between the two, and develop an easy-to-use, freely available web-based tool to automate search syntax translations. Case presentation In this paper, we present a custom-built freely available online tool, Medline Transpose, to streamline the process of converting search strategies between Ovid MEDLINE and PubMed. With this tool, users can paste a strategy formatted for one interface into the search box and immediately retrieve an output formatted for use in the other interface, with recommendations for changes that users can make to the strategy where an exact translation does not exist. Conclusion This novel approach has the potential to reduce time and errors that database users spend translating search strategies.},
  doi      = {10.1002/jrsm.1314},
  file     = {:Wanner2019 - Design and Implementation of a Tool for Conversion of Search Strategies between PubMed and Ovid MEDLINE.pdf:PDF},
  keywords = {bibliographic databases, information science, information storage and retrieval, literature searching, MEDLINE, PubMed, software tool, systematic review},
}

@Article{Neveol2010,
  author    = {Névéol, Aurélie and Doğan, Rezarta Islamaj and Lu, Zhiyong},
  journal   = {AMIA Annu Symp Proc},
  title     = {{Author Keywords in Biomedical Journal Articles}},
  year      = {2010},
  issn      = {1942-597X},
  month     = nov,
  note      = {PMID: 21347036},
  pages     = {537--541},
  volume    = {2010},
  abstract  = {As an information retrieval system, PubMed(®) aims at providing efficient access to documents cited in MEDLINE(®). For this purpose, it relies on matching representations of documents, as provided by authors and indexers to user queries. In this paper, we describe the growth of author keywords in biomedical journal articles and present a comparative study of author keywords and MeSH(®) indexing terms assigned by MEDLINE indexers to PubMed Central Open Access articles. A similarity metric is used to assess automatically the relatedness between pairs of author keywords and indexing terms. A set of 300 pairs is manually reviewed to evaluate the metric and characterize the relationships between author keywords and indexing terms. Results show that author keywords are increasingly available in biomedical articles and that over 60% of author keywords can be linked to a closely related indexing term. Finally, we discuss the potential impact of this work on indexing and terminology development.},
  comment   = {21347036[pmid]
PMC3041277[pmcid]},
  database  = {PubMed},
  eprint    = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041277/},
  file      = {:Neveol2010 - Author Keywords in Biomedical Journal Articles.pdf:PDF},
  keywords  = {Humans, *MEDLINE, *Medical Subject Headings, PubMed},
  language  = {eng},
  publisher = {American Medical Informatics Association},
  url       = {https://pubmed.ncbi.nlm.nih.gov/21347036/},
}

@Book{Suber2012,
  author    = {Suber, Peter},
  publisher = {The MIT Press},
  title     = {{Open Access}},
  year      = {2012},
  address   = {Cambridge, Massachusetts},
  isbn      = {978-0-262-51763-8},
  series    = {The MIT Press Essential Knowledge series},
  eprint    = {https://openaccesseks.mitpress.mit.edu},
  file      = {:Suber2012 - Open Access.pdf:PDF;:Suber2012 - Open Access.epub:ePUB},
  keywords  = {Open Access Publishing},
  url       = {http://archive.org/stream/9780262517638OpenAccess/9780262517638_Open_Access},
}

@Misc{oakampbrosch2020,
  author       = {swissuniversities},
  howpublished = {Kampagnenbroschüre},
  month        = apr,
  title        = {{Open Access -- Wissen für alle}},
  year         = {2020},
  comment      = {https://www.swissuniversities.ch/fileadmin/swissuniversities/Dokumente/Hochschulpolitik/Open_Access/2020_Kampagne/OA_Kamp_Brosch_A5_Version_04_20_DE_DS.pdf},
  eprint       = {https://www.swissuniversities.ch/open-access},
  file         = {:oakampbrosch2020 - Open Access Wissen Für Alle.pdf:PDF},
}

@Article{De2019,
  author  = {De, Dipankar and Singh, Sanjay},
  journal = {Indian Dermatol Online J},
  title   = {{Basic understanding of study types and formulating research question for a clinical trial}},
  year    = {2019},
  issn    = {2249-5673},
  number  = {3},
  pages   = {351--353},
  volume  = {10},
  doi     = {10.4103/idoj.IDOJ_56_19},
  file    = {:De2019 - Basic Understanding of Study Types and Formulating Research Question for a Clinical Trial.pdf:PDF},
}

@InCollection{Mark2018,
  author    = {Daniel B. Mark and John B. Wong},
  booktitle = {{Harrison's Principles of Internal Medicine, 20e}},
  publisher = {McGraw Hill},
  title     = {{Chapter 3: Decision-Making in Clinical Medicine}},
  year      = {2018},
  address   = {New York, NY},
  editor    = {Jameson, J. Larry and Fauci, Anthony S. and Kasper, Dennis L. and Hauser, Stephen L. and Longo, Dan L. and Loscalzo, Joseph},
  isbn      = {978-1-259-64403-0},
  eprint    = {https://accessmedicine.mhmedical.com/content.aspx?aid=1155940793},
  file      = {:Mark2018 - Decision Making in Clinical Medicine.pdf:PDF},
}

@Misc{rfc3986,
  author       = {Tim Berners-Lee and Roy T. Fielding and Larry M. Masinter},
  howpublished = {RFC 3986},
  month        = jan,
  title        = {{Uniform Resource Identifier (URI): Generic Syntax}},
  year         = {2005},
  abstract     = {A Uniform Resource Identifier (URI) is a compact sequence of characters that identifies an abstract or physical resource. This specification defines the generic URI syntax and a process for resolving URI references that might be in relative form, along with guidelines and security considerations for the use of URIs on the Internet. The URI syntax defines a grammar that is a superset of all valid URIs, allowing an implementation to parse the common components of a URI reference without knowing the scheme-specific requirements of every possible identifier. This specification does not define a generative grammar for URIs; that task is performed by the individual specifications of each URI scheme. {[}STANDARDS-TRACK{]}},
  doi          = {10.17487/RFC3986},
  file         = {:rfc3986 - Uniform Resource Identifier (URI)_ Generic Syntax.txt:Text;:rfc3986 - Uniform Resource Identifier (URI)_ Generic Syntax.pdf:PDF},
  number       = {3986},
  pagetotal    = {61},
  publisher    = {RFC Editor},
  series       = {Request for Comments},
  url          = {https://www.rfc-editor.org/info/rfc3986},
}

@Misc{rfc8141,
  author       = {Peter Saint-Andre and Dr. John C. Klensin},
  howpublished = {RFC 8141},
  month        = apr,
  title        = {{Uniform Resource Names (URNs)}},
  year         = {2017},
  abstract     = {A Uniform Resource Name (URN) is a Uniform Resource Identifier (URI) that is assigned under the "urn" URI scheme and a particular URN namespace, with the intent that the URN will be a persistent, location-independent resource identifier. With regard to URN syntax, this document defines the canonical syntax for URNs (in a way that is consistent with URI syntax), specifies methods for determining URN-equivalence, and discusses URI conformance. With regard to URN namespaces, this document specifies a method for defining a URN namespace and associating it with a namespace identifier, and it describes procedures for registering namespace identifiers with the Internet Assigned Numbers Authority (IANA). This document obsoletes both RFCs 2141 and 3406.},
  doi          = {10.17487/RFC8141},
  file         = {:rfc8141 - Uniform Resource Names (URNs).txt:Text;:rfc8141 - Uniform Resource Names (URNs).pdf:PDF},
  number       = {8141},
  pagetotal    = {40},
  publisher    = {RFC Editor},
  series       = {Request for Comments},
  url          = {https://www.rfc-editor.org/info/rfc8141},
}

@Article{Bradley1992,
  author    = {Philip Bradley},
  journal   = {Indexer},
  title     = {Book numbering: the importance of the {ISBN}},
  year      = {1992},
  issn      = {0019-4131},
  month     = apr,
  number    = {1},
  pages     = {25--26},
  volume    = {18},
  doi       = {10.3828/indexer.1992.18.1.11},
  file      = {:Bradley1992 - Book Numbering_ the Importance of the ISBN.pdf:PDF},
  publisher = {Liverpool University Press},
}

@InCollection{White2020,
  author    = {Susan E. White},
  booktitle = {{Basic \& Clinical Biostatistics, 5e}},
  publisher = {McGraw Hill},
  title     = {{Chapter 2: Study Designs in Medical Research}},
  year      = {2020},
  address   = {New York, NY},
  editor    = {Jason Malley and Leah Carton},
  isbn      = {978-1-260-45536-6},
  eprint    = {https://accessmedicine.mhmedical.com/content.aspx?aid=1176051349},
  file      = {:White2020 - Study Designs in Medical Research.pdf:PDF},
}

@InCollection{Bigelow2013,
  author    = {Robert Bigelow},
  booktitle = {{Understanding Clinical Research}},
  publisher = {McGraw Hill},
  title     = {{Chapter 5: Introduction to Clinical Experimentation}},
  year      = {2013},
  address   = {New York, NY},
  editor    = {Lopes, Renato D. and Harrington, Robert A.},
  isbn      = {978-0-07-174678-6},
  eprint    = {https://accessmedicine.mhmedical.com/content.aspx?aid=57835465},
  file      = {:Bigelow2013 - Understanding Clinical Research.pdf:PDF},
}







@Article{Akers2016,
  author    = {Katherine G. Akers and Alexandra Sarkozy and Wendy Wu and Alison Slyman},
  journal   = {Med Ref Serv Q},
  title     = {{ORCID Author Identifiers: A Primer for Librarians}},
  year      = {2016},
  number    = {2},
  pages     = {135--144},
  volume    = {35},
  abstract  = {ABSTRACTThe ORCID (Open Researcher and Contributor ID) registry helps disambiguate authors and streamline research workflows by assigning unique 16-digit author identifiers that enable automatic linkages between researchers and their scholarly activities. This article describes how ORCID works, the benefits of using ORCID, and how librarians can promote ORCID at their institutions by raising awareness of ORCID, helping researchers create and populate ORCID profiles, and integrating ORCID identifiers into institutional repositories and other university research information systems.},
  comment   = {PMID: 27054531},
  doi       = {10.1080/02763869.2016.1152139},
  file      = {:Akers2016 - ORCID Author Identifiers_ a Primer for Librarians.pdf:PDF},
  publisher = {Routledge},
}

@Article{Cress2019,
  author   = {Cress, Phaedra E.},
  journal  = {Aesthet Surg J},
  title    = {{Why Do Academic Authors Need an ORCID ID?}},
  year     = {2019},
  issn     = {1090-820X},
  month    = feb,
  number   = {6},
  pages    = {696--697},
  volume   = {39},
  abstract = {{Publishing an article in an academic, peer-reviewed journal is no small feat. Promoting it and making it more discoverable can be equally hard. But what if readers can’t find your work or mistake you for someone with a similar name? What if a university, grant funder, or potential employer wants to see your full listing of publications—how do you share that information quickly?Open Researcher and Contributor ID (ORCID) is a global registry of author and researcher identifiers created through a global effort by publishers, researchers, research institutions, and funders. By signing up, authors create a unique, lifelong ORCID identifier that helps simplify research workflows, resolves name ambiguity (eg, married vs maiden names or similarly spelled names and initials), and ensures accurate research attribution which may help strengthen recognition and credibility within the community. Since the ID is persistent, it is immune to employment changes; all past publications remain permanently linked to the ID.}},
  doi      = {10.1093/asj/sjz042},
  file     = {:Cress2019 - Why Do Academic Authors Need an ORCID ID_.pdf:PDF},
}

@Article{Buchanan2021,
  author  = {Buchanan, Helen and Grimmer, Karen},
  journal = {Syst Rev},
  title   = {Keyword parsimony--lessons from a scoping review},
  year    = {2021},
  issn    = {2046-4053},
  number  = {1},
  pages   = {230},
  volume  = {10},
  doi     = {10.1186/s13643-021-01784-5},
  file    = {:Buchanan2021 - Keyword Parsimony Lessons from a Scoping Review.pdf:PDF},
  refid   = {Buchanan2021},
}

@Book{Gough2017,
  author    = {Gough, David and Oliver, Sandy and Thomas, James},
  publisher = {SAGE Publications},
  title     = {{An Introduction to Systematic Reviews}},
  year      = {2017},
  address   = {London},
  edition   = {Second},
  isbn      = {978-1-4739-2942-5},
  abstract  = {"Focused on actively using systematic review as method, An introduction to systematic reviews provides clear, step-by-step advice on the logic and processes of systematic reviewing. Stressing the importance of precision and accuracy, this practical text carefully balances a need for insightful theory with real-world pragmatism. The second edition features a new chapter on statistical synthesis and introduces a wide range of cutting-edge approaches to research synthesis, including text mining, living reviews, and new ideas in mixed methods reviews, such as qualitative comparative analysis."--Publisher's description},
  comment   = {Includes bibliographical references (pages [297]-322) and index},
  copyright = {OCoLC 20190523 Réutilisation sous conditions: Licence ODC-BY},
  eprint    = {https://swisscovery.slsp.ch/permalink/41SLSP_UBE/17e6d97/alma99116770158205511},
  keywords  = {Forschungsdaten, Datenanalyse, Sekundäranalyse, Methodologie, Sozialwissenschaften, Social sciences -- Research -- Methodology, Social sciences -- Research -- Evaluation, Research -- Methodology, Entscheidungsfindung, Evaluation, Evidenz, Forschung, Informationsmanagement, Wissensmanagement, Research, Decision making, INFORMATIONS- UND LITERATURRECHERCHEN (WISSENSCHAFTLICHE ARBEITSTECHNIK), REZENSIONEN TECHNISCH-NATURWISSENSCHAFTLICHER PUBLIKATIONEN (DOKUMENTENTYP), TECHNIKEN DES WISSENSCHAFTLICHEN ARBEITENS, WISSENSCHAFTLICHES SCHREIBEN (ARBEITSTECHNIK)},
}

@Article{Moher2003,
  author             = {Moher, D. and Pham, B. and Lawson, M. L. and Klassen, T. P.},
  journal            = {Health Technol Assess},
  title              = {{The inclusion of reports of randomised trials published in languages other than English in systematic reviews.}},
  year               = {2003},
  pages              = {1--90},
  volume             = {7},
  linking-issn       = {1366-5278},
  print-issn         = {1366-5278},
  abstract           = {OBJECTIVE: To assemble a large dataset of language restricted and language inclusive systematic reviews, including both conventional medicinal (CM) and complementary and alternative medicine (CAM) interventions. To then assess the quality of these reports by considering and comparing different types of systematic reviews and their associated RCTs; CM and CAM interventions; the effect of language restrictions compared with language inclusions, and whether these results are influenced by other issues, including statistical heterogeneity and publication bias, in the systematic review process. DATA SOURCES: MEDLINE, EMBASE, the Cochrane Database of Systematic Reviews and the Centralised Information Service for Complementary Medicine. REVIEW METHODS: Three types of systematic reviews were included: language restricted; language inclusive/English language (EL) reviews that searched RCTs in languages other than English (LOE) but did not find any and, hence, could not include any, in the quantitative data synthesis; and systematic reviews that searched for RCTs in LOE and included them in the quantitative data synthesis. Fisher's exact test was applied to compare the three different types of systematic reviews with respect to their reporting characteristics and the systematic review quality assessment tool. The odds ratio of LOE trials versus EL trials was computed for each review and this information was pooled across the reviews to examine the influence that language of publication and type of intervention (CM, CAM) have on the estimates of intervention effect. Several sensitivity analyses were performed. RESULTS: The LOE RCTs were predominantly in French and German. Language inclusive/LOE systematic reviews were of the highest quality compared with the other types of reviews. The CAM reviews were of higher quality compared with the CM reviews. There were only minor differences in the quality of reports of EL RCTs compared with the eight other languages considered. However, there are inconsistent differences in the quality of LOE reports depending on the intervention type. The results, and those reported previously, suggest that excluding reports of RCTs in LOE from the analytical part of a systematic review is reasonable. Because the present research and previous efforts have not included every type of CM RCT and the resulting possibility of the uncertainty as to when bias will be present by excluding LOE, it is always prudent to perform a comprehensive search for all evidence. This result only applies to reviews investigating the benefits of CM interventions. This does not imply that systematic reviewers should neglect reports in LOE. We recommend that systematic reviewers search for reports regardless of the language. There may be merit in including them in some aspects of the review process although this decision is likely to depend on several factors, including fiscal and other resources being available. Language restrictions significantly shift the estimates of an intervention's effectiveness when the intervention is CAM. Here, excluding trials reported in LOE, compared with their inclusion, resulted in a reduced intervention effect. The present results do not appear to be influenced by statistical heterogeneity and publication bias. CONCLUSIONS: With the exception of CAM systematic reviews, the quality of recently published systematic reviews is less than optimal. Language inclusive/LOE systematic reviews appear to be a marker for a better quality systematic review. Language restrictions do not appear to bias the estimates of a conventional intervention's effectiveness. However, there is substantial bias in the results of a CAM systematic review if LOE reports are excluded from it.},
  address            = {England},
  article-doi        = {10.3310/hta7410},
  article-pii        = {96-52-99},
  completed          = {20040329},
  doi                = {10.3310/hta7410},
  file               = {:Moher2003 - The Inclusion of Reports of Randomised Trials Published in Languages Other Than English in Systematic Reviews..pdf:PDF},
  history            = {2003/12/13 05:00 [entrez]},
  issue              = {41},
  keywords           = {Complementary Therapies, Humans, *Language, *Publishing, *Randomized Controlled Trials as Topic, United Kingdom},
  language           = {eng},
  nlm-unique-id      = {9706284},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20191108},
  source             = {Health Technol Assess. 2003;7(41):1-90. doi: 10.3310/hta7410.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {Health Technol Assess},
}

@Article{Morrison2012,
  author    = {Morrison, Andra and Polisena, Julie and Husereau, Don and Moulton, Kristen and Clark, Michelle and Fiander, Michelle and Mierzwinski-Urban, Monika and Clifford, Tammy and Hutton, Brian and Rabb, Danielle and et al.},
  journal   = {Int J Technol Assess Health Care},
  title     = {{The effect of English-language restriction on systematic review-based meta-analyses: a systematic review of empirical studies}},
  year      = {2012},
  number    = {2},
  pages     = {138--144},
  volume    = {28},
  doi       = {10.1017/S0266462312000086},
  file      = {:Morrison2012 - The Effect of English Language Restriction on Systematic Review Based Meta Analyses_ a Systematic Review of Empirical Studies.pdf:PDF},
  publisher = {Cambridge University Press},
}

@Article{Lefebvre2017,
  author    = {Carol Lefebvre and Julie Glanville and Sophie Beale and Charles Boachie and Steven Duffy and Cynthia Fraser and Jenny Harbour and Rachael McCool and Lynne Smith},
  journal   = {Health Technol Assess},
  title     = {Assessing the performance of methodological search filters to improve the efficiency of evidence information retrieval: five literature reviews and a qualitative study},
  year      = {2017},
  month     = nov,
  number    = {69},
  pages     = {1--148},
  volume    = {21},
  doi       = {10.3310/hta21690},
  file      = {:Lefebvre2017 - Assessing the Performance of Methodological Search Filters to Improve the Efficiency of Evidence Information Retrieval_ Five Literature Reviews and a Qualitative Study.pdf:PDF},
  publisher = {National Institute for Health Research},
  url       = {https://doi.org/10.3310/hta21690},
}

@Article{Powers2020,
  author    = {Powers, David M. W.},
  journal   = {arXiv e-prints},
  title     = {{Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation}},
  year      = {2020},
  month     = oct,
  number    = {arXiv:2010.16061},
  comment   = {International Journal of Machine Learning Technology 2:1 (2011), pp.37-63},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2010.16061},
  file      = {:Powers2020 - Evaluation_ from Precision, Recall and F Measure to ROC, Informedness, Markedness and Correlation.pdf:PDF},
  keywords  = {Machine Learning (cs.LG), Methodology (stat.ME), Machine Learning (stat.ML), FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Fawcett2006,
  author    = {Tom Fawcett},
  journal   = {Pattern Recognit Lett},
  title     = {An introduction to {ROC} analysis},
  year      = {2006},
  month     = jun,
  number    = {8},
  pages     = {861--874},
  volume    = {27},
  abstract  = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
  doi       = {10.1016/j.patrec.2005.10.010},
  file      = {:Fawcett2006 - An Introduction to ROC Analysis.pdf:PDF},
  keywords  = {ROC analysis, Classifier evaluation, Evaluation metrics},
  publisher = {Elsevier {BV}},
}

@InCollection{Boutron2022,
  author    = {Boutron, I. and Page, M. J. and Higgins, J. P. T. and Altman, D. G. and Lundh, A. and Hróbjartsson, A.},
  booktitle = {Cochrane Handbook for Systematic Reviews of Interventions},
  publisher = {Cochrane},
  title     = {Chapter 7: Considering bias and conflicts of interest among the included studies},
  year      = {2022},
  editor    = {Higgins, J. P. T. and Thomas, J. and Chandler, J. and Cumpston, M. and Li, T. and Page, M. J. and Welch, V. A.},
  month     = feb,
  eprint    = {https://training.cochrane.org/handbook/current/chapter-07},
  file      = {:Boutron2022 - Chapter 7_ Considering Bias and Conflicts of Interest among the Included Studies.pdf:PDF},
}

@Article{OdgaardJensen2011,
  author    = {Odgaard‐Jensen, Jan and Vist, Gunn E. and Timmer, Antje and Kunz, R. and Akl, Elie A. and Schünemann, Holger and Briel, Matthias and Nordmann, Alain J. and Pregno, Silvia and Oxman, Andrew D.},
  journal   = {Cochrane Database Syst Rev},
  title     = {Randomisation to protect against selection bias in healthcare trials},
  year      = {2011},
  issn      = {1465-1858},
  note      = {Art. No.: MR000012},
  number    = {4},
  volume    = {\,},
  abstract  = {Abstract - Background Randomised trials use the play of chance to assign participants to comparison groups. The unpredictability of the process, if not subverted, should prevent systematic differences between comparison groups (selection bias). Differences due to chance will still occur and these are minimised by randomising a sufficiently large number of people. Objectives To assess the effects of randomisation and concealment of allocation on the results of healthcare studies. Search methods We searched the Cochrane Methodology Register, MEDLINE, SciSearch and reference lists up to September 2009. In addition, we screened articles citing included studies (ISI Science Citation Index) and papers related to included studies (PubMed). Selection criteria Eligible study designs were cohorts of studies, systematic reviews or meta‐analyses of healthcare interventions that compared random allocation versus non‐random allocation or adequate versus inadequate/unclear concealment of allocation in randomised trials. Outcomes of interest were the magnitude and direction of estimates of effect and imbalances in prognostic factors. Data collection and analysis We retrieved and assessed studies that appeared to meet the inclusion criteria independently. At least two review authors independently appraised methodological quality and extracted information. We prepared tabular summaries of the results for each comparison and assessed the results across studies qualitatively to identify common trends or discrepancies. Main results A total of 18 studies (systematic reviews or meta‐analyses) met our inclusion criteria. Ten compared random allocation versus non‐random allocation and nine compared adequate versus inadequate or unclear concealment of allocation within controlled trials. All studies were at high risk of bias. For the comparison of randomised versus non‐randomised studies, four comparisons yielded inconclusive results (differed between outcomes or different modes of analysis); three comparisons showed similar results for random and non‐random allocation; two comparisons had larger estimates of effect in non‐randomised studies than in randomised trials; and two comparisons had larger estimates of effect in randomised than in non‐randomised studies. Five studies found larger estimates of effect in trials with inadequate concealment of allocation than in trials with adequate concealment. The four other studies did not find statistically significant differences. Authors' conclusions The results of randomised and non‐randomised studies sometimes differed. In some instances non‐randomised studies yielded larger estimates of effect and in other instances randomised trials yielded larger estimates of effect. The results of controlled trials with adequate and inadequate/unclear concealment of allocation sometimes differed. When differences occurred, most often trials with inadequate or unclear allocation concealment yielded larger estimates of effects relative to controlled trials with adequate allocation concealment. However, it is not generally possible to predict the magnitude, or even the direction, of possible selection biases and consequent distortions of treatment effects from studies with non‐random allocation or controlled trials with inadequate or unclear allocation concealment. Plain language summary Randomised controlled trials as a safeguard against biased estimates of treatment effects Randomised controlled trials (RCTs) use the play of chance to allocate participants to comparison groups to prevent selection bias. Other means of treatment allocation are more prone to bias because decisions about which treatment to use can be influenced by the preferences of the physician or patient. This review compares random allocation (allocated to treatment using a random method) versus non‐random allocation (allocated to treatment using a non‐random method, such as alternation or external, uncontrollable factors, with no clinical judgement involved) and controlled trials with adequate versus inadequate/unclear concealment of allocation. Concealed treatment allocation is best described in general terms as the process used to prevent foreknowledge of group assignment in a controlled trial (such as the use of sequentially numbered opaque, sealed envelopes). The results of randomised and non‐randomised studies sometimes differed. Sometimes non‐randomised studies yielded larger estimates of effect, and sometimes randomised trials yielded larger estimates of effect. On the other hand, not using concealed random allocation resulted in larger estimates of effect, but sometimes it resulted in similar estimates of effect (from harmful to beneficial or vice versa). It is a paradox that the unpredictability of random allocation is the best protection against the unpredictability of the extent to which non‐randomised studies may be biased.},
  doi       = {10.1002/14651858.MR000012.pub3},
  file      = {:Odgaard‐Jensen2011 - Randomisation to Protect against Selection Bias in Healthcare Trials.pdf:PDF},
  keywords  = {*Clinical Trials as Topic [methods, standards, statistics & numerical data]; *Random Allocation; *Selection Bias; Controlled Clinical Trials as Topic [methods, statistics & numerical data]; Randomized Controlled Trials as Topic [methods, statistics & numerical data]; Treatment Outcome},
  publisher = {John Wiley & Sons, Ltd},
}

@Article{Hirt2021,
  author  = {Julian Hirt and Thomas Nordhausen and Christian Appenzeller-Herzog and Hannah Ewald},
  journal = {F1000Res},
  title   = {{Using citation tracking for systematic literature searching --~study protocol for a scoping review of methodological studies and a Delphi study}},
  year    = {2021},
  month   = sep,
  pages   = {1386},
  volume  = {9},
  doi     = {10.12688/f1000research.27337.3},
  file    = {:Hirt2021 - Using Citation Tracking for Systematic Literature Searching ~study Protocol for a Scoping Review of Methodological Studies and a Delphi Study.pdf:PDF},
}

@InCollection{McKenzie2022,
  author    = {McKenzie, J. E. and Brennan, S. E. and Ryan, R. E. and Thomson, H. J. and Johnston, R. V. and Thomas, J.},
  booktitle = {Cochrane Handbook for Systematic Reviews of Interventions},
  publisher = {Cochrane},
  title     = {Chapter 3: Defining the criteria for including studies and how they will be grouped for the synthesis.},
  year      = {2022},
  editor    = {Higgins, J. P. T. and Thomas, J. and Chandler, J. and Cumpston, M. and Li, T. and Page, M. J. and Welch, V. A.},
  month     = feb,
  eprint    = {https://training.cochrane.org/handbook/current/chapter-03},
  file      = {:McKenzie2022 - Chapter 3_ Defining the Criteria for Including Studies and How They Will Be Grouped for the Synthesis..pdf:PDF},
}

@Article{Murad2016,
  author    = {Murad, M. Hassan and Asi, Noor and Alsawas, Mouaz and Alahdab, Fares},
  journal   = {BMJ Evid Based Med},
  title     = {New evidence pyramid},
  year      = {2016},
  issn      = {1356-5524},
  number    = {4},
  pages     = {125--127},
  volume    = {21},
  doi       = {10.1136/ebmed-2016-110401},
  file      = {:Murad2016 - New Evidence Pyramid.pdf:PDF},
  publisher = {Royal Society of Medicine},
  url       = {https://ebm.bmj.com/content/21/4/125},
}

@Article{Haynes2001,
  author    = {Haynes, R. Brian},
  journal   = {BMJ Evid Based Med},
  title     = {{Of studies, syntheses, synopses, and systems: the ``4S'' evolution of services for finding current best evidence}},
  year      = {2001},
  number    = {2},
  pages     = {36--38},
  volume    = {6},
  doi       = {10.1136/ebm.6.2.36},
  file      = {:haynes2001studies - Of Studies, Syntheses, Synopses, and Systems_ the “4S” Evolution of Services for Finding Current Best Evidence.pdf:PDF},
  publisher = {Royal Society of Medicine},
}

@InCollection{Djulbegovic2015,
  author    = {Benjamin Djulbegovic and Gordon Guyatt},
  booktitle = {Users' Guides to the Medical Literature: A Manual for Evidence-Based Clinical Practice, 3rd ed},
  publisher = {McGraw-Hill Education},
  title     = {{Chapter 3: Evidence-Based Medicine and the Theory of Knowledge}},
  year      = {2015},
  address   = {New York, NY},
  editor    = {Guyatt, Gordon and Rennie, Drummond and Meade, Maureen O. and Cook, Deborah J.},
  eprint    = {https://jamaevidence.mhmedical.com/content.aspx?aid=1183875498},
  file      = {:Djulbegovic2015 - Evidence Based Medicine and the Theory of Knowledge.pdf:PDF},
}

@InCollection{Guyatt2015,
  author    = {Gordon Guyatt and Roman Jaeschke and Mark C. Wilson and Victor M. Montori and W. Scott Richardson},
  booktitle = {Users' Guides to the Medical Literature: A Manual for Evidence-Based Clinical Practice, 3rd ed},
  publisher = {McGraw-Hill Education},
  title     = {{Chapter 2: What Is Evidence-Based Medicine?}},
  year      = {2015},
  address   = {New York, NY},
  editor    = {Guyatt, Gordon and Rennie, Drummond and Meade, Maureen O. and Cook, Deborah J.},
  eprint    = {https://jamaevidence.mhmedical.com/content.aspx?aid=1183875473},
  file      = {:Guyatt2015 - Chapter 2_ What Is Evidence Based Medicine_.pdf:PDF},
}

@Article{Akobeng2005a,
  author    = {Akobeng, Anthony K.},
  journal   = {Arch Dis Child},
  title     = {Understanding randomised controlled trials},
  year      = {2005},
  issn      = {0003-9888},
  number    = {8},
  pages     = {840--844},
  volume    = {90},
  abstract  = {The hierarchy of evidence in assessing the effectiveness of interventions or treatments is explained, and the gold standard for evaluating the effectiveness of interventions, the randomised controlled trial, is discussed. Issues that need to be considered during the critical appraisal of randomised controlled trials, such as assessing the validity of trial methodology and the magnitude and precision of the treatment effect, and deciding on the applicability of research results, are discussed. Important terminologies such as randomisation, allocation concealment, blinding, intention to treat, p values, and confidence intervals are explained.},
  doi       = {10.1136/adc.2004.058222},
  file      = {:Akobeng2005a - Understanding Randomised Controlled Trials.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
  url       = {https://adc.bmj.com/content/90/8/840},
}

@Article{Alper2016,
  author    = {Alper, Brian S. and Haynes, R. Brian},
  journal   = {BMJ Evid Based Med},
  title     = {{EBHC pyramid 5.0 for accessing preappraised evidence and guidance}},
  year      = {2016},
  issn      = {1356-5524},
  number    = {4},
  pages     = {123--125},
  volume    = {21},
  doi       = {10.1136/ebmed-2016-110447},
  file      = {:Alper2016 - EBHC Pyramid 5.0 for Accessing Preappraised Evidence and Guidance.pdf:PDF},
  publisher = {Royal Society of Medicine},
  url       = {https://ebm.bmj.com/content/21/4/123},
}

@Article{Peters2015,
  author    = {Micah D. J. Peters and Christina M. Godfrey and Hanan Khalil and Patricia McInerney and Deborah Parker and Cassia Baldini Soares},
  journal   = {Int J Evid Based Healthc},
  title     = {Guidance for conducting systematic scoping reviews},
  year      = {2015},
  month     = sep,
  number    = {3},
  pages     = {141--146},
  volume    = {13},
  doi       = {10.1097/xeb.0000000000000050},
  file      = {:Peters2015 - Guidance for Conducting Systematic Scoping Reviews.pdf:PDF;:Peters2015 - Guidance for Conducting Systematic Scoping Reviews.epub:ePUB},
  publisher = {Ovid Technologies (Wolters Kluwer Health)},
}

@Article{Jenkins2004,
  author    = {Michelle Jenkins},
  journal   = {Health Info Libr J},
  title     = {Evaluation of methodological search filters--a review},
  year      = {2004},
  month     = aug,
  number    = {3},
  pages     = {148--163},
  volume    = {21},
  doi       = {10.1111/j.1471-1842.2004.00511.x},
  file      = {:Jenkins2004 - Evaluation of Methodological Search Filters a Review.pdf:PDF},
  publisher = {Wiley},
}

@Book{Moher2014,
  editor    = {David Moher and Douglas G. Altman and Kenneth F. Schulz and Iveta Simera and Elizabeth Wager},
  publisher = {John Wiley {\&} Sons, Ltd},
  title     = {{Guidelines for Reporting Health Research: A User{\textquotesingle}s Manual}},
  year      = {2014},
  month     = jul,
  doi       = {10.1002/9781118715598},
  file      = {:2014 - Guidelines for Reporting Health Research_ a User_s Manual.pdf:PDF},
  url       = {https://doi.org/10.1002/9781118715598},
}

@InCollection{Moher2014a,
  author    = {Moher, David and Altman, Douglas G. and Tetzlaff, Jennifer},
  booktitle = {Guidelines for Reporting Health Research: A User's Manual},
  publisher = {John Wiley {\&} Sons, Ltd},
  title     = {{PRISMA (Preferred ReportingItems for Systematic Reviewsand Meta-Analyses)}},
  year      = {2014},
  isbn      = {9781118715598},
  pages     = {250--261},
  abstract  = {Summary The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement is a guidance for authors reporting a systematic review and/or meta-analysis of randomized trials and other types of research designs evaluating a healthcare intervention, such as a drug, device, operative procedure, or psychological counseling. PRISMA can be used by peer reviewers and editors reviewing a submission of a systematic review and/or meta-analysis. PRISMA can also be used by readers wanting to gauge the validity of the results of systematic reviews and meta-analyses. The PRISMA statement represents an extensive update and expansion of the QUality Of Reporting Of Meta-analyses (QUOROM) statement, a guideline primarily for reporting meta-analyses of randomized trials. This chapter discusses history/development of PRISMA, when to use this guideline, current version and extensions and/or implementations of the PRISMA. It focuses on how best to use the guideline, cautions and limitations of PRISMA, and protocols of systematic reviews.},
  doi       = {10.1002/9781118715598.ch24},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118715598.ch24},
  file      = {:Moher2014a - Chapter 24.pdf:PDF},
  keywords  = {PRISMA, QUality Of Reporting Of Meta-analyses (QUOROM), randomized trials},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118715598.ch24},
}

@Article{Joore2020,
  author    = {Joore, Manuela and Grimm, Sabine and Boonen, Annelies and de Wit, Maarten and Guillemin, Francis and Fautrel, Bruno},
  journal   = {RMD open},
  title     = {Health technology assessment: a framework},
  year      = {2020},
  issn      = {2056-5933},
  month     = nov,
  number    = {33148786},
  pages     = {e001289},
  volume    = {6},
  comment   = {33148786[pmid]
PMC7856136[pmcid]},
  database  = {PubMed},
  doi       = {10.1136/rmdopen-2020-001289},
  file      = {:Joore2020 - Health Technology Assessment_ a Framework.pdf:PDF},
  keywords  = {*Economics, *Epidemiology, *Health services research, *Biomedical Technology, Humans},
  language  = {eng},
  publisher = {BMJ Publishing Group},
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7856136/},
}

@Book{WHO2011,
  author    = {{World Health Organization}},
  publisher = {World Health Organization},
  title     = {Health technology assessment of medical devices},
  year      = {2011},
  isbn      = {9789241501361},
  month     = aug,
  series    = {WHO Medical Device Technical},
  eprint    = {https://www.who.int/publications/i/item/9789241501361},
  file      = {:World_Health_Organization2012-rp - Health Technology Assessment of Medical Devices.pdf:PDF},
}

@Misc{Braun2021,
  author    = {Braun, Cordula and Schmucker, Christine and Nothacker, Monika and Nitschke, Kai and Schaefer, Corinna and Bollig, Claudia and Muche-Borowski, Cathleen and Kopp, Ina B. and Meerpohl, J\"{o}rg},
  month     = may,
  title     = {{Manual Bewertung des Biasrisikos in Interventionsstudien}},
  year      = {2021},
  comment   = {URN:nbn:de:bsz:25-freidok-1949005},
  doi       = {10.6094/UNIFR/194900},
  file      = {:Braun2021 - Manual Bewertung Des Biasrisikos in Interventionsstudien.pdf:PDF},
  keywords  = {610},
  language  = {de},
  publisher = {Albert-Ludwigs-Universit{\"a}t Freiburg},
  url       = {https://freidok.uni-freiburg.de/data/194900},
}






@Article{Watson2020,
  author   = {Watson, Mandy},
  journal  = {Br J Nurs},
  title    = {How to undertake a literature search: a step-by-step guide},
  year     = {2020},
  note     = {PMID: 32279549},
  number   = {7},
  pages    = {431--435},
  volume   = {29},
  abstract = {Undertaking a literature search can be a daunting prospect. Breaking the exercise down into smaller steps will make the process more manageable. This article suggests 10 steps that will help readers complete this task, from identifying key concepts to choosing databases for the search and saving the results and search strategy. It discusses each of the steps in a little more detail, with examples and suggestions on where to get help. This structured approach will help readers obtain a more focused set of results and, ultimately, save time and effort.},
  doi      = {10.12968/bjon.2020.29.7.431},
  file     = {:Watson2020 - How to Undertake a Literature Search_ a Step by Step Guide.pdf:PDF},
}






@Article{Key2020,
  author   = {Key, Julie},
  journal  = {Br J Nurs},
  title    = {How to undertake a literature search: enhancing your search},
  year     = {2020},
  note     = {PMID: 32324469},
  number   = {8},
  pages    = {481--483},
  volume   = {29},
  abstract = {This article follows on from a previous article on how to carry out a literature search (Watson, 2020) and looks at how you can enhance your search by going beyond journal databases to using search engines, websites and grey literature sources. Ways to evaluate the resources you find, the use of critical appraisal tools and factors to consider when presenting your results are also discussed.},
  doi      = {10.12968/bjon.2020.29.8.481},
  file     = {:Key2020 - How to Undertake a Literature Search_ Enhancing Your Search.pdf:PDF},
}

@Book{Petticrew2006,
  author    = {Mark Petticrew and Helen Roberts},
  publisher = {Blackwell Publishing Ltd},
  title     = {{Systematic Reviews in the Social Sciences}},
  year      = {2006},
  isbn      = {9780470754887},
  month     = jan,
  doi       = {10.1002/9780470754887},
  file      = {:Petticrew2006 - Systematic Reviews in the Social Sciences.pdf:PDF},
}

@Article{Cooper2018,
  author   = {Cooper, Chris and Booth, Andrew and Varley-Campbell, Jo and Britten, Nicky and Garside, Ruth},
  journal  = {BMC Med Res Methodol},
  title    = {Defining the process to literature searching in systematic reviews: a literature review of guidance and supporting studies},
  year     = {2018},
  issn     = {1471-2288},
  number   = {1},
  pages    = {85},
  volume   = {18},
  abstract = {Systematic literature searching is recognised as a critical component of the systematic review process. It involves a systematic search for studies and aims for a transparent report of study identification, leaving readers clear about what was done to identify studies, and how the findings of the review are situated in the relevant evidence.},
  doi      = {10.1186/s12874-018-0545-3},
  file     = {:Cooper2018 - Defining the Process to Literature Searching in Systematic Reviews_ a Literature Review of Guidance and Supporting Studies.pdf:PDF},
  refid    = {Cooper2018},
}

@Book{Noble2018,
  author      = {Safiya Umoja Noble},
  publisher   = {New York University Press},
  title       = {{Algorithms of Oppression: How Search Engines Reinforce Racism}},
  year        = {2018},
  isbn        = {9781479833641},
  doi         = {10.18574/9781479833641},
  file        = {:Noble2018 - Algorithms of Oppression_ How Search Engines Reinforce Racism.pdf:PDF},
  lastchecked = {2022-06-07},
}

@Article{Grames2019,
  author   = {Grames, Eliza M. and Stillman, Andrew N. and Tingley, Morgan W. and Elphick, Chris S.},
  journal  = {Methods Ecol Evol},
  title    = {An automated approach to identifying search terms for systematic reviews using keyword co-occurrence networks},
  year     = {2019},
  number   = {10},
  pages    = {1645--1654},
  volume   = {10},
  abstract = {Abstract Systematic review, meta-analysis and other forms of evidence synthesis are critical to strengthen the evidence base concerning conservation issues and to answer ecological and evolutionary questions. Synthesis lags behind the pace of scientific publishing, however, due to time and resource costs which partial automation of evidence synthesis tasks could reduce. Additionally, current methods of retrieving evidence for synthesis are susceptible to bias towards studies with which researchers are familiar. In fields that lack standardized terminology encoded in an ontology, including ecology and evolution, research teams can unintentionally exclude articles from the review by omitting synonymous phrases in their search terms. To combat these problems, we developed a quick, objective, reproducible method for generating search strategies that uses text mining and keyword co-occurrence networks to identify the most important terms for a review. The method reduces bias in search strategy development because it does not rely on a predetermined set of articles and can improve search recall by identifying synonymous terms that research teams might otherwise omit. When tested against the search strategies used in published environmental systematic reviews, our method performs as well as the published searches and retrieves gold-standard hits that replicated versions of the original searches do not. Because the method is quasi-automated, the amount of time required to develop a search strategy, conduct searches, and assemble results is reduced from approximately 17–34 hr to under 2 hr. To facilitate use of the method for environmental evidence synthesis, we implemented the method in the R package litsearchr, which also contains a suite of functions to improve efficiency of systematic reviews by automatically deduplicating and assembling results from separate databases.},
  doi      = {10.1111/2041-210X.13268},
  file     = {:Grames2019 - An Automated Approach to Identifying Search Terms for Systematic Reviews Using Keyword Co Occurrence Networks.pdf:PDF},
  keywords = {evidence synthesis, keyword co-occurrence network, keyword identification, literature review, meta-analysis, systematic review, text mining},
}

@Article{Vladut2022,
  author   = {Vlăduț, Cătălina and Heinrich, Henriette},
  journal  = {United European Gastroenterol J},
  title    = {{Young GI angle: How to recognize a predatory journal}},
  year     = {2022},
  number   = {1},
  pages    = {130--133},
  volume   = {10},
  doi      = {10.1002/ueg2.12198},
  file     = {:Vladut2022 - Young GI Angle_ How to Recognize a Predatory Journal.pdf:PDF},
  keywords = {journal, open access, predatory, publish},
}

@Article{Smalheiser2022,
  author    = {Neil R. Smalheiser and Jodi Schneider and Vetle I. Torvik and Dean P. Fragnito and Eric E. Tirk},
  journal   = {J Med Libr Assoc},
  title     = {{The Citation Cloud of a biomedical article: a free, public, web-based tool enabling citation analysis}},
  year      = {2022},
  month     = jan,
  number    = {1},
  pages     = {103--108},
  volume    = {110},
  doi       = {10.5195/jmla.2022.1117},
  file      = {:Smalheiser2022 - The Citation Cloud of a Biomedical Article_ a Free, Public, Web Based Tool Enabling Citation Analysis.pdf:PDF;:Smalheiser2022 - The Citation Cloud of a Biomedical Article_ a Free, Public, Web Based Tool Enabling Citation Analysis.docx:Word 2007+},
  publisher = {University Library System, University of Pittsburgh},
}

@Article{Janssens2020,
  author   = {Janssens, A. Cecile J. W. and Gwinn, Marta and Brockman, J. Elaine and Powell, Kimberley and Goodman, Michael},
  journal  = {BMC Med Res Methodol},
  title    = {{Novel citation-based search method for scientific literature: a validation study}},
  year     = {2020},
  issn     = {1471-2288},
  month    = feb,
  number   = {1},
  pages    = {25},
  volume   = {20},
  abstract = {We recently developed CoCites, a citation-based search method that is designed to be more efficient than traditional keyword-based methods. The method begins with identification of one or more highly relevant publications (query articles) and consists of two searches: the co-citation search, which ranks publications on their co-citation frequency with the query articles, and the citation search, which ranks publications on frequency of all citations that cite or are cited by the query articles.},
  doi      = {10.1186/s12874-020-0907-5},
  file     = {:Janssens2020 - Novel Citation Based Search Method for Scientific Literature_ a Validation Study.pdf:PDF},
  refid    = {Janssens2020},
}

@Article{Clark2020,
  author    = {Justin Michael Clark and Sharon Sanders and Matthew Carter and David Honeyman and Gina Cleo and Yvonne Auld and Debbie Booth and Patrick Condron and Christine Dalais and Sarah Bateup and Bronwyn Linthwaite and Nikki May and Jo Munn and Lindy Ramsay and Kirsty Rickett and Cameron Rutter and Angela Smith and Peter Sondergeld and Margie Wallin and Mark Jones and Elaine Beller},
  journal   = {J Med Libr Assoc},
  title     = {{Improving the translation of search strategies using the Polyglot Search Translator: a randomized controlled trial}},
  year      = {2020},
  month     = apr,
  number    = {2},
  pages     = {195--207},
  volume    = {108},
  doi       = {10.5195/jmla.2020.834},
  file      = {:Clark2020 - Improving the Translation of Search Strategies Using the Polyglot Search Translator_ a Randomized Controlled Trial.pdf:PDF},
  publisher = {University Library System, University of Pittsburgh},
  url       = {https://doi.org/10.5195/jmla.2020.834},
}

@Article{Lin2007,
  author                 = {Lin, Jimmy and Wilbur, W. John},
  journal                = {BMC Bioinf},
  title                  = {{PubMed related articles: a probabilistic topic-based model for content similarity.}},
  year                   = {2007},
  month                  = oct,
  pages                  = {423},
  volume                 = {8},
  abstract               = {BACKGROUND: We present a probabilistic topic-based model for content similarity called pmra that underlies the related article search feature in PubMed. Whether or not a document is about a particular topic is computed from term frequencies, modeled as Poisson distributions. Unlike previous probabilistic retrieval models, we do not attempt to estimate relevance-but rather our focus is "relatedness", the probability that a user would want to examine a particular document given known interest in another. We also describe a novel technique for estimating parameters that does not require human relevance judgments; instead, the process is based on the existence of MeSH in MEDLINE. RESULTS: The pmra retrieval model was compared against bm25, a competitive probabilistic model that shares theoretical similarities. Experiments using the test collection from the TREC 2005 genomics track shows a small but statistically significant improvement of pmra over bm25 in terms of precision. CONCLUSION: Our experiments suggest that the pmra model provides an effective ranking algorithm for related article search.},
  article-doi            = {10.1186/1471-2105-8-423},
  article-pii            = {1471-2105-8-423},
  completed              = {20080211},
  doi                    = {10.1186/1471-2105-8-423},
  electronic-issn        = {1471-2105},
  electronic-publication = {20071030},
  file                   = {:Lin2007 - PubMed Related Articles_ a Probabilistic Topic Based Model for Content Similarity..pdf:PDF},
  grantno                = {Intramural NIH HHS/United States},
  history                = {2007/11/01 09:00 [entrez]},
  keywords               = {*Algorithms, Artificial Intelligence, *Bibliometrics, *Data Interpretation, Statistical, *Models, *Natural Language Processing, Periodicals as Topic/*statistics & numerical data, *PubMed, Vocabulary, Controlled},
  language               = {eng},
  linking-issn           = {1471-2105},
  nlm-unique-id          = {100965194},
  owner                  = {NLM},
  publication-status     = {epublish},
  revised                = {20211020},
  source                 = {BMC Bioinformatics. 2007 Oct 30;8:423. doi: 10.1186/1471-2105-8-423.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {BMC Bioinformatics},
}







@Article{Brunskill2020,
  author    = {Amelia Brunskill},
  journal   = {Med Ref Serv Q},
  title     = {{A Microsoft Excel Approach to Reduce Errors and Increase Efficiency in Systematic Searching}},
  year      = {2020},
  note      = {PMID: 32069194},
  number    = {1},
  pages     = {15--26},
  volume    = {39},
  abstract  = {AbstractDeveloping a search strategy for a systematic review is a time-consuming process in which small errors around the formatting and compilation of terms can have large consequences. Microsoft Excel was identified as a potentially useful software to streamline the process and reduce manual errors. Ultimately a spreadsheet was created that largely automates the process of creating a single-line search string with correctly formatted terms, Boolean operators and parentheses.},
  doi       = {10.1080/02763869.2020.1704598},
  file      = {:Brunskill2020 - A Microsoft Excel Approach to Reduce Errors and Increase Efficiency in Systematic Searching.pdf:PDF},
  publisher = {Routledge},
}

@Article{Engwall2017,
  author  = {Engwall, Keith D.},
  journal = {J Med Libr Assoc},
  title   = {{Anne O’Tate}},
  year    = {2017},
  issn    = {1536-5050},
  month   = apr,
  number  = {2},
  pages   = {200--202},
  volume  = {105},
  doi     = {10.5195/jmla.2017.92},
  file    = {:Engwall2017 - Anne O’Tate.pdf:PDF},
  url     = {https://europepmc.org/articles/PMC5370618},
}

@Article{Smalheiser2008,
  author   = {Smalheiser, Neil R. and Zhou, Wei and Torvik, Vetle I.},
  journal  = {J Biomed Discovery Collab},
  title    = {{Anne O'Tate: A tool to support user-driven summarization, drill-down and browsing of PubMed search results}},
  year     = {2008},
  issn     = {1747-5333},
  number   = {1},
  pages    = {2},
  volume   = {3},
  abstract = {PubMed is designed to provide rapid, comprehensive retrieval of papers that discuss a given topic. However, because PubMed does not organize the search output further, it is difficult for users to grasp an overview of the retrieved literature according to non-topical dimensions, to drill-down to find individual articles relevant to a particular individual's need, or to browse the collection.},
  doi      = {10.1186/1747-5333-3-2},
  file     = {:Smalheiser2008 - Anne O'Tate_ a Tool to Support User Driven Summarization, Drill down and Browsing of PubMed Search Results.pdf:PDF},
  refid    = {Smalheiser2008},
}

@Article{Smalheiser2021,
  author                 = {Smalheiser, Neil R. and Fragnito, Dean P. and Tirk, Eric E.},
  journal                = {PLoS One},
  title                  = {{Anne O'Tate: Value-added PubMed search engine for analysis and text mining.}},
  year                   = {2021},
  pages                  = {e0248335},
  volume                 = {16},
  abstract               = {Over a decade ago, we introduced Anne O'Tate, a free, public web-based tool http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi to support user-driven summarization, drill-down and mining of search results from PubMed, the leading search engine for biomedical literature. A set of hotlinked buttons allows the user to sort and rank retrieved articles according to important words in titles and abstracts; topics; author names; affiliations; journal names; publication year; and clustered by topic. Any result can be further mined by choosing any other button, and small search results can be expanded to include related articles. It has been deployed continuously, serving a wide range of biomedical users and needs, and over time has also served as a platform to support the creation of new tools that address additional needs. Here we describe the current, greatly expanded implementation of Anne O'Tate, which has added additional buttons to provide new functionalities: We now allow users to sort and rank search results by important phrases contained in titles and abstracts; the number of authors listed on the article; and pairs of topics that co-occur significantly more than chance. We also display articles according to NLM-indexed publication types, as well as according to 50 different publication types and study designs as predicted by a novel machine learning-based model. Furthermore, users can import search results into two new tools: e) Mine the Gap!, which identifies pairs of topics that are under-represented within set of the search results, and f) Citation Cloud, which for any given article, allows users to visualize the set of articles that cite it; that are cited by it; that are co-cited with it; and that are bibliographically coupled to it. We invite the scientific community to explore how Anne O'Tate can assist in analyzing biomedical literature, in a variety of use cases.},
  article-doi            = {10.1371/journal.pone.0248335},
  article-pii            = {PONE-D-20-15023},
  completed              = {20211012},
  doi                    = {10.1371/journal.pone.0248335},
  electronic-issn        = {1932-6203},
  electronic-publication = {20210308},
  file                   = {:Smalheiser2021 - Anne O'Tate_ Value Added PubMed Search Engine for Analysis and Text Mining..pdf:PDF},
  fjournal               = {PloS one},
  grantno                = {R01 LM010817/LM/NLM NIH HHS/United States},
  history                = {2021/10/13 06:00 [medline]},
  issue                  = {3},
  keywords               = {*Abstracting and Indexing, Data Mining/*trends, Humans, PubMed/*trends, *Search Engine, Software},
  language               = {eng},
  linking-issn           = {1932-6203},
  location-id            = {e0248335},
  nlm-unique-id          = {101285081},
  owner                  = {NLM},
  publication-status     = {epublish},
  revised                = {20211012},
  source                 = {PLoS One. 2021 Mar 8;16(3):e0248335. doi: 10.1371/journal.pone.0248335. eCollection 2021.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {PLoS One},
}

@Article{Haddaway2022,
  author   = {Haddaway, Neal R. and Page, Matthew J. and Pritchard, Chris C. and McGuinness, Luke A.},
  journal  = {Campbell Syst Rev},
  title    = {{PRISMA2020: An R package and Shiny app for producing PRISMA 2020-compliant flow diagrams, with interactivity for optimised digital transparency and Open Synthesis}},
  year     = {2022},
  number   = {2},
  pages    = {e1230},
  volume   = {18},
  abstract = {Abstract Background Reporting standards, such as PRISMA aim to ensure that the methods and results of systematic reviews are described in sufficient detail to allow full transparency. Flow diagrams in evidence syntheses allow the reader to rapidly understand the core procedures used in a review and examine the attrition of irrelevant records throughout the review process. Recent research suggests that use of flow diagrams in systematic reviews is poor and of low quality and called for standardised templates to facilitate better reporting in flow diagrams. The increasing options for interactivity provided by the Internet gives us an opportunity to support easy-to-use evidence synthesis tools, and here we report on the development of a tool for the production of PRISMA 2020-compliant systematic review flow diagrams. Methods and Findings We developed a free-to-use, Open Source R package and web-based Shiny app to allow users to design PRISMA flow diagrams for their own systematic reviews. Our tool allows users to produce standardised visualisations that transparently document the methods and results of a systematic review process in a variety of formats. In addition, we provide the opportunity to produce interactive, web-based flow diagrams (exported as HTML files), that allow readers to click on boxes of the diagram and navigate to further details on methods, results or data files. We provide an interactive example here; https://prisma-flowdiagram.github.io/. Conclusions We have developed a user-friendly tool for producing PRISMA 2020-compliant flow diagrams for users with coding experience and, importantly, for users without prior experience in coding by making use of Shiny (https://estech.shinyapps.io/prisma\_flowdiagram/). This free-to-use tool will make it easier to produce clear and PRISMA 2020-compliant systematic review flow diagrams. Significantly, users can also produce interactive flow diagrams for the first time, allowing readers of their reviews to smoothly and swiftly explore and navigate to further details of the methods and results of a review. We believe this tool will increase use of PRISMA flow diagrams, improve the compliance and quality of flow diagrams, and facilitate strong science communication of the methods and results of systematic reviews by making use of interactivity. We encourage the systematic review community to make use of the tool, and provide feedback to streamline and improve their usability and efficiency.},
  doi      = {10.1002/cl2.1230},
  file     = {:Haddaway2022 - PRISMA2020_ an R Package and Shiny App for Producing PRISMA 2020 Compliant Flow Diagrams, with Interactivity for Optimised Digital Transparency and Open Synthesis.pdf:PDF},
}

@Article{Bramer2018a,
  author   = {Bramer, Wichor M. and Rethlefsen, Melissa L. and Mast, Frans and Kleijnen, Jos},
  journal  = {Res Syn Meth},
  title    = {Evaluation of a new method for librarian-mediated literature searches for systematic reviews},
  year     = {2018},
  number   = {4},
  pages    = {510--520},
  volume   = {9},
  abstract = {Objective To evaluate and validate the time of completion and results of a new method of searching for systematic reviews, the exhaustive search method (ESM), using a pragmatic comparison. Methods Single-line search strategies were prepared in a text document. Term completeness was ensured with a novel optimization technique. Macros in MS Word converted the syntaxes between databases and interfaces almost automatically. We compared search characteristics, such as number of search terms and databases, and outcomes, such as number of included and retrieved references and precision, from ESM searches and other Dutch academic hospitals identified by searching PubMed for systematic reviews published between 2014 and 2016. We compared time to perform the ESM with a secondary comparator of recorded search times from published literature and contact with authors to acquire unpublished data. Results We identified 73 published Erasmus MC systematic reviews and 258 published by other Dutch academic hospitals meeting our criteria. We pooled search time data from 204 other systematic reviews. The ESM searches differed by using 2 times more databases, retrieving 44\% more references, including 20\% more studies in the final systematic review, but the time needed for the search was 8\% of that of the control group. Similarities between methods include precision and the number of search terms. Conclusions The evaluated similarities and differences suggest that the ESM is a highly efficient way to locate more references meeting the specified selection criteria in systematic reviews than traditional search methods. Further prospective research is required.},
  doi      = {10.1002/jrsm.1279},
  file     = {:Bramer2018a - Evaluation of a New Method for Librarian Mediated Literature Searches for Systematic Reviews.pdf:PDF;:Bramer2018a - Evaluation of a New Method for Librarian Mediated Literature Searches for Systematic Reviews.docx:Word 2007+;:jrsm1279-sup-0002-data_s2 .docx:Word 2007+},
  keywords = {bibliographic databases, information storage and retrieval, quality improvement, review literature as topic},
}

@Article{Zwakman2018,
  author   = {Zwakman, Marieke and Verberne, Lisa M. and Kars, Marijke C. and Hooft, Lotty and van Delden, Johannes J. M. and Spijker, René},
  journal  = {BMC Palliat Care},
  title    = {{Introducing PALETTE: an iterative method for conducting a literature search for a review in palliative care}},
  year     = {2018},
  issn     = {1472-684X},
  number   = {1},
  pages    = {82},
  volume   = {17},
  abstract = {In the rapidly developing specialty of palliative care, literature reviews have become increasingly important to inform and improve the field. When applying widely used methods for literature reviews developed for intervention studies onto palliative care, challenges are encountered such as the heterogeneity of palliative care in practice (wide range of domains in patient characteristics, stages of illness and stakeholders), the explorative character of review questions, and the poorly defined keywords and concepts. To overcome the challenges and to provide guidance for researchers to conduct a literature search for a review in palliative care, Palliative cAre Literature rEview iTeraTive mEthod (PALLETE), a pragmatic framework, was developed. We assessed PALETTE with a detailed description.},
  doi      = {10.1186/s12904-018-0335-z},
  file     = {:Zwakman2018 - Introducing PALETTE_ an Iterative Method for Conducting a Literature Search for a Review in Palliative Care.pdf:PDF},
  refid    = {Zwakman2018},
}

@Article{Borissov2022,
  author   = {Borissov, Nikolay and Haas, Quentin and Minder, Beatrice and Kopp-Heim, Doris and von Gernler, Marc and Janka, Heidrun and Teodoro, Douglas and Amini, Poorya},
  journal  = {Syst Rev},
  title    = {{Reducing systematic review burden using Deduklick: a novel, automated, reliable, and explainable deduplication algorithm to foster medical research}},
  year     = {2022},
  issn     = {2046-4053},
  number   = {1},
  pages    = {172},
  volume   = {11},
  abstract = {Identifying and removing reference duplicates when conducting systematic reviews (SRs) remain a major, time-consuming issue for authors who manually check for duplicates using built-in features in citation managers. To address issues related to manual deduplication, we developed an automated, efficient, and rapid artificial intelligence-based algorithm named Deduklick. Deduklick combines natural language processing algorithms with a set of rules created by expert information specialists.},
  doi      = {10.1186/s13643-022-02045-9},
  file     = {:Borissov2022 - Reducing Systematic Review Burden Using Deduklick_ a Novel, Automated, Reliable, and Explainable Deduplication Algorithm to Foster Medical Research.pdf:PDF},
  refid    = {Borissov2022},
  url      = {https://doi.org/10.1186/s13643-022-02045-9},
}

@InCollection{Chan2017,
  author    = {Chan, Man-pui Sally and Jones, Christopher and Albarracín, Dolores},
  booktitle = {{The Oxford Handbook of the Science of Science Communication}},
  publisher = {Oxford University Press},
  title     = {{Chapter 36: Countering False Beliefs: An Analysis of the Evidence and Recommendations of Best Practices for the Retraction and Correction of Scientific Misinformation}},
  year      = {2017},
  editor    = {Kathleen Hall Jamieson and Dan M. Kahan and Dietram A. Scheufele},
  isbn      = {9780190497620},
  month     = jun,
  pages     = {340--349},
  abstract  = {{Although false beliefs about science are at the core of theory and practice in the field of scientific communication, correction and retraction of misinformation entail a complex and difficult process. This chapter first provides a review of trends in scientific retraction and correction notes failures in the fundamental communicative function of signaling that a published finding has been invalidated. It describes the recent practical communication developments that are increasing the transparency and visibility of retractions and corrections of fraudulent or incorrect scientific findings and examines the final barrier to correction of misbelief: the continued influence effect. The chapter reviews the results of a meta-analysis of the continued influence effect and present psychology-based recommendations in the form of decision trees to guide the work of scientists and practitioners and provides eight best practice recommendations for science communication scholars and practitioners as they continue their battle against misinformation.}},
  doi       = {10.1093/oxfordhb/9780190497620.013.37},
  eprint    = {https://academic.oup.com/book/0/chapter/211544161/chapter-ag-pdf/44600263/book\_27956\_section\_211544161.ag.pdf},
  file      = {:Chan2017 - Countering False Beliefs_ an Analysis of the Evidence and Recommendations of Best Practices for the Retraction and Correction of Scientific Misinformation.pdf:PDF},
  url       = {https://doi.org/10.1093/oxfordhb/9780190497620.013.37},
}

@Article{Alfirevic2020,
  author    = {Alfirevic, Zarko},
  journal   = {Am J Obstet Gynecol MFM},
  title     = {Retracted papers are only the tip of the iceberg of untrustworthy evidence},
  year      = {2020},
  issn      = {2589-9333},
  month     = nov,
  number    = {4},
  volume    = {2},
  doi       = {10.1016/j.ajogmf.2020.100223},
  file      = {:Alfirevic2020 - Retracted Papers Are Only the Tip of the Iceberg of Untrustworthy Evidence.pdf:PDF},
  publisher = {Elsevier},
  url       = {https://doi.org/10.1016/j.ajogmf.2020.100223},
}

@Article{OConnor2019,
  author   = {O’Connor, Annette M. and Tsafnat, Guy and Thomas, James and Glasziou, Paul and Gilbert, Stephen B. and Hutton, Brian},
  journal  = {Syst Rev},
  title    = {A question of trust: can we build an evidence base to gain trust in systematic review automation technologies?},
  year     = {2019},
  issn     = {2046-4053},
  number   = {1},
  pages    = {143},
  volume   = {8},
  abstract = {Although many aspects of systematic reviews use computational tools, systematic reviewers have been reluctant to adopt machine learning tools.},
  doi      = {10.1186/s13643-019-1062-0},
  file     = {:O’Connor2019 - A Question of Trust_ Can We Build an Evidence Base to Gain Trust in Systematic Review Automation Technologies_.pdf:PDF},
}

@Book{Egger2022,
  editor    = {Matthias Egger and Julian P. T. Higgins and George Davey Smith},
  publisher = {John Wiley \& Sons, Ltd.},
  title     = {{Systematic Reviews in Health Research: Meta-Analysis in Context}},
  year      = {2022},
  isbn      = {9781119099369},
  month     = apr,
  doi       = {10.1002/9781119099369},
  file      = {:2022 - Systematic Reviews in Health Research.pdf:PDF;:2022 - Systematic Reviews in Health Research.epub:ePUB},
  url       = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119099369},
}

@Article{Marik2015,
  author                 = {Marik, Paul E.},
  journal                = {Eur J Clin Invest},
  title                  = {Self-plagiarism: the perspective of a convicted plagiarist!},
  year                   = {2015},
  month                  = aug,
  pages                  = {883--887},
  volume                 = {45},
  address                = {England},
  article-doi            = {10.1111/eci.12473},
  comment                = {Eur J Clin Invest. 2015 Nov;45(11):1220. PMID: 26342169},
  completed              = {20160504},
  electronic-issn        = {1365-2362},
  electronic-publication = {20150625},
  file                   = {:Marik2015 - Self Plagiarism_ the Perspective of a Convicted Plagiarist!.pdf:PDF},
  history                = {2016/05/05 06:00 [medline]},
  issue                  = {8},
  keywords               = {Humans, *Periodicals as Topic, *Plagiarism, Retraction of Publication as Topic, *Software, *Writing},
  language               = {eng},
  linking-issn           = {0014-2972},
  location-id            = {10.1111/eci.12473 [doi]},
  nlm-unique-id          = {0245331},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20150723},
  source                 = {Eur J Clin Invest. 2015 Aug;45(8):883-7. doi: 10.1111/eci.12473. Epub 2015 Jun 25.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {Eur J Clin Invest},
}

@Article{Oransky2022,
  author             = {Oransky, Ivan},
  journal            = {Nature},
  title              = {Retractions are increasing, but not enough.},
  year               = {2022},
  month              = aug,
  number             = {7921},
  pages              = {9},
  volume             = {608},
  address            = {England},
  article-doi        = {10.1038/d41586-022-02071-6},
  article-pii        = {10.1038/d41586-022-02071-6},
  completed          = {20220804},
  doi                = {10.1038/d41586-022-02071-6},
  electronic-issn    = {1476-4687},
  file               = {:Oransky2022 - Retractions Are Increasing, but Not Enough..pdf:PDF},
  history            = {2022/08/05 06:00 [medline]},
  issue              = {7921},
  keywords           = {Editorial Policies, Reproducibility of Results, *Retraction of Publication as Topic, Scientific Misconduct/legislation & jurisprudence/statistics & numerical data, Ethics, Journalism, Publishing},
  language           = {eng},
  linking-issn       = {0028-0836},
  location-id        = {10.1038/d41586-022-02071-6 [doi]},
  nlm-unique-id      = {0410462},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20220805},
  source             = {Nature. 2022 Aug;608(7921):9. doi: 10.1038/d41586-022-02071-6.},
  status             = {MEDLINE},
  subset             = {IM},
  termowner          = {NOTNLM},
  title-abbreviation = {Nature},
}

@Article{Grave2021,
  author             = {Grave, Joana},
  journal            = {Nat Hum Behav},
  title              = {Scientists should be open about their mistakes.},
  year               = {2021},
  month              = dec,
  pages              = {1593},
  volume             = {5},
  address            = {England},
  article-doi        = {10.1038/s41562-021-01225-2},
  article-pii        = {10.1038/s41562-021-01225-2},
  completed          = {20220221},
  electronic-issn    = {2397-3374},
  file               = {:Grave2021 - Scientists Should Be Open about Their Mistakes..pdf:PDF},
  history            = {2021/10/19 06:23 [entrez]},
  issue              = {12},
  keywords           = {*Disclosure, Humans, *Research, *Retraction of Publication as Topic},
  language           = {eng},
  linking-issn       = {2397-3374},
  location-id        = {10.1038/s41562-021-01225-2 [doi]},
  nlm-unique-id      = {101697750},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20220221},
  source             = {Nat Hum Behav. 2021 Dec;5(12):1593. doi: 10.1038/s41562-021-01225-2.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {Nat Hum Behav},
}

@Article{Tolsgaard2019,
  author    = {Martin G. Tolsgaard and Rachel Ellaway and Nikki Woods and Geoff Norman},
  journal   = {Adv Health Sci Educ},
  title     = {Salami-slicing and plagiarism: How should we respond?},
  year      = {2019},
  month     = feb,
  number    = {1},
  pages     = {3--14},
  volume    = {24},
  doi       = {10.1007/s10459-019-09876-7},
  file      = {:Tolsgaard2019 - Salami Slicing and Plagiarism_ How Should We Respond_.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Smith2011,
  author                 = {Smith, Valerie and Devane, Declan and Begley, Cecily M. and Clarke, Mike},
  journal                = {BMC Med Res Methodol},
  title                  = {Methodology in conducting a systematic review of systematic reviews of healthcare interventions.},
  year                   = {2011},
  month                  = feb,
  pages                  = {15},
  volume                 = {11},
  abstract               = {BACKGROUND: Hundreds of studies of maternity care interventions have been published, too many for most people involved in providing maternity care to identify and consider when making decisions. It became apparent that systematic reviews of individual studies were required to appraise, summarise and bring together existing studies in a single place. However, decision makers are increasingly faced by a plethora of such reviews and these are likely to be of variable quality and scope, with more than one review of important topics. Systematic reviews (or overviews) of reviews are a logical and appropriate next step, allowing the findings of separate reviews to be compared and contrasted, providing clinical decision makers with the evidence they need. METHODS: The methods used to identify and appraise published and unpublished reviews systematically, drawing on our experiences and good practice in the conduct and reporting of systematic reviews are described. The process of identifying and appraising all published reviews allows researchers to describe the quality of this evidence base, summarise and compare the review's conclusions and discuss the strength of these conclusions. RESULTS: Methodological challenges and possible solutions are described within the context of (i) sources, (ii) study selection, (iii) quality assessment (i.e. the extent of searching undertaken for the reviews, description of study selection and inclusion criteria, comparability of included studies, assessment of publication bias and assessment of heterogeneity), (iv) presentation of results, and (v) implications for practice and research. CONCLUSION: Conducting a systematic review of reviews highlights the usefulness of bringing together a summary of reviews in one place, where there is more than one review on an important topic. The methods described here should help clinicians to review and appraise published reviews systematically, and aid evidence-based clinical decision-making.},
  address                = {England},
  article-doi            = {10.1186/1471-2288-11-15},
  article-pii            = {1471-2288-11-15},
  completed              = {20110505},
  doi                    = {10.1186/1471-2288-11-15},
  electronic-issn        = {1471-2288},
  electronic-publication = {20110203},
  file                   = {:Smith2011 - Methodology in Conducting a Systematic Review of Systematic Reviews of Healthcare Interventions..pdf:PDF},
  history                = {2011/05/06 06:00 [medline]},
  issue                  = {1},
  keywords               = {Female, Health Services Research/standards, Humans, Information Storage and Retrieval, Maternal Health Services, *Meta-Analysis as Topic, *Review Literature as Topic},
  language               = {eng},
  linking-issn           = {1471-2288},
  location-id            = {10.1186/1471-2288-11-15 [doi]},
  nlm-unique-id          = {100968545},
  owner                  = {NLM},
  publication-status     = {epublish},
  revised                = {20220408},
  source                 = {BMC Med Res Methodol. 2011 Feb 3;11(1):15. doi: 10.1186/1471-2288-11-15.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {BMC Med Res Methodol},
}

@Article{Patel2022,
  author     = {Patel, Jayshil J. and Hill, Aileen and Lee, Zheng-Yii and Heyland, Daren K. and Stoppe, Christian},
  journal    = {Crit Care Med},
  title      = {{Critical Appraisal of a Systematic Review: A Concise Review}},
  year       = {2022},
  issn       = {0090-3493},
  number     = {9},
  volume     = {50},
  abstract   = {OBJECTIVES:},
  doi        = {10.1097/CCM.0000000000005602},
  file       = {:Patel2022 - Critical Appraisal of a Systematic Review_ a Concise Review.pdf:PDF;:Patel2022 - Critical Appraisal of a Systematic Review_ a Concise Review.epub:ePUB},
  keywords   = {critical appraisal, evidence-based medicine, meta-analysis, randomized controlled trial, systematic review},
  refid      = {00003246-202209000-00009},
  shorttitle = {SELECTION:},
  url        = {https://journals.lww.com/ccmjournal/Fulltext/2022/09000/Critical_Appraisal_of_a_Systematic_Review__A.9.aspx},
}

@Article{McKeown2019,
  author                 = {McKeown, Sandra and Ross-White, Amanda},
  journal                = {J Med Libr Assoc},
  title                  = {Building capacity for librarian support and addressing collaboration challenges by formalizing library systematic review services.},
  year                   = {2019},
  month                  = jul,
  pages                  = {411--419},
  volume                 = {107},
  electronic-issn        = {1558-9439},
  linking-issn           = {1536-5050},
  print-issn             = {1536-5050},
  abstract               = {BACKGROUND: Many health sciences librarians are noticing an increase in demand for systematic review support. Developing a strategic approach to supporting systematic review activities can address commonly reported barriers and challenges including time factors, methodological issues, and supporting student-led projects. CASE PRESENTATION: This case report describes how a health sciences library at a mid-sized university developed and implemented a structured and defined systematic review service in order to build capacity for increased librarian support and to maximize librarians' time and expertise. The process also revealed underlying collaboration challenges related to student-led systematic reviews and research quality concerns that needed to be addressed. The steps for developing a formal service included defining the librarian's role and a library service model, building librarian expertise, developing documentation to guide librarians and patrons, piloting and revising the service model, marketing and promoting the service, and evaluating service usage. CONCLUSIONS: The two-tiered service model developed for advisory consultation and collaboration provides a framework for supporting systematic review activities that other libraries can adapt to meet their own needs. Librarian autonomy in deciding whether to collaborate on reviews based on defined and explicit considerations was crucial for maximizing librarians' time and expertise and for promoting higher quality research. Monitoring service usage will be imperative for managing existing and future librarian workload. These data and tracking of research outputs from librarian collaborations may also be used to advocate for new librarian positions.},
  address                = {United States},
  article-doi            = {10.5195/jmla.2019.443},
  article-pii            = {jmla-107-411},
  completed              = {20200113},
  electronic-publication = {20190701},
  file                   = {:McKeown2019 - Building Capacity for Librarian Support and Addressing Collaboration Challenges by Formalizing Library Systematic Review Services..pdf:PDF},
  history                = {2020/01/14 06:00 [medline]},
  issue                  = {3},
  keywords               = {Adult, Capacity Building, Female, Humans, *Intersectoral Collaboration, Librarians/*psychology, Libraries, Medical/*organization & administration, Library Services/*organization & administration, Male, Middle Aged, *Professional Role, *Systematic Reviews as Topic},
  language               = {eng},
  location-id            = {10.5195/jmla.2019.443 [doi]},
  nlm-unique-id          = {101132728},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20220409},
  source                 = {J Med Libr Assoc. 2019 Jul;107(3):411-419. doi: 10.5195/jmla.2019.443. Epub 2019 Jul 1.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {J Med Libr Assoc},
}

@Article{Booth2016,
  author   = {Booth, Andrew},
  journal  = {Syst Rev},
  title    = {Searching for qualitative research for inclusion in systematic reviews: a structured methodological review},
  year     = {2016},
  issn     = {2046-4053},
  number   = {1},
  pages    = {74},
  volume   = {5},
  abstract = {Qualitative systematic reviews or qualitative evidence syntheses (QES) are increasingly recognised as a way to enhance the value of systematic reviews (SRs) of clinical trials. They can explain the mechanisms by which interventions, evaluated within trials, might achieve their effect. They can investigate differences in effects between different population groups. They can identify which outcomes are most important to patients, carers, health professionals and other stakeholders. QES can explore the impact of acceptance, feasibility, meaningfulness and implementation-related factors within a real world setting and thus contribute to the design and further refinement of future interventions. To produce valid, reliable and meaningful QES requires systematic identification of relevant qualitative evidence. Although the methodologies of QES, including methods for information retrieval, are well-documented, little empirical evidence exists to inform their conduct and reporting.},
  doi      = {10.1186/s13643-016-0249-x},
  file     = {:Booth2016 - Searching for Qualitative Research for Inclusion in Systematic Reviews_ a Structured Methodological Review.pdf:PDF},
  refid    = {Booth2016},
  url      = {https://doi.org/10.1186/s13643-016-0249-x},
}

@Article{Mulrow1994,
  author    = {Cynthia D. Mulrow},
  journal   = {BMJ},
  title     = {{Rationale For Systematic Reviews}},
  year      = {1994},
  month     = sep,
  number    = {6954},
  pages     = {597--599},
  volume    = {309},
  abstract  = {Systematic literature reviews including metaanalyses are invaluable scientific activities. The rationale for such reviews is well established. Health care providers, researchers, and policy makers are inundated with unmanageable amounts of information; they need systematic reviews to efficiently integrate existing information and provide data for rational decision making. Systematic reviews establish whether scientific findings are consistent and can be generalised across populations, settings, and treatment variations, or whether findings vary significantly by particular subsets. Meta-analyses in particular can increase power and precision of estimates of treatment effects and exposure risks. Finally, explicit methods used in systematic reviews limit bias and, hopefully, will improve reliability and accuracy of conclusions.},
  eprint    = {http://www.jstor.org/stable/29724645},
  file      = {:Mulrow1994 - Rationale for Systematic Reviews.pdf:PDF},
  publisher = {BMJ},
  url       = {http://www.jstor.org/stable/29724645},
  urldate   = {2023-03-07},
}

@Article{Torgerson2006,
  author    = {Carole J. Torgerson},
  journal   = {Brit J Educ Stud},
  title     = {{Publication Bias: The Achilles' Heel of Systematic Reviews?}},
  year      = {2006},
  number    = {1},
  pages     = {89--102},
  volume    = {54},
  abstract  = {The term 'publication bias' usually refers to the tendency for a greater proportion of statistically significant positive results of experiments to be published and, conversely, a greater proportion of statistically significant negative or null results not to be published. It is widely accepted in the fields of healthcare and psychological research to be a major threat to the validity of systematic reviews and meta-analyses. Some methodological work has previously been undertaken, by the author and others, in the field of educational research to investigate the extent of the problem. This paper describes the problem of publication bias with reference to its history in a number of fields, with special reference to the area of educational research. Informal methods for detecting publication bias in systematic reviews and meta-analyses of controlled trials are outlined and retrospective and prospective methods for dealing with the problem are suggested.},
  file      = {:Torgerson2006 - Publication Bias_ the Achilles' Heel of Systematic Reviews_.pdf:PDF},
  publisher = {[Taylor & Francis, Ltd., Society for Educational Studies]},
  url       = {http://www.jstor.org/stable/3699297},
  urldate   = {2023-03-07},
}

@Article{Beall2012,
  author             = {Beall, Jeffrey},
  journal            = {Nature},
  title              = {Predatory publishers are corrupting open access.},
  year               = {2012},
  month              = {Sep},
  pages              = {179},
  volume             = {489},
  electronic-issn    = {1476-4687},
  linking-issn       = {0028-0836},
  address            = {England},
  article-doi        = {10.1038/489179a},
  article-pii        = {489179a},
  completed          = {20121105},
  doi                = {10.1038/489179a},
  file               = {:Beall2012 - Predatory Publishers Are Corrupting Open Access..pdf:PDF},
  history            = {2012/11/06 06:00 [medline]},
  issue              = {7415},
  keywords           = {*Access to Information, Authorship/standards, *Fraud, Peer Review, Research/standards, Periodicals as Topic/economics/*ethics/*standards, Publishing/economics/*ethics/*standards/trends, Quality Control, Research Personnel/economics/standards},
  language           = {eng},
  location-id        = {10.1038/489179a [doi]},
  nlm-unique-id      = {0410462},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20120913},
  source             = {Nature. 2012 Sep 13;489(7415):179. doi: 10.1038/489179a.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {Nature},
}

@Article{Grudniewicz2019,
  author             = {Grudniewicz, Agnes and Moher, David and Cobey, Kelly D. and Bryson, Gregory L. and Cukier, Samantha and Allen, Kristiann and Ardern, Clare and Balcom, Lesley and Barros, Tiago and Berger, Monica and Ciro, Jairo Buitrago and Cugusi, Lucia and Donaldson, Michael R. and Egger, Matthias and Graham, Ian D. and Hodgkinson, Matt and Khan, Karim M. and Mabizela, Mahlubi and Manca, Andrea and Milzow, Katrin and Mouton, Johann and Muchenje, Marvelous and Olijhoek, Tom and Ommaya, Alexander and Patwardhan, Bhushan and Poff, Deborah and Proulx, Laurie and Rodger, Marc and Severin, Anna and Strinzel, Michaela and Sylos-Labini, Mauro and Tamblyn, Robyn and van Niekerk, Marthie and Wicherts, Jelte M. and Lalu, Manoj M.},
  journal            = {Nature},
  title              = {Predatory journals: no definition, no defence.},
  year               = {2019},
  month              = dec,
  pages              = {210--212},
  volume             = {576},
  electronic-issn    = {1476-4687},
  linking-issn       = {0028-0836},
  address            = {England},
  article-doi        = {10.1038/d41586-019-03759-y},
  article-pii        = {10.1038/d41586-019-03759-y},
  comment            = {Nature. 2020 Apr;580(7801):29. PMID: 32235937
Nature. 2020 Apr;580(7801):29. PMID: 32235938},
  completed          = {20200402},
  doi                = {10.1038/d41586-019-03759-y},
  file               = {:Grudniewicz2019 - Predatory Journals_ No Definition, No Defence..pdf:PDF},
  history            = {2019/12/13 06:01 [medline]},
  issue              = {7786},
  keywords           = {Publishing, Research management},
  language           = {eng},
  location-id        = {10.1038/d41586-019-03759-y [doi]},
  nlm-unique-id      = {0410462},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20201210},
  source             = {Nature. 2019 Dec;576(7786):210-212. doi: 10.1038/d41586-019-03759-y.},
  status             = {PubMed-not-MEDLINE},
  subset             = {IM},
  termowner          = {NOTNLM},
  title-abbreviation = {Nature},
}

@Article{Butler2013,
  author   = {Butler, Declan},
  journal  = {Nature},
  title    = {Investigating journals: The dark side of publishing},
  year     = {2013},
  issn     = {1476-4687},
  month    = mar,
  number   = {7442},
  pages    = {433--435},
  volume   = {495},
  abstract = {The explosion in open-access publishing has fuelled the rise of questionable operators.},
  doi      = {10.1038/495433a},
  file     = {:Butler2013 - Investigating Journals_ the Dark Side of Publishing.pdf:PDF},
  refid    = {Butler2013},
  url      = {https://doi.org/10.1038/495433a},
}

@Article{Cobey2017,
  author                 = {Cobey, Kelly D. and de Costa E Silva, Miguel and Mazzarello, Sasha and Stober, Carol and Hutton, Brian and Moher, David and Clemons, Mark},
  journal                = {J Oncol Pract},
  title                  = {{Is This Conference for Real? Navigating Presumed Predatory Conference Invitations.}},
  year                   = {2017},
  month                  = jul,
  pages                  = {410--413},
  volume                 = {13},
  address                = {United States},
  article-doi            = {10.1200/JOP.2017.021469},
  completed              = {20181214},
  doi                    = {10.1200/JOP.2017.021469},
  electronic-issn        = {1935-469X},
  electronic-publication = {20170614},
  file                   = {:Cobey2017 - Is This Conference for Real_ Navigating Presumed Predatory Conference Invitations..pdf:PDF},
  history                = {2017/06/15 06:00 [entrez]},
  issue                  = {7},
  keywords               = {Biomedical Research, Congresses as Topic/*standards, Electronic Mail/statistics & numerical data, Fraud},
  language               = {eng},
  linking-issn           = {1554-7477},
  location-id            = {10.1200/JOP.2017.021469 [doi]},
  nlm-unique-id          = {101261852},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20181214},
  source                 = {J Oncol Pract. 2017 Jul;13(7):410-413. doi: 10.1200/JOP.2017.021469. Epub 2017 Jun 14.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {J Oncol Pract},
}

@Article{Godskesen2022,
  author    = {Tove Godskesen and Stefan Eriksson and Marilyn H. Oermann and Sebastian Gabrielsson},
  journal   = {{BMJ} Open},
  title     = {Predatory conferences: a systematic scoping review},
  year      = {2022},
  month     = nov,
  number    = {11},
  pages     = {e062425},
  volume    = {12},
  abstract  = {Objective To systematically map the scholarly literature on predatory conferences and describe the present state of research and the prevalent attitudes about these conferences. Methods This scoping review follows Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Four databases were searched (PubMed/ Medline, Web of Science, Scopus and ProQuest Social Sciences Premium Collection). In addition, the included studies' reference lists were scanned for additional papers not found in the searches. Peer-reviewed publications were included irrespective of study design. Letters and commentary were included if they were peer reviewed. Editorials and literature reviews were excluded. Results From 809 initial publications, 20 papers were included in the review, from 12 countries and covered a wide range of science disciplines, from nursing/medicine to energy/technology and computer science. More than half were empirical and published after 2017. In most papers, a definition of the term predatory conferences was put forward. Spam email invitations with flattering language were the most common characteristics, and the conferences were often hosted by unknown organisations that used copied pictures without permission. High fees, lack of peer review, and a multidisciplinary scope were signal features. All papers explicitly or implicitly suggested possible reasons for participating in predatory conferences. Some reasons were related to the overall context of academic work, the nature of predatory conferences (eg, researchers falling prey to misleading information about a conference or choosing a conference based on an attractive location) and the personal characteristics of researchers. Only one paper reported empirically identified reasons for participating in predatory conferences. The three countermeasures proposed most frequently to deal with predatory conferences were increasing education, emphasising responsibilities of universities and funders, and publishing lists of predatory publishers associated with conferences. Conclusions This review identified a scarcity of research concerning predatory conferences. Future empirical as well as fully analytical research should be encouraged by funders, journals and research institutions.},
  date      = {2022-11-30},
  day       = {30},
  doi       = {10.1136/bmjopen-2022-062425},
  file      = {:Godskesen2022a - Predatory Conferences_ a Systematic Scoping Review.pdf:PDF},
  publisher = {{BMJ}},
}

@Article{Bohannon2013,
  author    = {John Bohannon},
  journal   = {Science},
  title     = {{Who{\textquotesingle}s Afraid of Peer Review?}},
  year      = {2013},
  month     = oct,
  number    = {6154},
  pages     = {60--65},
  volume    = {342},
  doi       = {10.1126/science.2013.342.6154.342_60},
  file      = {:Bohannon2013 - Who_s Afraid of Peer Review_.pdf:PDF},
  publisher = {American Association for the Advancement of Science ({AAAS})},
  url       = {https://doi.org/10.1126/science.2013.342.6154.342_60},
}

@Article{Hansoti2016,
  author                 = {Hansoti, Bhakti and Langdorf, Mark I. and Murphy, Linda S.},
  journal                = {West J Emerg Med},
  title                  = {{Discriminating Between Legitimate and Predatory Open Access Journals: Report from the International Federation for Emergency Medicine Research Committee.}},
  year                   = {2016},
  month                  = sep,
  pages                  = {497--507},
  volume                 = {17},
  abstract               = {INTRODUCTION: Open access (OA) medical publishing is growing rapidly. While subscription-based publishing does not charge the author, OA does. This opens the door for "predatory" publishers who take authors' money but provide no substantial peer review or indexing to truly disseminate research findings. Discriminating between predatory and legitimate OA publishers is difficult. METHODS: We searched a number of library indexing databases that were available to us through the University of California, Irvine Libraries for journals in the field of emergency medicine (EM). Using criteria from Jeffrey Beall, University of Colorado librarian and an expert on predatory publishing, and the Research Committee of the International Federation for EM, we categorized EM journals as legitimate or likely predatory. RESULTS: We identified 150 journal titles related to EM from all sources, 55 of which met our criteria for OA (37%, the rest subscription based). Of these 55, 25 (45%) were likely to be predatory. We present lists of clearly legitimate OA journals, and, conversely, likely predatory ones. We present criteria a researcher can use to discriminate between the two. We present the indexing profiles of legitimate EM OA journals, to inform the researcher about degree of dissemination of research findings by journal. CONCLUSION: OA journals are proliferating rapidly. About half in EM are legitimate. The rest take substantial money from unsuspecting, usually junior, researchers and provide no value for true dissemination of findings. Researchers should be educated and aware of scam journals.},
  address                = {United States},
  article-doi            = {10.5811/westjem.2016.7.30328},
  article-pii            = {wjem-17-497},
  comment                = {West J Emerg Med. 2017 Feb;18(2):318. PMID: 28265334},
  completed              = {20170411},
  doi                    = {10.5811/westjem.2016.7.30328},
  electronic-issn        = {1936-9018},
  electronic-publication = {20160808},
  file                   = {:Hansoti2016 - Discriminating between Legitimate and Predatory Open Access Journals_ Report from the International Federation for Emergency Medicine Research Committee..pdf:PDF},
  history                = {2017/04/12 06:00 [medline]},
  issue                  = {5},
  keywords               = {*Access to Information, Bibliometrics, Biomedical Research, *Emergency Medicine, Humans, Open Access Publishing/*standards, Peer Review, Periodicals as Topic/*standards, Research Personnel},
  language               = {eng},
  linking-issn           = {1936-900X},
  location-id            = {10.5811/westjem.2016.7.30328 [doi]},
  nlm-unique-id          = {101476450},
  owner                  = {NLM},
  print-issn             = {1936-900X},
  publication-status     = {ppublish},
  revised                = {20181113},
  source                 = {West J Emerg Med. 2016 Sep;17(5):497-507. doi: 10.5811/westjem.2016.7.30328. Epub 2016 Aug 8.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {West J Emerg Med},
}

@Article{Nordhausen2022,
  author    = {Nordhausen, Thomas and Hirt, Julian},
  journal   = {GMS Med Bibl Inf},
  title     = {{RefHunter im neuen Webformat: Eine Plattform zur systematischen Literaturrecherche}},
  year      = {2022},
  issn      = {1865-066X},
  month     = dec,
  number    = {2},
  pages     = {Doc31},
  volume    = {22},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.3205/MBI000549},
  file      = {:Hirt2022 - RefHunter Im Neuen Webformat_ Eine Plattform Zur Systematischen Literaturrecherche.pdf:PDF},
  keywords  = {systematic literature research, systematic review, databases, manual, information literacy, systematische Literaturrecherche, systematische \"{U}bersichtsarbeit, Datenbanken, Manual, Informationskompetenz, Medicine and health},
  language  = {de},
  publisher = {German Medical Science GMS Publishing House},
  url       = {https://www.egms.de/en/journals/mbi/2022-22/mbi000549.shtml},
}

@Article{Brice2009,
  author  = {Brice, Julie and Bligh, John and Bordage, Georges and Colliver, Jerry and Cook, David and Eva, Kevin W. and Harden, Ronald and Kanter, Steven L. and Norman, Geoffrey R.},
  journal = {Acad Med},
  title   = {{Publishing Ethics in Medical Education Journals}},
  year    = {2009},
  issn    = {1040-2446},
  month   = oct,
  number  = {10},
  pages   = {S132--S134},
  volume  = {84},
  doi     = {10.1097/ACM.0b013e3181b36f69},
  file    = {:Brice2009 - Publishing Ethics in Medical Education Journals.pdf:PDF},
  refid   = {00001888-200910001-00034},
  url     = {https://journals.lww.com/academicmedicine/Fulltext/2009/10001/Publishing_Ethics_in_Medical_Education_Journals.34.aspx},
}

@Article{Baggs2008,
  author  = {Baggs, Judith Gedney},
  journal = {Res Nurs Health},
  title   = {Issues and rules for authors concerning authorship versus acknowledgements, dual publication, self plagiarism, and salami publishing},
  year    = {2008},
  number  = {4},
  pages   = {295--297},
  volume  = {31},
  doi     = {10.1002/nur.20280},
  file    = {:Baggs2008 - Issues and Rules for Authors Concerning Authorship Versus Acknowledgements, Dual Publication, Self Plagiarism, and Salami Publishing.pdf:PDF},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nur.20280},
}

@Article{Neill2008,
  author    = {Ushma S. Neill},
  journal   = {J Clin Invest},
  title     = {Publish or perish, but at what cost?},
  year      = {2008},
  month     = jul,
  number    = {7},
  pages     = {2368},
  volume    = {118},
  abstract  = {The academic scientific enterprise rewards those with the longest CVs and the most publications. Under pressure to generate voluminous output, scientists often fall prey to double publishing, self plagiarism, and submitting the "minimal publishable unit." Are these ethical gray areas, or true transgressions?},
  doi       = {10.1172/jci36371},
  file      = {:Neill2008 - Publish or Perish, but at What Cost_.pdf:PDF},
  keywords  = {Copyright, Duplicate Publications as Topic, Humans, Periodicals as Topic/ethics/legislation & jurisprudence, Publishing/*ethics, *Scientific Misconduct},
  publisher = {American Society for Clinical Investigation},
  url       = {https://doi.org/10.1172/jci36371},
}

@Book{CRD2009,
  author    = {{Centre for Reviews and Dissemination}},
  publisher = {University of York NHS Centre for Reviews \& Dissemination},
  title     = {Systematic reviews},
  year      = {2009},
  address   = {York, England},
  edition   = {3},
  isbn      = {9781900640473},
  month     = feb,
  file      = {:CRD2009 - Systematic Reviews.pdf:PDF},
  language  = {en},
  url       = {https://www.york.ac.uk/crd/guidance/},
}

@Misc{elicit,
  author = {{Ought}},
  title  = {Elicit: The AI Research Assistant},
  year   = {2023},
  date   = {2023-02-22},
  url    = {https://elicit.org},
}

@Article{Allot2019,
  author             = {Allot, Alexis and Chen, Qingyu and Kim, Sun and Vera Alvarez, Roberto and Comeau, Donald C. and Wilbur, W. John and Lu, Zhiyong},
  journal            = {Nucleic Acids Res},
  title              = {{LitSense: making sense of biomedical literature at sentence level.}},
  year               = {2019},
  month              = jul,
  pages              = {W594--W599},
  volume             = {47},
  electronic-issn    = {1362-4962},
  linking-issn       = {0305-1048},
  print-issn         = {0305-1048},
  abstract           = {Literature search is a routine practice for scientific studies as new discoveries build on knowledge from the past. Current tools (e.g. PubMed, PubMed Central), however, generally require significant effort in query formulation and optimization (especially in searching the full-length articles) and do not allow direct retrieval of specific statements, which is key for tasks such as comparing/validating new findings with previous knowledge and performing evidence attribution in biocuration. Thus, we introduce LitSense, which is the first web-based system that specializes in sentence retrieval for biomedical literature. LitSense provides unified access to PubMed and PMC content with over a half-billion sentences in total. Given a query, LitSense returns best-matching sentences using both a traditional term-weighting approach that up-weights sentences that contain more of the rare terms in the user query as well as a novel neural embedding approach that enables the retrieval of semantically relevant results without explicit keyword match. LitSense provides a user-friendly interface that assists its users to quickly browse the returned sentences in context and/or further filter search results by section or publication date. LitSense also employs PubTator to highlight biomedical entities (e.g. gene/proteins) in the sentences for better result visualization. LitSense is freely available at https://www.ncbi.nlm.nih.gov/research/litsense.},
  address            = {England},
  article-doi        = {10.1093/nar/gkz289},
  article-pii        = {gkz289},
  completed          = {20200519},
  doi                = {10.1093/nar/gkz289},
  file               = {:Allot2019 - LitSense_ Making Sense of Biomedical Literature at Sentence Level..pdf:PDF},
  history            = {2019/04/26 06:00 [entrez]},
  issue              = {W1},
  keywords           = {Abstracting and Indexing, Data Mining/*methods, PubMed, Publications, *Software},
  language           = {eng},
  location-id        = {10.1093/nar/gkz289 [doi]},
  nlm-unique-id      = {0411011},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20200519},
  source             = {Nucleic Acids Res. 2019 Jul 2;47(W1):W594-W599. doi: 10.1093/nar/gkz289.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {Nucleic Acids Res},
}

@Article{Haddaway2022a,
  author                 = {Haddaway, Neal R. and Rethlefsen, Melissa L. and Davies, Melinda and Glanville, Julie and McGowan, Bethany and Nyhan, Kate and Young, Sarah},
  journal                = {Campbell Syst Rev},
  title                  = {A suggested data structure for transparent and repeatable reporting of bibliographic searching.},
  year                   = {2022},
  month                  = dec,
  pages                  = {e1288},
  volume                 = {18},
  abstract               = {Academic searching is integral to research activities: (1) searching to retrieve specific information, (2) to expand our knowledge iteratively, (3) and to collate a representative and unbiased selection of the literature. Rigorous searching methods are vital for reliable, repeatable and unbiased searches needed for these second and third forms of searches (exploratory and systematic searching, respectively) that form a core part of evidence syntheses. Despite the broad awareness of the importance of transparency in reporting search activities in evidence syntheses, the importance of searching has been highlighted only recently and has been the explicit focus of reporting guidance (PRISMA-S). Ensuring bibliographic searches are reported in a way that is transparent enough to allow for full repeatability or evaluation is challenging for a number of reasons. Here, we detail these reasons and provide for the first time a standardised data structure for transparent and comprehensive reporting of search histories. This data structure was produced by a group of international experts in informatics and library sciences. We explain how the data structure was produced and describe its components in detail. We also demonstrate its practical applicability in tools designed to support literature review authors and explain how it can help to improve interoperability across tools used to manage literature reviews. We call on the research community and developers of reference and review management tools to embrace the data structure to facilitate adequate reporting of academic searching in an effort to raise the standard of evidence syntheses globally.},
  address                = {United States},
  article-doi            = {10.1002/cl2.1288},
  article-pii            = {CL21288},
  doi                    = {10.1002/cl2.1288},
  electronic-issn        = {1891-1803},
  electronic-publication = {20221123},
  file                   = {:Haddaway2022a - A Suggested Data Structure for Transparent and Repeatable Reporting of Bibliographic Searching..pdf:PDF},
  history                = {2023/03/14 06:01 [medline]},
  issue                  = {4},
  language               = {eng},
  linking-issn           = {1891-1803},
  location-id            = {e1288},
  nlm-unique-id          = {9918227275506676},
  owner                  = {NLM},
  publication-status     = {epublish},
  revised                = {20230314},
  source                 = {Campbell Syst Rev. 2022 Nov 23;18(4):e1288. doi: 10.1002/cl2.1288. eCollection 2022 Dec.},
  status                 = {PubMed-not-MEDLINE},
  title-abbreviation     = {Campbell Syst Rev},
}

@Article{Hamel2021,
  author                 = {Hamel, Candyce and Michaud, Alan and Thuku, Micere and Skidmore, Becky and Stevens, Adrienne and Nussbaumer-Streit, Barbara and Garritty, Chantelle},
  journal                = {J Clin Epidemiol},
  title                  = {{Defining Rapid Reviews: a systematic scoping review and thematic analysis of definitions and defining characteristics of rapid reviews.}},
  year                   = {2021},
  month                  = jan,
  pages                  = {74--85},
  volume                 = {129},
  electronic-issn        = {1878-5921},
  linking-issn           = {0895-4356},
  abstract               = {BACKGROUND AND OBJECTIVE: Rapid reviews were first mentioned in the literature in 1997, when Best et al. described the rapid health technology assessment program in the south and west regions of England but did not provide a formal definition. More recently, the only consensus around a rapid review definition is that a formal definition does not exist. The primary aim of this work is to create a repository of existing definitions and to identify key themes, which may help the knowledge synthesis community in defining rapid review products. METHODS: A systematic scoping review was performed to identify definitions used in journal-published rapid reviews written in English between 2017 and January 2019. We searched Medline, Embase Classic + Embase, PsycINFO, ERIC, Cochrane Library, CINAHL, and Web of Science on December 21, 2018. Two reviewers performed study selection and data extraction using a priori-defined methods published in a protocol. Definitions from rapid review methods articles (published from 1997 onward) identified in another scoping review were added to the results, and all definitions were thematically analyzed using NVivo. A quantitative analysis was also performed around studies cited. RESULTS: Definitions from 216 rapid reviews and 90 rapid review methods articles were included in the thematic analysis. Eight key themes were identified: accelerated/rapid process or approach, variation in methods shortcuts, focus/depth/breadth of scope, compare and contrast to a full traditional systematic review, stakeholder rationale, resource efficiency rationale, systematic approach, bias/limitations. Secondary referencing was a common occurrence. CONCLUSION: Thematic analysis performed in this systematic scoping review has allowed for the creation of a suggested definition for rapid reviews that can be used to inform the systematic review community.},
  address                = {United States},
  article-doi            = {10.1016/j.jclinepi.2020.09.041},
  article-pii            = {S0895-4356(20)31127-6},
  completed              = {20210906},
  doi                    = {10.1016/j.jclinepi.2020.09.041},
  electronic-publication = {20201008},
  file                   = {:Hamel2021 - Defining Rapid Reviews_ a Systematic Scoping Review and Thematic Analysis of Definitions and Defining Characteristics of Rapid Reviews..pdf:PDF},
  grantno                = {142310/CIHR/Canada},
  history                = {2020/10/10 20:10 [entrez]},
  keywords               = {Humans, Publishing/standards, *Review Literature as Topic, *Terminology as Topic, Definition, Rapid reviews, Scoping review, Thematic analysis},
  language               = {eng},
  location-id            = {10.1016/j.jclinepi.2020.09.041 [doi]},
  nlm-unique-id          = {8801383},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20210906},
  source                 = {J Clin Epidemiol. 2021 Jan;129:74-85. doi: 10.1016/j.jclinepi.2020.09.041. Epub 2020 Oct 8.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {J Clin Epidemiol},
}

@Article{Pieper2022,
  author   = {Pieper, Dawid and Rombey, Tanja},
  journal  = {Syst Rev},
  title    = {{Where to prospectively register a systematic review}},
  year     = {2022},
  issn     = {2046-4053},
  month    = jan,
  number   = {1},
  pages    = {8},
  volume   = {11},
  abstract = {Prospective registration aims to reduce bias in the conduct and reporting of research and to increase transparency. In addition, prospective registration of systematic reviews is argued to help preventing unintended duplication, thereby reducing research waste. PROSPERO was launched in 2011 as the first prospective register for systematic reviews. While it has long been the only option to prospectively register systematic reviews, recently there have been new developments. Our aim was to identify and characterize current options to prospectively register a systematic review to assist review authors in choosing a suitable register.},
  doi      = {10.1186/s13643-021-01877-1},
  file     = {:Pieper2022 - Where to Prospectively Register a Systematic Review.pdf:PDF},
  refid    = {Pieper2022},
  url      = {https://doi.org/10.1186/s13643-021-01877-1},
}

@Article{Bakker2020,
  author    = {Bakker, Marjan and Veldkamp, Coosje L. S. and van Assen, Marcel A. L. M. and Crompvoets, Elise A. V. and Ong, How Hwee and Nosek, Brian A. and Soderberg, Courtney K. and Mellor, David and Wicherts, Jelte M.},
  journal   = {PLoS Biol},
  title     = {Ensuring the quality and specificity of preregistrations},
  year      = {2020},
  month     = dec,
  number    = {12},
  pages     = {1--18},
  volume    = {18},
  abstract  = {Researchers face many, often seemingly arbitrary, choices in formulating hypotheses, designing protocols, collecting data, analyzing data, and reporting results. Opportunistic use of “researcher degrees of freedom” aimed at obtaining statistical significance increases the likelihood of obtaining and publishing false-positive results and overestimated effect sizes. Preregistration is a mechanism for reducing such degrees of freedom by specifying designs and analysis plans before observing the research outcomes. The effectiveness of preregistration may depend, in part, on whether the process facilitates sufficiently specific articulation of such plans. In this preregistered study, we compared 2 formats of preregistration available on the OSF: Standard Pre-Data Collection Registration and Prereg Challenge Registration (now called “OSF Preregistration,” http://osf.io/prereg/). The Prereg Challenge format was a “structured” workflow with detailed instructions and an independent review to confirm completeness; the “Standard” format was “unstructured” with minimal direct guidance to give researchers flexibility for what to prespecify. Results of comparing random samples of 53 preregistrations from each format indicate that the “structured” format restricted the opportunistic use of researcher degrees of freedom better (Cliff’s Delta = 0.49) than the “unstructured” format, but neither eliminated all researcher degrees of freedom. We also observed very low concordance among coders about the number of hypotheses (14%), indicating that they are often not clearly stated. We conclude that effective preregistration is challenging, and registration formats that provide effective guidance may improve the quality of research.},
  doi       = {10.1371/journal.pbio.3000937},
  file      = {:Bakker2020 - Ensuring the Quality and Specificity of Preregistrations.pdf:PDF},
  fjournal  = {PLoS biology},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pbio.3000937},
}

@Article{Association2013,
  author  = {{World Medical Association}},
  journal = {JAMA},
  title   = {{World Medical Association Declaration of Helsinki: Ethical Principles for Medical Research Involving Human Subjects}},
  year    = {2013},
  issn    = {0098-7484},
  month   = nov,
  number  = {20},
  pages   = {2191--2194},
  volume  = {310},
  doi     = {10.1001/jama.2013.281053},
  file    = {:Association2013 - World Medical Association Declaration of Helsinki_ Ethical Principles for Medical Research Involving Human Subjects.pdf:PDF},
  url     = {https://doi.org/10.1001/jama.2013.281053},
}

@Article{Rethlefsen2015,
  author                 = {Rethlefsen, Melissa L. and Farrell, Ann M. and Osterhaus Trzasko, Leah C. and Brigham, Tara J.},
  journal                = {J Clin Epidemiol},
  title                  = {Librarian co-authors correlated with higher quality reported search strategies in general internal medicine systematic reviews.},
  year                   = {2015},
  month                  = jun,
  pages                  = {617--626},
  volume                 = {68},
  electronic-issn        = {1878-5921},
  linking-issn           = {0895-4356},
  abstract               = {OBJECTIVES: To determine whether librarian and information specialist authorship was associated with better reported systematic review (SR) search quality. STUDY DESIGN AND SETTING: SRs from high-impact general internal medicine journals were reviewed for search quality characteristics and reporting quality by independent reviewers using three instruments, including a checklist of Institute of Medicine Recommended Standards for the Search Process and a scored modification of the Peer Review of Electronic Search Strategies instrument. RESULTS: The level of librarian and information specialist participation was significantly associated with search reproducibility from reported search strategies (Χ(2) = 23.5; P < 0.0001). Librarian co-authored SRs had significantly higher odds of meeting 8 of 13 analyzed search standards than those with no librarian participation and six more than those with mentioned librarian participation. One-way ANOVA showed that differences in total search quality scores between all three groups were statistically significant (F2,267 = 10.1233; P < 0.0001). CONCLUSION: Problems remain with SR search quality and reporting. SRs with librarian or information specialist co-authors are correlated with significantly higher quality reported search strategies. To minimize bias in SRs, authors and editors could encourage librarian engagement in SRs including authorship as a potential way to help improve documentation of the search strategy.},
  address                = {United States},
  article-doi            = {10.1016/j.jclinepi.2014.11.025},
  article-pii            = {S0895-4356(15)00057-8},
  completed              = {20150917},
  doi                    = {10.1016/j.jclinepi.2014.11.025},
  electronic-publication = {20150207},
  file                   = {:Rethlefsen2015 - Librarian Co Authors Correlated with Higher Quality Reported Search Strategies in General Internal Medicine Systematic Reviews..pdf:PDF},
  history                = {2015/09/18 06:00 [medline]},
  issue                  = {6},
  keywords               = {Analysis of Variance, Authorship/*standards, Information Services/*statistics & numerical data, Information Storage and Retrieval/*standards/*statistics & numerical data, *Internal Medicine, Journal Impact Factor, Librarians/*statistics & numerical data, Meta-Analysis as Topic, Reproducibility of Results, Review Literature as Topic, Authorship, Librarians, Publishing, Quality control, Standards, Systematic review},
  language               = {eng},
  location-id            = {10.1016/j.jclinepi.2014.11.025 [doi]},
  nlm-unique-id          = {8801383},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20220409},
  source                 = {J Clin Epidemiol. 2015 Jun;68(6):617-26. doi: 10.1016/j.jclinepi.2014.11.025. Epub 2015 Feb 7.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {J Clin Epidemiol},
}

@Article{Schellinger2021,
  author                 = {Schellinger, Jana and Sewell, Kerry and Bloss, Jamie E. and Ebron, Tristan and Forbes, Carrie},
  journal                = {PLoS One},
  title                  = {The effect of librarian involvement on the quality of systematic reviews in dental medicine.},
  year                   = {2021},
  pages                  = {e0256833},
  volume                 = {16},
  abstract               = {OBJECTIVES: To determine whether librarian or information specialist authorship is associated with better reproducibility of the search, at least three databases searched, and better reporting quality in dental systematic reviews (SRs). METHODS: SRs from the top ten dental research journals (as determined by Journal Citation Reports and Scimago) were reviewed for search quality and reproducibility by independent reviewers using two Qualtrics survey instruments. Data was reviewed for all SRs based on reproducibility and librarian participation and further reviewed for search quality of reproducible searches. RESULTS: Librarians were co-authors in only 2.5% of the 913 included SRs and librarians were mentioned or acknowledged in only 9% of included SRs. Librarian coauthors were associated with more reproducible searches, higher search quality, and at least three databases searched. Although the results indicate librarians are associated with improved SR quality, due to the small number of SRs that included a librarian, results were not statistically significant. CONCLUSION: Despite guidance from organizations that produce SR guidelines recommending the inclusion of a librarian or information specialist on the review team, and despite evidence showing that librarians improve the reproducibility of searches and the reporting of methodology in SRs, librarians are not being included in SRs in the field of dental medicine. The authors of this review recommend the inclusion of a librarian on SR teams in dental medicine and other fields.},
  address                = {United States},
  article-doi            = {10.1371/journal.pone.0256833},
  article-pii            = {PONE-D-21-15877},
  completed              = {20211116},
  doi                    = {10.1371/journal.pone.0256833},
  electronic-issn        = {1932-6203},
  electronic-publication = {20210901},
  file                   = {:Schellinger2021 - The Effect of Librarian Involvement on the Quality of Systematic Reviews in Dental Medicine..pdf:PDF},
  fjournal               = {PloS one},
  history                = {2021/11/17 06:00 [medline]},
  issue                  = {9},
  keywords               = {Databases, Factual/statistics & numerical data, *Dental Research, Humans, *Librarians, Library Services/*organization & administration, *Professional Role, Reproducibility of Results, Systematic Reviews as Topic},
  language               = {eng},
  linking-issn           = {1932-6203},
  location-id            = {e0256833},
  nlm-unique-id          = {101285081},
  owner                  = {NLM},
  publication-status     = {epublish},
  revised                = {20211116},
  source                 = {PLoS One. 2021 Sep 1;16(9):e0256833. doi: 10.1371/journal.pone.0256833. eCollection 2021.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {PLoS One},
}

@Article{Meert2016,
  author             = {Meert, Deborah and Torabi, Nazi and Costella, John},
  journal            = {J Med Libr Assoc},
  title              = {Impact of librarians on reporting of the literature searching component of pediatric systematic reviews.},
  year               = {2016},
  month              = oct,
  pages              = {267--277},
  volume             = {104},
  electronic-issn    = {1558-9439},
  linking-issn       = {1536-5050},
  print-issn         = {1536-5050},
  abstract           = {OBJECTIVE: A critical element in conducting a systematic review is the identification of studies. To date, very little empirical evidence has been reported on whether the presence of a librarian or information professional can contribute to the quality of the final product. The goal of this study was to compare the reporting rigor of the literature searching component of systematic reviews with and without the help of a librarian. METHOD: Systematic reviews published from 2002 to 2011 in the twenty highest impact factor pediatrics journals were collected from MEDLINE. Corresponding authors were contacted via an email survey to determine if a librarian was involved, the role that the librarian played, and functions that the librarian performed. The reviews were scored independently by two reviewers using a fifteen-item checklist. RESULTS: There were 186 reviews that met the inclusion criteria, and 44% of the authors indicated the involvement of a librarian in conducting the systematic review. With the presence of a librarian as coauthor or team member, the mean checklist score was 8.40, compared to 6.61 (p<0.001) for reviews without a librarian. CONCLUSIONS: Findings indicate that having a librarian as a coauthor or team member correlates with a higher score in the literature searching component of systematic reviews.},
  address            = {United States},
  article-doi        = {10.3163/1536-5050.104.4.004},
  completed          = {20170713},
  doi                = {10.3163/1536-5050.104.4.004},
  file               = {:Meert2016 - Impact of Librarians on Reporting of the Literature Searching Component of Pediatric Systematic Reviews..pdf:PDF},
  history            = {2017/07/14 06:00 [medline]},
  issue              = {4},
  keywords           = {Child, Evidence-Based Medicine/*methods, Humans, *Librarians, *Pediatrics/methods/standards, Professional Role, *Review Literature as Topic, Surveys and Questionnaires, Critical Appraisal, Librarian, Literature Search, Reporting, Systematic Review},
  language           = {eng},
  nlm-unique-id      = {101132728},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20220409},
  source             = {J Med Libr Assoc. 2016 Oct;104(4):267-277. doi: 10.3163/1536-5050.104.4.004.},
  status             = {MEDLINE},
  subset             = {IM},
  termowner          = {NOTNLM},
  title-abbreviation = {J Med Libr Assoc},
}

@Article{Perrier2014,
  author                 = {Perrier, Laure and Farrell, Ann and Ayala, A. Patricia and Lightfoot, David and Kenny, Tim and Aaronson, Ellen and Allee, Nancy and Brigham, Tara and Connor, Elizabeth and Constantinescu, Teodora and Muellenbach, Joanne and Epstein, Helen-Ann Brown and Weiss, Ardis},
  journal                = {J Am Med Inform Assoc},
  title                  = {Effects of librarian-provided services in healthcare settings: a systematic review.},
  year                   = {2014},
  month                  = {Nov-Dec},
  pages                  = {1118--1124},
  volume                 = {21},
  electronic-issn        = {1527-974X},
  linking-issn           = {1067-5027},
  print-issn             = {1067-5027},
  abstract               = {OBJECTIVE: To assess the effects of librarian-provided services in healthcare settings on patient, healthcare provider, and researcher outcomes. MATERIALS AND METHODS: Medline, CINAHL, ERIC, LISA (Library and Information Science Abstracts), and the Cochrane Central Register of Controlled Trials were searched from inception to June 2013. Studies involving librarian-provided services for patients encountering the healthcare system, healthcare providers, or researchers were eligible for inclusion. All librarian-provided services in healthcare settings were considered as an intervention, including hospitals, primary care settings, or public health clinics. RESULTS: Twenty-five articles fulfilled our eligibility criteria, including 22 primary publications and three companion reports. The majority of studies (15/22 primary publications) examined librarians providing instruction in literature searching to healthcare trainees, and measured literature searching proficiency. Other studies analyzed librarian-provided literature searching services and instruction in question formulation as well as the impact of librarian-provided services on patient length of stay in hospital. No studies were found that investigated librarians providing direct services to researchers or patients in healthcare settings. CONCLUSIONS: Librarian-provided services directed to participants in training programs (eg, students, residents) improve skills in searching the literature to facilitate the integration of research evidence into clinical decision-making. Services provided to clinicians were shown to be effective in saving time for health professionals and providing relevant information for decision-making. Two studies indicated patient length of stay was reduced when clinicians requested literature searches related to a patient's case.},
  address                = {England},
  article-doi            = {10.1136/amiajnl-2014-002825},
  article-pii            = {amiajnl-2014-002825},
  completed              = {20150511},
  doi                    = {10.1136/amiajnl-2014-002825},
  electronic-publication = {20140528},
  file                   = {:Perrier2014 - Effects of Librarian Provided Services in Healthcare Settings_ a Systematic Review..pdf:PDF},
  history                = {2015/05/12 06:00 [medline]},
  issue                  = {6},
  keywords               = {Health Facilities, Humans, *Information Storage and Retrieval, *Librarians, *Outcome and Process Assessment, Health Care, *Patient Care, Librarians, Library Services, Medical Informatics, Systematic Review},
  language               = {eng},
  location-id            = {10.1136/amiajnl-2014-002825 [doi]},
  nlm-unique-id          = {9430800},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20220318},
  source                 = {J Am Med Inform Assoc. 2014 Nov-Dec;21(6):1118-24. doi: 10.1136/amiajnl-2014-002825. Epub 2014 May 28.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {J Am Med Inform Assoc},
}

@Misc{ThomsonCorporation2001,
  author       = {{The Thomson Corporation}},
  howpublished = {Online},
  month        = feb,
  note         = {Archived from http://www.refman.com on 2011-09-30},
  title        = {{RIS Format Specifications}},
  year         = {2001},
  eprint       = {https://web.archive.org/web/20110930172154/http://www.refman.com/support/risformat_intro.asp},
  journal      = {Reference Manager},
}

@Book{BNCBI2010,
  author    = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  publisher = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  title     = {{Entrez Programming Utilities Help [Internet]}},
  year      = {2010},
  eprint    = {https://www.ncbi.nlm.nih.gov/books/NBK25501/},
}

@InCollection{Sayers2008,
  author    = {Eric Sayers},
  booktitle = {{Entrez Programming Utilities Help [Internet]}},
  publisher = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  title     = {{E-utilities Quick Start}},
  year      = {2009},
  month     = dec,
  note      = {[Updated 2018 Oct 24]},
  eprint    = {https://www.ncbi.nlm.nih.gov/books/NBK25500/},
}

@InCollection{Sayers2009,
  author    = {Eric Sayers},
  booktitle = {{Entrez Programming Utilities Help [Internet]}},
  publisher = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  title     = {{A General Introduction to the E-utilities}},
  year      = {2009},
  month     = may,
  note      = {[Updated 2022 Nov 17]},
  eprint    = {https://www.ncbi.nlm.nih.gov/books/NBK25497/},
}

@Book{BNCBI2006,
  author    = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  publisher = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  title     = {{Entrez Help [Internet]}},
  year      = {2006},
  month     = jan,
  note      = {[Updated 2016 May 31]},
  eprint    = {https://www.ncbi.nlm.nih.gov/books/NBK3837/},
}

@InCollection{Kans2013,
  author    = {Jonathan Kans},
  booktitle = {{Entrez Programming Utilities Help [Internet]}},
  publisher = {{Bethesda (MD): National Center for Biotechnology Information (US)}},
  title     = {{Entrez Direct: E-utilities on the Unix Command Line}},
  year      = {2013},
  month     = apr,
  note      = {[Updated 2023 Apr 17]},
  eprint    = {https://www.ncbi.nlm.nih.gov/books/NBK179288/},
}

@Article{Burns2021,
  author    = {Burns, C. Sean and Nix, Tyler and Shapiro {II}, Robert M. and Huber, Jeffrey T.},
  journal   = {PLoS One},
  title     = {{MEDLINE search retrieval issues: A longitudinal query analysis of five vendor platforms}},
  year      = {2021},
  month     = may,
  number    = {5},
  pages     = {e0234221},
  volume    = {16},
  abstract  = {This study compared the results of data collected from a longitudinal query analysis of the MEDLINE database hosted on multiple platforms that include PubMed, EBSCOHost, Ovid, ProQuest, and Web of Science. The goal was to identify variations among the search results on the platforms after controlling for search query syntax. We devised twenty-nine cases of search queries comprised of five semantically equivalent queries per case to search against the five MEDLINE database platforms. We ran our queries monthly for a year and collected search result count data to observe changes. We found that search results varied considerably depending on MEDLINE platform. Reasons for variations were due to trends in scholarly publication such as publishing individual papers online first versus complete issues. Some other reasons were metadata differences in bibliographic records; differences in the levels of specificity of search fields provided by the platforms and large fluctuations in monthly search results based on the same query. Database integrity and currency issues were observed as each platform updated its MEDLINE data throughout the year. Specific biomedical bibliographic databases are used to inform clinical decision-making, create systematic reviews, and construct knowledge bases for clinical decision support systems. They serve as essential information retrieval and discovery tools to help identify and collect research data and are used in a broad range of fields and as the basis of multiple research designs. This study should help clinicians, researchers, librarians, informationists, and others understand how these platforms differ and inform future work in their standardization.},
  doi       = {10.1371/journal.pone.0234221},
  file      = {:Burns2021 - MEDLINE Search Retrieval Issues_ a Longitudinal Query Analysis of Five Vendor Platforms.pdf:PDF},
  fjournal  = {PloS one},
  publisher = {Public Library of Science},
}

@Misc{NLM2022,
  author       = {{National Library of Medicine}},
  howpublished = {Online},
  month        = oct,
  title        = {{MEDLINE, PubMed, and PMC (PubMed Central): How are they different?}},
  year         = {2022},
  eprint       = {https://www.nlm.nih.gov/bsd/difference.html},
}

@InCollection{Butterick2023,
  author    = {Matthew Butterick},
  booktitle = {{Practical Typography}},
  publisher = {Online},
  title     = {{straight and curly quotes}},
  year      = {2023},
  edition   = {2.},
  eprint    = {https://practicaltypography.com/straight-and-curly-quotes.html},
}

@Book{InstituteMedicine2011,
  author    = {{Institute of Medicine}},
  editor    = {Jill Eden and Laura Levit and Alfred Berg and Sally Morton},
  publisher = {The National Academies Press},
  title     = {{Finding What Works in Health Care: Standards for Systematic Reviews}},
  year      = {2011},
  address   = {Washington, DC},
  isbn      = {978-0-309-16425-2},
  abstract  = {Healthcare decision makers in search of reliable information that compares health interventions increasingly turn to systematic reviews for the best summary of the evidence. Systematic reviews identify, select, assess, and synthesize the findings of similar but separate studies, and can help clarify what is known and not known about the potential benefits and harms of drugs, devices, and other healthcare services. Systematic reviews can be helpful for clinicians who want to integrate research findings into their daily practices, for patients to make well-informed choices about their own care, for professional medical societies and other organizations that develop clinical practice guidelines. \n\nToo often systematic reviews are of uncertain or poor quality. There are no universally accepted standards for developing systematic reviews leading to variability in how conflicts of interest and biases are handled, how evidence is appraised, and the overall scientific rigor of the process.\n\nIn Finding What Works in Health Care the Institute of Medicine (IOM) recommends 21 standards for developing high-quality systematic reviews of comparative effectiveness research. The standards address the entire systematic review process from the initial steps of formulating the topic and building the review team to producing a detailed final report that synthesizes what the evidence shows and where knowledge gaps remain.\n\nFinding What Works in Health Care also proposes a framework for improving the quality of the science underpinning systematic reviews. This book will serve as a vital resource for both sponsors and producers of systematic reviews of comparative effectiveness research.\n},
  doi       = {10.17226/13059},
  file      = {:InstituteMedicine2011 - Finding What Works in Health Care_ Standards for Systematic Reviews.pdf:PDF},
  url       = {https://nap.nationalacademies.org/catalog/13059/finding-what-works-in-health-care-standards-for-systematic-reviews},
}

@InCollection{NCBI2023,
  author       = {{National Center for Biotechnology Information}},
  booktitle    = {{PubMed User Guide}},
  publisher    = {{National Library of Medicine}},
  title        = {Proximity searching},
  year         = {2023},
  eprint       = {https://pubmed.ncbi.nlm.nih.gov/help/\#proximity-searching},
  howpublished = {Online},
}

@Article{Garritty2021,
  author    = {Garritty, Chantelle and Gartlehner, Gerald and Nussbaumer-Streit, Barbara and King, Valerie J. and Hamel, Candyce and Kamel, Chris and Affengruber, Lisa and Stevens, Adrienne},
  journal   = {J Clin Epidemiol},
  title     = {{Cochrane Rapid Reviews Methods Group offers evidence-informed guidance to conduct rapid reviews}},
  year      = {2021},
  issn      = {0895-4356},
  month     = feb,
  pages     = {13--22},
  volume    = {130},
  abstract  = {ObjectivesTo develop methods guidance to support the conduct of rapid reviews (RRs) produced within Cochrane and beyond, in response to requests for timely evidence syntheses for decision-making purposes including urgent health issues of high priority.},
  comment   = {doi: 10.1016/j.jclinepi.2020.10.007},
  doi       = {10.1016/j.jclinepi.2020.10.007},
  file      = {:Garritty2021 - Cochrane Rapid Reviews Methods Group Offers Evidence Informed Guidance to Conduct Rapid Reviews.pdf:PDF},
  publisher = {Elsevier},
  url       = {https://doi.org/10.1016/j.jclinepi.2020.10.007},
}

@Article{Tricco2015,
  author   = {Tricco, Andrea C. and Antony, Jesmin and Zarin, Wasifa and Strifler, Lisa and Ghassemi, Marco and Ivory, John and Perrier, Laure and Hutton, Brian and Moher, David and Straus, Sharon E.},
  journal  = {BMC Med},
  title    = {A scoping review of rapid review methods},
  year     = {2015},
  issn     = {1741-7015},
  number   = {1},
  pages    = {224},
  volume   = {13},
  abstract = {Rapid reviews are a form of knowledge synthesis in which components of the systematic review process are simplified or omitted to produce information in a timely manner. Although numerous centers are conducting rapid reviews internationally, few studies have examined the methodological characteristics of rapid reviews. We aimed to examine articles, books, and reports that evaluated, compared, used or described rapid reviews or methods through a scoping review.},
  doi      = {10.1186/s12916-015-0465-6},
  file     = {:Tricco2015 - A Scoping Review of Rapid Review Methods.pdf:PDF},
  refid    = {Tricco2015},
  url      = {https://doi.org/10.1186/s12916-015-0465-6},
}

@Article{Haby2016,
  author   = {Haby, Michelle M. and Chapman, Evelina and Clark, Rachel and Barreto, Jorge and Reveiz, Ludovic and Lavis, John N.},
  journal  = {Health Res Policy Syst},
  title    = {What are the best methodologies for rapid reviews of the research evidence for evidence-informed decision making in health policy and practice: a rapid review},
  year     = {2016},
  issn     = {1478-4505},
  number   = {1},
  pages    = {83},
  volume   = {14},
  abstract = {Rapid reviews have the potential to overcome a key barrier to the use of research evidence in decision making, namely that of the lack of timely and relevant research. This rapid review of systematic reviews and primary studies sought to answer the question: What are the best methodologies to enable a rapid review of research evidence for evidence-informed decision making in health policy and practice?},
  doi      = {10.1186/s12961-016-0155-7},
  file     = {:Haby2016 - What Are the Best Methodologies for Rapid Reviews of the Research Evidence for Evidence Informed Decision Making in Health Policy and Practice_ a Rapid Review.pdf:PDF},
  refid    = {Haby2016},
  url      = {https://doi.org/10.1186/s12961-016-0155-7},
}

@Article{Tricco2016,
  author   = {Andrea C. Tricco and Wasifa Zarin and Jesmin Antony and Brian Hutton and David Moher and Diana Sherifali and Sharon E. Straus},
  journal  = {J Clin Epidemiol},
  title    = {{An international survey and modified Delphi approach revealed numerous rapid review methods}},
  year     = {2016},
  issn     = {0895-4356},
  pages    = {61--67},
  volume   = {70},
  abstract = {Objectives
To solicit experiences with and perceptions of rapid reviews from stakeholders, including researchers, policy makers, industry, journal editors, and health care providers.
Study Design and Setting
An international survey of rapid review producers and modified Delphi.
Results
Forty rapid review producers responded on our survey (63% response rate). Eighty-eight rapid reviews with 31 different names were reported. Rapid review commissioning organizations were predominantly government (78%) and health care (58%) organizations. Several rapid review approaches were identified, including updating the literature search of previous reviews (92%); limiting the search strategy by date of publication (88%); and having only one reviewer screen (85%), abstract data (84%), and assess the quality of studies (86%). The modified Delphi included input from 113 stakeholders on the rapid review approaches from the survey. Approach 1 (search limited by date and language; study selection by one reviewer only, and data abstraction and quality appraisal conducted by one reviewer and one verifier) was ranked the most feasible (72%, 81/113 responses), with the lowest perceived risk of bias (12%, 12/103); it also ranked second in timeliness (37%, 38/102) and fifth in comprehensiveness (5%, 5/100).
Conclusion
Rapid reviews have many names and approaches, and some methods might be more desirable than others.},
  doi      = {10.1016/j.jclinepi.2015.08.012},
  file     = {:Tricco2016 - An International Survey and Modified Delphi Approach Revealed Numerous Rapid Review Methods.pdf:PDF},
  keywords = {Rapid review, Survey, Systematic review, Delphi, Consensus, Knowledge synthesis},
  url      = {https://www.sciencedirect.com/science/article/pii/S0895435615003881},
}

@Book{Purssell2020,
  author    = {Edward Purssell and Niall McCrae},
  publisher = {Springer Nature Switzerland AG},
  title     = {{How to Perform a Systematic Literature Review}},
  year      = {2020},
  address   = {Gewerbestrasse 11, 6330 Cham, Switzerland},
  isbn      = {978-3-030-49672-2},
  abstract  = {The systematic review is a rigorous method of collating and synthesizing evidence from multiple studies, producing a whole greater than the sum of parts. This textbook is an authoritative and accessible guide to an activity that is often found overwhelming. The authors steer readers on a logical, sequential path through the process, taking account of the different needs of researchers, students and practitioners. Practical guidance is provided on the fundamentals of systematic reviewing and also on advanced techniques such as meta-analysis. Examples are given in each chapter, with a succinct glossary to support the text. This up-to-date, accessible textbook will satisfy the needs of students, practitioners and educators in the sphere of healthcare, and contribute to improving the quality of evidence-based practice. The authors will advise some freely available or inexpensive open source/access resources (such as PubMed, R and Zotero) to help students how to perform a systemic review, in particular those with limited resources.},
  doi       = {10.1007/978-3-030-49672-2},
  file      = {:Purssell2020 - How to Perform a Systematic Literature Review.pdf:PDF;:Purssell2020 - How to Perform a Systematic Literature Review.epub:ePUB},
  url       = {https://doi.org/10.1007/978-3-030-49672-2},
}

@Book{Dekkers2022,
  author    = {Rob Dekkers and Lindsey Carey and Peter Langhorne},
  publisher = {Springer Nature Switzerland AG},
  title     = {{Making Literature Reviews Work: A Multidisciplinary Guide to Systematic Approaches}},
  year      = {2022},
  address   = {Gewerbestrasse 11, 6330 Cham, Switzerland},
  month     = aug,
  abstract  = {This textbook guides the reader on how to undertake high-quality literature reviews, from traditional narrative to protocol-driven reviews. The guidance covers a broad range of purposes, disciplines and research paradigms. Whether the literature review is part of a research project, doctoral study, dissertation or a stand-alone study, the book offers approaches, methods, tools, tips and guidelines to produce more effective literature reviews in an efficient manner. The numerous examples are drawn from an array of subject areas, such as economics, healthcare, education, medicine, psychology, software engineering amongst others. This makes it worthwhile for a wide range of studies and for reviews into evidence-based interventions, policies, practices and treatments. There is attention given to presenting, reporting and publishing literature reviews. With the additional clarity brought about by explanatory tables and graphs, this textbook is a `must-have' for all students, researchers, academics and practitioners at any stage of their project or career when engaging with literature. In addition, citizens, policymakers and practitioners will benefit from the guidance with better insight into how literature reviews could and should have been conducted.},
  doi       = {10.1007/978-3-030-90025-0},
  file      = {:Dekkers2022 - Making Literature Reviews Work_ a Multidisciplinary Guide to Systematic Approaches.pdf:PDF;:Dekkers2022 - Making Literature Reviews Work_ a Multidisciplinary Guide to Systematic Approaches.epub:ePUB},
  url       = {https://doi.org/10.1007/978-3-030-90025-0},
}

@Article{Khangura2012,
  author   = {Khangura, Sara and Konnyu, Kristin and Cushman, Rob and Grimshaw, Jeremy and Moher, David},
  journal  = {Syst Rev},
  title    = {Evidence summaries: the evolution of a rapid review approach},
  year     = {2012},
  issn     = {2046-4053},
  number   = {1},
  pages    = {10},
  volume   = {1},
  abstract = {Rapid reviews have emerged as a streamlined approach to synthesizing evidence - typically for informing emergent decisions faced by decision makers in health care settings. Although there is growing use of rapid review 'methods', and proliferation of rapid review products, there is a dearth of published literature on rapid review methodology. This paper outlines our experience with rapidly producing, publishing and disseminating evidence summaries in the context of our Knowledge to Action (KTA) research program.},
  doi      = {10.1186/2046-4053-1-10},
  file     = {:Khangura2012 - Evidence Summaries_ the Evolution of a Rapid Review Approach.pdf:PDF},
  refid    = {Khangura2012},
  url      = {https://doi.org/10.1186/2046-4053-1-10},
}

@Article{Klerings2023,
  author       = {Irma Klerings and Shannon Robalino and Andrew Booth and Camila Micaela Escobar-Liquitay and Isolde Sommer and Gerald Gartlehner and Declan Devane and Siw Waffenschmidt},
  journal      = {BMJ Evid Based Med},
  title        = {Rapid reviews methods series: Guidance on literature search},
  year         = {2023},
  issn         = {2515-446X},
  abstract     = {This paper is part of a series of methodological guidance from the Cochrane Rapid Reviews Methods Group. Rapid reviews (RR) use modified systematic review methods to accelerate the review process while maintaining systematic, transparent and reproducible methods. In this paper, we address considerations for RR searches. We cover the main areas relevant to the search process: preparation and planning, information sources and search methods, search strategy development, quality assurance, reporting, and record management. Two options exist for abbreviating the search process: (1) reducing time spent on conducting searches and (2) reducing the size of the search result. Because screening search results is usually more resource-intensive than conducting the search, we suggest investing time upfront in planning and optimising the search to save time by reducing the literature screening workload. To achieve this goal, RR teams should work with an information specialist. They should select a small number of relevant information sources (eg, databases) and use search methods that are highly likely to identify relevant literature for their topic. Database search strategies should aim to optimise both precision and sensitivity, and quality assurance measures (peer review and validation of search strategies) should be applied to minimise errors.No data are available.},
  doi          = {10.1136/bmjebm-2022-112079},
  elocation-id = {bmjebm-2022-112079},
  file         = {:Klerings2023 - Rapid Reviews Methods Series_ Guidance on Literature Search.pdf:PDF},
  publisher    = {Royal Society of Medicine},
  url          = {https://ebm.bmj.com/content/early/2023/04/19/bmjebm-2022-112079},
}

@TechReport{CampbellCollaboration2021,
  author    = {{The Campbell Collaboration}},
  title     = {{Campbell Collaboration Systematic Reviews: Policies and Guidelines}},
  year      = {2021},
  month     = feb,
  doi       = {10.4073/cpg.2016.1},
  file      = {:CampbellCollaboration2021 - Campbell Collaboration Systematic Reviews_ Policies and Guidelines.pdf:PDF},
  publisher = {The Campbell Collaboration},
  url       = {https://doi.org/10.4073/cpg.2016.1},
}

@Article{Spencer2018,
  author                 = {Spencer, Angela J. and Eldredge, Jonathan D.},
  journal                = {J Med Libr Assoc},
  title                  = {Roles for librarians in systematic reviews: a scoping review.},
  year                   = {2018},
  month                  = jan,
  pages                  = {46--56},
  volume                 = {106},
  abstract               = {OBJECTIVE: What roles do librarians and information professionals play in conducting systematic reviews? Librarians are increasingly called upon to be involved in systematic reviews, but no study has considered all the roles librarians can perform. This inventory of existing and emerging roles aids in defining librarians' systematic reviews services. METHODS: For this scoping review, the authors conducted controlled vocabulary and text-word searches in the PubMed; Library, Information Science & Technology Abstracts; and CINAHL databases. We separately searched for articles published in the Journal of the European Association for Health Information and Libraries, Evidence Based Library and Information Practice, the Journal of the Canadian Heath Libraries Association, and Hypothesis. We also text-word searched Medical Library Association annual meeting poster and paper abstracts. RESULTS: We identified 18 different roles filled by librarians and other information professionals in conducting systematic reviews from 310 different articles, book chapters, and presented papers and posters. Some roles were well known such as searching, source selection, and teaching. Other less documented roles included planning, question formulation, and peer review. We summarize these different roles and provide an accompanying bibliography of references for in-depth descriptions of these roles. CONCLUSION: Librarians play central roles in systematic review teams, including roles that go beyond searching. This scoping review should encourage librarians who are fulfilling roles that are not captured here to document their roles in journal articles and poster and paper presentations.},
  address                = {United States},
  article-doi            = {10.5195/jmla.2018.82},
  article-pii            = {jmla-106-46},
  completed              = {20180827},
  doi                    = {10.5195/jmla.2018.82},
  electronic-issn        = {1558-9439},
  electronic-publication = {20180102},
  file                   = {:Spencer2018 - Roles for Librarians in Systematic Reviews_ a Scoping Review..pdf:PDF},
  history                = {2018/08/28 06:00 [medline]},
  issue                  = {1},
  keywords               = {Humans, *Librarians, Libraries, Medical/statistics & numerical data, Library Services/*statistics & numerical data, *Professional Competence, *Professional Role, *Systematic Reviews as Topic},
  language               = {eng},
  linking-issn           = {1536-5050},
  location-id            = {10.5195/jmla.2018.82 [doi]},
  nlm-unique-id          = {101132728},
  owner                  = {NLM},
  print-issn             = {1536-5050},
  publication-status     = {ppublish},
  revised                = {20220409},
  source                 = {J Med Libr Assoc. 2018 Jan;106(1):46-56. doi: 10.5195/jmla.2018.82. Epub 2018 Jan 2.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {J Med Libr Assoc},
}

@Article{Bramer2018b,
  author   = {Bramer, Wichor M. and Giustini, Dean and Kleijnen, Jos and Franco, Oscar H.},
  journal  = {Syst Rev},
  title    = {{Searching Embase and MEDLINE by using only major descriptors or title and abstract fields: a prospective exploratory study}},
  year     = {2018},
  issn     = {2046-4053},
  number   = {1},
  pages    = {200},
  volume   = {7},
  abstract = {Researchers performing systematic reviews (SRs) must carefully consider the relevance of thousands of citations retrieved from bibliographic database searches, the majority of which will be excluded later on close inspection. Well-developed bibliographic searches are generally created with thesaurus or index terms in combination with keywords found in the title and/or abstract fields of citation records. Records in the bibliographic database Embase contain many more thesaurus terms than MEDLINE. Here, we aim to examine how limiting searches to major thesaurus terms (in MEDLINE called focus terms) in Embase and MEDLINE as well as limiting to words in the title and abstract fields of those databases affects the overall recall of SR searches.},
  doi      = {10.1186/s13643-018-0864-9},
  file     = {:Bramer2018b - Searching Embase and MEDLINE by Using Only Major Descriptors or Title and Abstract Fields_ a Prospective Exploratory Study.pdf:PDF},
  refid    = {Bramer2018},
  url      = {https://doi.org/10.1186/s13643-018-0864-9},
}

@Article{Metzendorf2018,
  author    = {Metzendorf, Maria-Inti and Featherstone, Robin M.},
  journal   = {Cochrane Database Syst Rev},
  title     = {Ensuring quality as the basis of evidence synthesis: leveraging information specialists' knowledge, skills, and expertise},
  year      = {2018},
  issn      = {1465-1858},
  number    = {9},
  doi       = {10.1002/14651858.ED000125},
  file      = {:Metzendorf2018 - Ensuring Quality As the Basis of Evidence Synthesis_ Leveraging Information Specialists' Knowledge, Skills, and Expertise.pdf:PDF},
  fjournal  = {Cochrane Database of Systematic Reviews},
  keywords  = {Evidence synthesis; Methodology},
  publisher = {John Wiley & Sons, Ltd},
  url       = {https://doi.org//10.1002/14651858.ED000125},
}

@Article{Tsafnat2014,
  author   = {Tsafnat, Guy and Glasziou, Paul and Choong, Miew Keen and Dunn, Adam and Galgani, Filippo and Coiera, Enrico},
  journal  = {Syst Rev},
  title    = {Systematic review automation technologies},
  year     = {2014},
  issn     = {2046-4053},
  number   = {1},
  pages    = {74},
  volume   = {3},
  abstract = {Systematic reviews, a cornerstone of evidence-based medicine, are not produced quickly enough to support clinical practice. The cost of production, availability of the requisite expertise and timeliness are often quoted as major contributors for the delay. This detailed survey of the state of the art of information systems designed to support or automate individual tasks in the systematic review, and in particular systematic reviews of randomized controlled clinical trials, reveals trends that see the convergence of several parallel research projects.},
  doi      = {10.1186/2046-4053-3-74},
  file     = {:Tsafnat2014 - Systematic Review Automation Technologies.pdf:PDF},
  refid    = {Tsafnat2014},
  url      = {https://doi.org/10.1186/2046-4053-3-74},
}

@Article{Adam2023,
  author    = {Gaelen P. Adam and Robin Paynter},
  journal   = {BMJ Evid Based Med},
  title     = {Development of literature search strategies for evidence syntheses: pros and cons of incorporating text mining tools and objective approaches},
  year      = {2023},
  issn      = {2515-446X},
  number    = {2},
  pages     = {137--139},
  volume    = {28},
  doi       = {10.1136/bmjebm-2021-111892},
  file      = {:Adam2023 - Development of Literature Search Strategies for Evidence Syntheses_ Pros and Cons of Incorporating Text Mining Tools and Objective Approaches.pdf:PDF},
  publisher = {Royal Society of Medicine},
  url       = {https://ebm.bmj.com/content/28/2/137},
}

@Article{Grosjean2023,
  author      = {Stefan Grosjean and Michelle Schaffer},
  journal     = {Bibliothek Forschung und Praxis},
  title       = {{E-Day: Die Bibliothek setzt mit einem Event auf Offenheit}},
  year        = {2023},
  month       = jun,
  number      = {2},
  pages       = {247--261},
  volume      = {47},
  doi         = {doi:10.1515/bfp-2023-0002},
  file        = {:Grosjean2023 - E Day_ Die Bibliothek Setzt Mit Einem Event Auf Offenheit.pdf:PDF},
  lastchecked = {2023-06-20},
  publisher   = {Walter de Gruyter {GmbH}},
  url         = {https://doi.org/10.1515/bfp-2023-0002},
}

@TechReport{Albrecht2023,
  author      = {Albrecht, Steffen},
  institution = {Institut für Technikfolgenabschätzung und Systemanalyse (ITAS)},
  title       = {{ChatGPT und andere Computermodelle zur Sprachverarbeitung – Grundlagen, Anwendungspotenziale und m\"{o}gliche Auswirkungen}},
  year        = {2023},
  month       = apr,
  note        = {46.24.02; LK 01},
  number      = {26},
  type        = {resreport},
  abstract    = {Rarely has a computer system attracted as much attention and debate around the world as ChatGPT has since its launch in November 2022. The chatbot is based on a computer model that has been trained to process linguistic data using artificial intelligence (AI) methods. It can generate eloquent responses on a wide range of topics in a very short time, create entire essays or computer programmes, and use language styles such as poetry, jokes or discussions in different languages.
On the one hand, the high public profile raises expectations about the potential applications. On the other hand, it can also obscure a realistic assessment of the possibilities and limitations of such systems, as well as their social impact. In order to provide guidance for the ongoing debate, this background paper examines
- the technological developments on which the system is based,
- the the potential and limitations of the technology
- possible applications, in particular in the field of education and
- the possible impacts of an application.
The aim of the background paper commissioned by the Committee on Education, Research and Technology Assessment in February 2023, which is the basis for a public expert discussion in the committee, is to compile sound information on these aspects and to identify questions under which the role of language-processing computer models can be further monitored and discussed.
A summary at the beginning provides an overview of the main findings in the form of a reading guide.},
  copyright   = {Open Access},
  doi         = {10.5445/IR/1000158070},
  file        = {:Albrecht2023 - ChatGPT Und Andere Computermodelle Zur Sprachverarbeitung – Grundlagen, Anwendungspotenziale Und Mogliche Auswirkungen.pdf:PDF},
  keywords    = {ChatGPT, KI, KI-Modelle, Sprachverarbeitung, Sprachmodelle, Chatbot, Anwendungen, Szenarien, Gesundheit, Bildung, Forschung, Potentzial, Risiken, Recht, Datenschutz, Urheberrecht, Nachhaltigkeitsaspekte, Regulierung, Forschungsbedarf, Literatur, Technikfolgenabsch\"{a}tzung},
  language    = {de},
  pagetotal   = {114},
  publisher   = {B\"{u}ro f\"{u}r Technikfolgen-Absch\"{a}tzung beim Deutschen Bundestag (TAB)},
  school      = {Karlsruher Institut für Technologie (KIT)},
  url         = {https://publikationen.bibliothek.kit.edu/1000158070},
}

@Book{Byrne2023,
  editor    = {Michael F. Byrne and Nasim Parsa and Alexandra T. Greenhill and Daljeet Chahal and Omer Ahmad and Ulas Bagci},
  publisher = {John Wiley & Sons Ltd},
  title     = {{AI in Clinical Medicine: A Practical Guide for Healthcare Professionals}},
  year      = {2023},
  isbn      = {9781119790686},
  month     = mar,
  doi       = {10.1002/9781119790686},
  file      = {:Byrne2023 - AI in Clinical Medicine_ a Practical Guide for Healthcare Professionals.pdf:PDF;:Byrne2023 - AI in Clinical Medicine_ a Practical Guide for Healthcare Professionals.epub:ePUB},
  keywords  = {Artificial Intelligence, Clinical Medicine, Medical Informatics},
  url       = {https://doi.org/10.1002/9781119790686},
}

@Article{Kolaski2023,
  author   = {Kolaski, Kat and Logan, Lynne Romeiser and Ioannidis, John P. A.},
  journal  = {Syst Rev},
  title    = {Guidance to best tools and practices for systematic reviews},
  year     = {2023},
  issn     = {2046-4053},
  number   = {1},
  pages    = {96},
  volume   = {12},
  abstract = {Data continue to accumulate indicating that many systematic reviews are methodologically flawed, biased, redundant, or uninformative. Some improvements have occurred in recent years based on empirical methods research and standardization of appraisal tools; however, many authors do not routinely or consistently apply these updated methods. In addition, guideline developers, peer reviewers, and journal editors often disregard current methodological standards. Although extensively acknowledged and explored in the methodological literature, most clinicians seem unaware of these issues and may automatically accept evidence syntheses (and clinical practice guidelines based on their conclusions) as trustworthy.},
  doi      = {10.1186/s13643-023-02255-9},
  file     = {:Kolaski2023 - Guidance to Best Tools and Practices for Systematic Reviews.pdf:PDF},
  refid    = {Kolaski2023},
  url      = {https://doi.org/10.1186/s13643-023-02255-9},
}

@Article{Mathes2017,
  author   = {Mathes, Tim and Pieper, Dawid},
  journal  = {BMC Med Res Methodol},
  title    = {Clarifying the distinction between case series and cohort studies in systematic reviews of comparative studies: potential impact on body of evidence and workload},
  year     = {2017},
  issn     = {1471-2288},
  number   = {1},
  pages    = {107},
  volume   = {17},
  abstract = {Distinguishing cohort studies from case series is difficult.},
  doi      = {10.1186/s12874-017-0391-8},
  file     = {:Mathes2017 - Clarifying the Distinction between Case Series and Cohort Studies in Systematic Reviews of Comparative Studies_ Potential Impact on Body of Evidence and Workload.pdf:PDF},
  refid    = {Mathes2017},
  url      = {https://doi.org/10.1186/s12874-017-0391-8},
}

@InProceedings{inproceedings,
  author = {Karasmanis, Sharon and Murphy, Fiona},
  title  = {Emerging roles and collaborations in research support for academic health librarians},
  year   = {2014},
  month  = {09},
  doi    = {10.13140/2.1.2350.7208},
  file   = {:inproceedings - Emerging Roles and Collaborations in Research Support for Academic Health Librarians.pdf:PDF},
}

@InBook{Gilbert2021,
  author    = {Gilbert, Cecily and Gray, Kathleen and Pritchard, Simone},
  editor    = {Butler-Henderson, Kerryn and Day, Karen and Gray, Kathleen},
  pages     = {23--54},
  publisher = {Springer International Publishing},
  title     = {{Health Information Work: A Scoping Review}},
  year      = {2021},
  address   = {Cham},
  isbn      = {978-3-030-81850-0},
  abstract  = {The work of managing health data, health information and health knowledge is fundamental in healthcare systems, as increasingly they are transformed by information and communication technologies. However, this work is not acknowledged or understood as commonly as other kinds of work in healthcare, even though it has been described in scholarly writing for five decades. This chapter is a scoping review of literature from the domains of health sciences, health information technology and health information sciences; bibliometric and thematic analyses explore the responsibilities and the contributions of the health information workforce. 284 publications from 1973 to 2018 outline a wide variety of occupational sub-groups, job titles, work roles and skills. The status and prospects of this kind of work are influenced by: external drivers of role changes; definitions of competency requirements; healthcare professions' needs for general and specialised education regarding new technologies; and fragmented identities within the health information workforce. If specialised professional work is considered essential for healthcare systems to realise the benefits of information and communication technologies, then concerted health workforce planning is needed to consolidate historically disparate health information work practices and to establish a distinctive, accountable workforce that provides the human infrastructure for digital health.},
  booktitle = {The Health Information Workforce : Current and Future Developments},
  doi       = {10.1007/978-3-030-81850-0_2},
  file      = {:Gilbert2021 - Health Information Work_ a Scoping Review.pdf:PDF},
  url       = {https://doi.org/10.1007/978-3-030-81850-0_2},
}

@InBook{Ritchie2021,
  author    = {Ritchie, Ann and McDonald, Steve and Lewis, Suzanne and Gilbert, Cecily and Solomons, Terena and Kang, Kristan and Kuusniemi, Mari-Elisa},
  editor    = {Butler-Henderson, Kerryn and Day, Karen and Gray, Kathleen},
  pages     = {295--307},
  publisher = {Springer International Publishing},
  title     = {Working as a Health Research Information Specialist},
  year      = {2021},
  address   = {Cham},
  isbn      = {978-3-030-81850-0},
  abstract  = {Working with health research information is an evolving and specialised area of health data, information, and knowledge management. The individuals who perform these roles have been characterised as being an emerging third tribe, sitting between and complementing the research work of scientists and administrators. Their specialist information management work facilitates the research process, intersecting at many points and stages in the research lifecycle. A thorough knowledge of scientific research methods as well as information and knowledge management competencies are essential. The six research information specialist case studies described in this chapter have been selected to demonstrate the variety of the roles, types of work, and skillsets that are required.},
  booktitle = {The Health Information Workforce : Current and Future Developments},
  doi       = {10.1007/978-3-030-81850-0_20},
  file      = {:Ritchie2021 - Working As a Health Research Information Specialist.pdf:PDF},
  url       = {https://doi.org/10.1007/978-3-030-81850-0_20},
}

@Article{Kirtley2016,
  author    = {Kirtley, Shona},
  journal   = {The Lancet},
  title     = {Increasing value and reducing waste in biomedical research: librarians are listening and are part of the answer},
  year      = {2016},
  month     = {4},
  number    = {10028},
  pages     = {1601},
  volume    = {387},
  abstract  = {www.thelancet.com Vol 387 April 16, 2016 1601 David Moher and colleagues asked who is listening to calls to increase value and reduce waste in biomedical research. They documented the response of the diff erent stakeholder groups identifi ed in the Lancet Research: Increasing Value, Reducing Waste Series and the Lancet REWARD (REduce research Waste And Reward Diligence) Campaign. However, there is one group that has not been explicitly discussed: biomedical librarians and information scientists. The role of librarians in supporting biomedical research could be substantially expanded by acknowledging their skills and embracing their involvement in research departments, funding bodies, and journal editorial offi ces. It is time for librarians and their essential skills to move beyond the confi nes of the library. First, a librarian could be embedded within every biomedical research department, or at least within every research team, and contribute to two of the areas highlighted in the Lancet Series. Given librarians\textquoteright{} expertise in systematic reviews, the librarian could conduct all the literature searches required by the department to ensure that searches are comprehensive and rigorously designed, conducted, documented, and reported. During preparations for funding applications the librarian could help to assess the extent of uncertainty and identify relevant ongoing research. Second, librarian involvement in peer review could help to ensure the quality and reliability of published research. Biomedical journals might consider the role of a literature search reviewer who could review possible inadequacies in the literature search process for submitted papers. Such a position would be similar to the role of the statistical reviewer that is already well established in many biomedical journals. Indeed, Jeff erson and Deeks have mentioned a potential role for ``methodological expert reviewers'', although they do not specify librarians within this grouping. Third, research funders could make greater use of librarians during peer review of funding applications. As highlighted in the recommendations of the Lancet Research: Increasing Value, Reducing Waste Series, grant applicants are increasingly required to provide evidence that the research question for which they are applying for funding refl ects a demonstrable uncertainty that requires addressing. Librarians could be involved in peer reviewing the search strategies used to identify evidence in support of funding applications to identify any issues, including relevant evidence that has been missed by the literature search. Involvement of literature search specialist reviewers would ensure that only those proposals that have shown reliable and robust evidence of uncertainty would be considered for funding, thereby reducing waste in research. Establishing the three roles outlined above could contribute to more meticulous funding decisions and to the publication of better research. Waste in biomedical research is a serious issue with no single solution. Biomedical librarians are listening and are ready to respond to the calls to increase value and reduce waste. To fully realise the contribution that health science librarians could make, other stakeholder groups identifi ed in the Lancet REWARD Campaign would benefi t from recognising and utilising librarians\textquoteright{} essential skills.},
  doi       = {10.1016/s0140-6736(16)30241-0},
  file      = {:Kirtley2016 - Increasing Value and Reducing Waste in Biomedical Research_ Librarians Are Listening and Are Part of the Answer.pdf:PDF},
  publisher = {Elsevier BV},
  url       = {http://dx.doi.org/10.1016/S0140-6736(16)30241-0},
}

@Book{Gantert2023,
  author      = {Klaus Gantert and Margrit Lauber-Reymann},
  publisher   = {De Gruyter Saur},
  title       = {Informationsressourcen},
  year        = {2023},
  address     = {Berlin, Boston},
  isbn        = {9783110673272},
  doi         = {10.1515/9783110673272},
  file        = {:Gantert2023 - Informationsressourcen.pdf:PDF;:Gantert2023 - Informationsressourcen.epub:ePUB},
  lastchecked = {2023-07-12},
  url         = {https://doi.org/10.1515/9783110673272},
}

@Article{Dhippayom2023,
  author   = {Dhippayom, Teerapon and Rattanachaisit, Natnicha and Wateemongkollert, Apinya and Napim, Rawiwan and Chaiyakunapruk, Nathorn},
  journal  = {Cochrane Ev Synth},
  title    = {{Should CINAHL be used as one of the main databases for evidence synthesis of health services intervention?}},
  year     = {2023},
  number   = {5},
  pages    = {e12019},
  volume   = {1},
  abstract = {Abstract Introduction CINAHL is not listed as one of the minimum databases for systematic review (SR) of interventions in the Methodological Expectations of the Cochrane Intervention Review. Objective To determine additional studies uniquely identified from the CINAHL search in SR of health services interventions (HSI). Methods We searched PubMed from inception to October 1, 2022 to identify SRs of HSI that determined clinical or humanistic outcomes of HSI and used CINAHL. Out of 5655 Systematic reviews identified, we randomly selected 374 SRs and extracted all primary studies included. We then explored the bibliographic databases in which the journals of those studies were indexed. The outcome of interest was the number of studies uniquely available in CINHAL. We also performed a subgroup analysis based on the type of HSI. We performed descriptive statistics to report the study outcomes using Excel (Microsoft 365). Results A total of 7550 primary studies were identified from the 374 Systematic reviews that met the inclusion criteria. Of these studies, 7380 were journal publications that have been indexed in MEDLINE/PubMed (75.1\%), Scopus (74.5\%), Sciences Citation Index, SCI (54.7\%), Embase (48.1\%), and CINAHL (34.9\%). Only 83 out of 7380 (1.1\%) studies were published in journals that were uniquely indexed in CINAHL. The percentage of studies that were only available in other databases was 9.7\% (Scopus), 4.3\% (MEDLINE/PubMed), 1.6\% (SCI), and 0.3\% (Embase). The number of studies that were unique to CINAHL in specific types of HSI were: 24/1570 (1.5\%) for community health services, 20/1520 (1.3\%) for preventive health services, 45/3624 (1.2\%) for patient care, 8/1173 (0.7\%) for mental health services, and 18/2804 (0.6\%) for rehabilitation. Conclusion The gain of CINAHL to identify unique primary studies for SR of HSI appears minimal. The impact of missing studies uniquely available in CINAHL on SR summary or magnitude of effect estimates from meta-analysis requires further investigation.},
  doi      = {10.1002/cesm.12019},
  file     = {:Dhippayom2023 - Should CINAHL Be Used As One of the Main Databases for Evidence Synthesis of Health Services Intervention_.pdf:PDF},
  fjournal = {Cochrane Evidence Synthesis and Methods},
  keywords = {CINAHL, database, health services intervention, search},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cesm.12019},
}

@Article{VanNoorden2023,
  author    = {Van Noorden, Richard},
  journal   = {Nature},
  title     = {{ChatGPT}-like {AIs} are coming to major science search engines},
  year      = {2023},
  month     = aug,
  number    = {7973},
  pages     = {258--258},
  volume    = {620},
  doi       = {10.1038/d41586-023-02470-3},
  file      = {:VanNoorden2023 - ChatGPT like AIs Are Coming to Major Science Search Engines.pdf:PDF},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1038/d41586-023-02470-3},
}

@Article{Cooper2021,
  author    = {Chris Cooper and Sarah Dawson and Carol Lefebvre},
  journal   = {Res Synth Methods},
  title     = {{Searching for medical devices {\textendash} Practical guidance}},
  year      = {2021},
  month     = nov,
  number    = {1},
  pages     = {144--154},
  volume    = {13},
  doi       = {10.1002/jrsm.1524},
  file      = {:Cooper2021 - Searching for Medical Devices _ Practical Guidance.pdf:PDF},
  publisher = {Wiley},
}

@Article{Bragge2010,
  author   = {P. Bragge},
  journal  = {Injury},
  title    = {Asking good clinical research questions and choosing the right study design},
  year     = {2010},
  issn     = {0020-1383},
  month    = jul,
  note     = {Trauma Melbourne 2009 20-21st November 2009 Sofitel Melbourne on Collins, Melbourne & Trauma Research Methods and Practice Workshop 19th November 2009 Monash Conference Centre, Melbourne},
  pages    = {3--6},
  volume   = {41},
  abstract = {Clinicians and researchers seek answers to clinical research questions, primarily by accessing the results of clinical research studies. This paper moves the focus of research enquiry from getting answers to developing good clinical research questions. Using worked examples, the steps involved in refining questions drawn from various sources to create ‘answerable’ clinical research questions using the ‘PICO’ principle are described. Issues to consider in prioritising clinical research questions are also identified. Theoretical and practical considerations involved in choosing the right study design for a clinical research question are then discussed using the worked examples. These include:•Categorisation of questions according to their central clinical issues;•Use of preliminary literature searching to identify existing research and further refine questions;•Identifying whether a quantitative or qualitative research paradigm is best suited to a research question;•Hierarchies of evidence that rank study designs and how they vary according to central clinical issues;•Other factors influencing study design selection.},
  doi      = {10.1016/j.injury.2010.04.016},
  file     = {:Bragge2010 - Asking Good Clinical Research Questions and Choosing the Right Study Design.pdf:PDF},
  keywords = {Research question development, Research design, Biomedical research},
  url      = {https://www.sciencedirect.com/science/article/pii/S0020138310002688},
}

@Book{Bayer2023,
  author    = {Bayer, Oliver and Cascant Ortolano, Lorena and Filbert, Anna-Liesa and Hoffmann, Dorle and Schweizer, Stefanus},
  publisher = {Johannes Gutenberg-Universität Mainz},
  title     = {{Praxisleitfaden Systematische Reviews}},
  year      = {2023},
  address   = {Mainz},
  abstract  = {Der Praxisleitfaden beschreibt die Grundlagen bei der Erarbeitung eines Systematischen Reviews Schritt für Schritt. Zunächst werden verschiedene Review-Arten gegenüber einem Systematischen Review abgegrenzt. Es wird beschrieben, wie die Fragestellung erarbeitet und in eine Suchstrategie umgesetzt wird. Anschließend wird ein Protokoll erstellt und idealerweise in Prospero registriert. 
Ein großer Teil des Praxisleitfadens widmet sich der Literatursuche und -dokumentation. Es wird erläutert, wie die Suche vorzubereiten, die Datenbanken auszuwählen und Schritt für Schritt zu durchsuchen sind. Konkret wird auf die Datenbanken PubMed, Cochrane Library, Web of Science, CINAHL und PsycInfo eingegangen.
Vor der Auswahl der relevanten Studien im Screening-Prozess sollten die Dubletten der Treffer aussortiert werden. Es wird beispielhaft ein Tool zur Datenextraktion – Covidence – vorgestellt und kurz auf die qualitative wie quantitative Zusammenfassung der Daten eingegangen. Zu guter Letzt werden anhand der PRISMA Checklisten Hinweise zum Publizieren gegeben.},
  doi       = {10.25358/openscience-8575},
  file      = {:Bayer2023 - Praxisleitfaden Systematische Reviews.pdf:PDF},
  language  = {ger},
}

@Article{Peters2020,
  author             = {Peters, Micah D. J. and Marnie, Casey and Tricco, Andrea C. and Pollock, Danielle and Munn, Zachary and Alexander, Lyndsay and McInerney, Patricia and Godfrey, Christina M. and Khalil, Hanan},
  journal            = {JBI Evid Synth},
  title              = {Updated methodological guidance for the conduct of scoping reviews.},
  year               = {2020},
  month              = {Oct},
  pages              = {2119--2126},
  volume             = {18},
  electronic-issn    = {2689-8381},
  linking-issn       = {2689-8381},
  abstract           = {OBJECTIVE: The objective of this paper is to describe the updated methodological guidance for conducting a JBI scoping review, with a focus on new updates to the approach and development of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (the PRISMA-ScR). INTRODUCTION: Scoping reviews are an increasingly common approach to informing decision-making and research based on the identification and examination of the literature on a given topic or issue. Scoping reviews draw on evidence from any research methodology and may also include evidence from non-research sources, such as policy. In this manner, scoping reviews provide a comprehensive overview to address broader review questions than traditionally more specific systematic reviews of effectiveness or qualitative evidence. The increasing popularity of scoping reviews has been accompanied by the development of a reporting guideline: the PRISMA-ScR. In 2014, the JBI Scoping Review Methodology Group developed guidance for scoping reviews that received minor updates in 2017 and was most recently updated in 2020. The updates reflect ongoing and substantial developments in approaches to scoping review conduct and reporting. As such, the JBI Scoping Review Methodology Group recognized the need to revise the guidance to align with the current state of knowledge and reporting standards in evidence synthesis. METHODS: Between 2015 and 2020, the JBI Scoping Review Methodology Group expanded its membership; extensively reviewed the literature; engaged via annual face-to-face meetings, regular teleconferences, and email correspondence; sought advice from methodological experts; facilitated workshops; and presented at scientific conferences. This process led to updated guidance for scoping reviews published in the JBI Manual for Evidence Synthesis. The updated chapter was endorsed by JBI's International Scientific Committee in 2020. RESULTS: The updated JBI guidance for scoping reviews includes additional guidance on several methodological issues, such as when a scoping review is (or is not) appropriate, and how to extract, analyze, and present results, and provides clarification for implications for practice and research. Furthermore, it is aligned with the PRISMA-ScR to ensure consistent reporting. CONCLUSIONS: The latest JBI guidance for scoping reviews provides up-to-date guidance that can be used by authors when conducting a scoping review. Furthermore, it aligns with the PRISMA-ScR, which can be used to report the conduct of a scoping review. A series of ongoing and future methodological projects identified by the JBI Scoping Review Methodology Group to further refine the methodology are planned.},
  address            = {United States},
  article-doi        = {10.11124/JBIES-20-00167},
  article-pii        = {02174543-202010000-00004},
  completed          = {20210514},
  doi                = {10.11124/JBIES-20-00167},
  file               = {:Peters2020 - Updated Methodological Guidance for the Conduct of Scoping Reviews..pdf:PDF},
  history            = {2021/05/15 06:00 [medline]},
  issue              = {10},
  keywords           = {Knowledge, Policy, *Publications, *Research Design, Surveys and Questionnaires},
  language           = {eng},
  location-id        = {10.11124/JBIES-20-00167 [doi]},
  nlm-unique-id      = {101764819},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20210514},
  source             = {JBI Evid Synth. 2020 Oct;18(10):2119-2126. doi: 10.11124/JBIES-20-00167.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {JBI Evid Synth},
}

@Article{Peters2021,
  author             = {Peters, Micah D. J. and Marnie, Casey and Tricco, Andrea C. and Pollock, Danielle and Munn, Zachary and Alexander, Lyndsay and McInerney, Patricia and Godfrey, Christina M. and Khalil, Hanan},
  journal            = {JBI Evid Implement},
  title              = {Updated methodological guidance for the conduct of scoping reviews.},
  year               = {2021},
  month              = {Mar},
  pages              = {3--10},
  volume             = {19},
  electronic-issn    = {2691-3321},
  linking-issn       = {2691-3321},
  abstract           = {OBJECTIVE: The objective of this paper is to describe the updated methodological guidance for conducting a JBI scoping review, with a focus on new updates to the approach and development of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (the PRISMA-ScR). INTRODUCTION: Scoping reviews are an increasingly common approach to informing decision-making and research based on the identification and examination of the literature on a given topic or issue. Scoping reviews draw on evidence from any research methodology and may also include evidence from non-research sources, such as policy. In this manner, scoping reviews provide a comprehensive overview to address broader review questions than traditionally more specific systematic reviews of effectiveness or qualitative evidence. The increasing popularity of scoping reviews has been accompanied by the development of a reporting guideline: the PRISMA-ScR. In 2014, the JBI Scoping Review Methodology Group developed guidance for scoping reviews that received minor updates in 2017 and was most recently updated in 2020. The updates reflect ongoing and substantial developments in approaches to scoping review conduct and reporting. As such, the JBI Scoping Review Methodology Group recognized the need to revise the guidance to align with the current state of knowledge and reporting standards in evidence synthesis. METHODS: Between 2015 and 2020, the JBI Scoping Review Methodology Group expanded its membership; extensively reviewed the literature; engaged via annual face-to-face meetings, regular teleconferences, and email correspondence; sought advice from methodological experts; facilitated workshops; and presented at scientific conferences. This process led to updated guidance for scoping reviews published in the JBI Manual for Evidence Synthesis. The updated chapter was endorsed by JBI's International Scientific Committee in 2020. RESULTS: The updated JBI guidance for scoping reviews includes additional guidance on several methodological issues, such as when a scoping review is (or is not) appropriate, and how to extract, analyze, and present results, and provides clarification for implications for practice and research. Furthermore, it is aligned with the PRISMA-ScR to ensure consistent reporting. CONCLUSIONS: The latest JBI guidance for scoping reviews provides up-to-date guidance that can be used by authors when conducting a scoping review. Furthermore, it aligns with the PRISMA-ScR, which can be used to report the conduct of a scoping review. A series of ongoing and future methodological projects identified by the JBI Scoping Review Methodology Group to further refine the methodology are planned.},
  address            = {United States},
  article-doi        = {10.1097/XEB.0000000000000277},
  article-pii        = {02205615-202103000-00002},
  completed          = {20210810},
  doi                = {10.1097/XEB.0000000000000277},
  file               = {:Peters2021 - Updated Methodological Guidance for the Conduct of Scoping Reviews..pdf:PDF},
  history            = {2021/08/11 06:00 [medline]},
  issue              = {1},
  keywords           = {Guidelines as Topic, Research Design/*standards},
  language           = {eng},
  location-id        = {10.1097/XEB.0000000000000277 [doi]},
  nlm-unique-id      = {101772772},
  owner              = {NLM},
  publication-status = {ppublish},
  revised            = {20210810},
  source             = {JBI Evid Implement. 2021 Mar;19(1):3-10. doi: 10.1097/XEB.0000000000000277.},
  status             = {MEDLINE},
  subset             = {IM},
  title-abbreviation = {JBI Evid Implement},
}

@Article{Pollock2021,
  author                 = {Pollock, Danielle and Davies, Ellen L. and Peters, Micah D. J. and Tricco, Andrea C. and Alexander, Lyndsay and McInerney, Patricia and Godfrey, Christina M. and Khalil, Hanan and Munn, Zachary},
  journal                = {J Adv Nurs},
  title                  = {Undertaking a scoping review: A practical guide for nursing and midwifery students, clinicians, researchers, and academics.},
  year                   = {2021},
  month                  = {Apr},
  pages                  = {2102--2113},
  volume                 = {77},
  electronic-issn        = {1365-2648},
  linking-issn           = {0309-2402},
  print-issn             = {0309-2402},
  abstract               = {AIM: The aim of this study is to discuss the available methodological resources and best-practice guidelines for the development and completion of scoping reviews relevant to nursing and midwifery policy, practice, and research. DESIGN: Discussion Paper. DATA SOURCES: Scoping reviews that exemplify best practice are explored with reference to the recently updated JBI scoping review guide (2020) and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Scoping Review extension (PRISMA-ScR). IMPLICATIONS FOR NURSING AND MIDWIFERY: Scoping reviews are an increasingly common form of evidence synthesis. They are used to address broad research questions and to map evidence from a variety of sources. Scoping reviews are a useful form of evidence synthesis for those in nursing and midwifery and present opportunities for researchers to review a broad array of evidence and resources. However, scoping reviews still need to be conducted with rigour and transparency. CONCLUSION: This study provides guidance and advice for researchers and clinicians who are preparing to undertake an evidence synthesis and are considering a scoping review methodology in the field of nursing and midwifery. IMPACT: With the increasing popularity of scoping reviews, criticism of the rigour, transparency, and appropriateness of the methodology have been raised across multiple academic and clinical disciplines, including nursing and midwifery. This discussion paper provides a unique contribution by discussing each component of a scoping review, including: developing research questions and objectives; protocol development; developing eligibility criteria and the planned search approach; searching and selecting the evidence; extracting and analysing evidence; presenting results; and summarizing the evidence specifically for the fields of nursing and midwifery. Considerations for when to select this methodology and how to prepare a review for publication are also discussed. This approach is applied to the disciplines of nursing and midwifery to assist nursing and/or midwifery students, clinicians, researchers, and academics.},
  address                = {England},
  article-doi            = {10.1111/jan.14743},
  article-pii            = {JAN14743},
  completed              = {20210618},
  doi                    = {10.1111/jan.14743},
  electronic-publication = {20210204},
  file                   = {:Pollock2021 - Undertaking a Scoping Review_ a Practical Guide for Nursing and Midwifery Students, Clinicians, Researchers, and Academics..pdf:PDF},
  grantno                = {AT is supported by the Tier 2 Canada Research Chair in Knowledge Synthesis/},
  history                = {2021/02/05 06:06 [entrez]},
  issue                  = {4},
  keywords               = {Female, Humans, *Midwifery, Pregnancy, Research Design, Research Personnel, Students, PRISMA-ScR, evidence synthesis, methodology, midwifery, nursing, reporting, scoping review},
  language               = {eng},
  location-id            = {10.1111/jan.14743 [doi]},
  nlm-unique-id          = {7609811},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20220421},
  source                 = {J Adv Nurs. 2021 Apr;77(4):2102-2113. doi: 10.1111/jan.14743. Epub 2021 Feb 4.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {J Adv Nurs},
}

@Article{Khalil2022,
  author                 = {Khalil, Hanan and McInerney, Patricia and Pollock, Danielle and Alexander, Lindsay and Munn, Zac and Tricco, Andrea C. and Godfrey, Christina M. and Peters, Micah D. J.},
  journal                = {J Clin Pharm Ther},
  title                  = {Practical guide to undertaking scoping reviews for pharmacy clinicians, researchers and policymakers.},
  year                   = {2022},
  month                  = {Feb},
  pages                  = {129--134},
  volume                 = {47},
  electronic-issn        = {1365-2710},
  linking-issn           = {0269-4727},
  abstract               = {WHAT IS KNOWN AND OBJECTIVE: Scoping reviews are a valuable evidence synthesis methodology. They can be used to map the evidence related to any topic to allow examination of practice, methods, policy and where (and how) future research could be undertaken. As such, they are a useful form of evidence synthesis for pharmacy clinicians, researchers and policymakers to review a broad range of evidence sources. COMMENT: This commentary presents the most comprehensive and up to date methodology for scoping reviews published by Joanna Briggs Institute (JBI). This approach builds upon two older approaches by Arksey and O'Malley, and Levac. To assist reviewers working in the field of pharmacy with planning and conducting scoping reviews, this paper describes how to undertake scoping reviews from inception to publication with specific examples related to pharmacy topics. WHAT IS NEW AND CONCLUSION: The JBI scoping review methodology is a valuable evidence synthesis approach to the field of pharmacy and therapeutics. This approach can assist pharmacy clinicians, researchers and policymakers to gain an understanding of the extant literature, to identify gaps, to explore concepts, characteristics and to examine current practice.},
  address                = {England},
  article-doi            = {10.1111/jcpt.13558},
  completed              = {20220304},
  doi                    = {10.1111/jcpt.13558},
  electronic-publication = {20211029},
  file                   = {:Khalil2022 - Practical Guide to Undertaking Scoping Reviews for Pharmacy Clinicians, Researchers and Policymakers..pdf:PDF},
  history                = {2021/10/29 12:32 [entrez]},
  issue                  = {2},
  keywords               = {Administrative Personnel, Algorithms, Humans, Pharmacists, Research Design, Research Personnel, Systematic Reviews as Topic/*methods/standards, evidence synthesis, mapping, methodology, scoping reviews},
  language               = {eng},
  location-id            = {10.1111/jcpt.13558 [doi]},
  nlm-unique-id          = {8704308},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20220304},
  source                 = {J Clin Pharm Ther. 2022 Feb;47(2):129-134. doi: 10.1111/jcpt.13558. Epub 2021 Oct 29.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {J Clin Pharm Ther},
}

@Book{Kuhlen2022,
  author    = {Kuhlen, Rainer and Lewandowski, Dirk and Semar, Wolfgang and Womser-Hacker, Christa},
  publisher = {Walter de Gruyter GmbH},
  title     = {{Grundlagen der Informationswissenschaft}},
  year      = {2022},
  address   = {Berlin/Boston, GERMANY},
  isbn      = {9783110769043},
  file      = {:Kuhlen2022 - Grundlagen Der Informationswissenschaft.pdf:PDF},
  refid     = {7143973},
  url       = {http://ebookcentral.proquest.com/lib/unibern/detail.action?docID=7143973},
}

@Book{Zipkin2023,
  editor    = {Daniella A. Zipkin},
  publisher = {Springer International Publishing},
  title     = {{Teaching Evidence-Based Medicine. A Toolkit for Educators}},
  year      = {2023},
  edition   = {1},
  isbn      = {978-3-031-11174-7},
  month     = dec,
  doi       = {10.1007/978-3-031-11174-7},
  file      = {:Zipkin2023 - Teaching Evidence Based Medicine. a Toolkit for Educators.pdf:PDF},
  owner     = {Springer Nature Switzerland AG 2023},
  url       = {https://doi.org/10.1007/978-3-031-11174-7},
}

@Book{Heneghan2006,
  editor    = {Carl Heneghan and Douglas Badenoch},
  publisher = {Wiley},
  title     = {{Evidence-based Medicine Toolkit}},
  year      = {2006},
  isbn      = {9780470750605},
  month     = jan,
  doi       = {10.1002/9780470750605},
  file      = {:Heneghan2006 - Evidence Based Medicine Toolkit.pdf:PDF},
  url       = {https://doi.org/10.1002/9780470750605},
}

﻿
@Article{Orel2023,
  author   = {Orel, Erol and Ciglenecki, Iza and Thiabaud, Amaury and Temerev, Alexander and Calmy, Alexandra and Keiser, Olivia and Merzouki, Aziza},
  journal  = {J Med Internet Res},
  title    = {{An Automated Literature Review Tool (LiteRev) for Streamlining and Accelerating Research Using Natural Language Processing and Machine Learning: Descriptive Performance Evaluation Study}},
  year     = {2023},
  issn     = {1438-8871},
  month    = sep,
  pages    = {e39736},
  volume   = {25},
  abstract = {Background: Literature reviews (LRs) identify, evaluate, and synthesize relevant papers to a particular research question to advance understanding and support decision-making. However, LRs, especially traditional systematic reviews, are slow, resource-intensive, and become outdated quickly. Objective: LiteRev is an advanced and enhanced version of an existing automation tool designed to assist researchers in conducting LRs through the implementation of cutting-edge technologies such as natural language processing and machine learning techniques. In this paper, we present a comprehensive explanation of LiteRev's capabilities, its methodology, and an evaluation of its accuracy and efficiency to a manual LR, highlighting the benefits of using LiteRev. Methods: Based on the user's query, LiteRev performs an automated search on a wide range of open-access databases and retrieves relevant metadata on the resulting papers, including abstracts or full texts when available. These abstracts (or full texts) are text processed and represented as a term frequency-inverse document frequency matrix. Using dimensionality reduction (pairwise controlled manifold approximation) and clustering (hierarchical density-based spatial clustering of applications with noise) techniques, the corpus is divided into different topics described by a list of the most important keywords. The user can then select one or several topics of interest, enter additional keywords to refine its search, or provide key papers to the research question. Based on these inputs, LiteRev performs a k-nearest neighbor (k-NN) search and suggests a list of potentially interesting papers. By tagging the relevant ones, the user triggers new k-NN searches until no additional paper is suggested for screening. To assess the performance of LiteRev, we ran it in parallel to a manual LR on the burden and care for acute and early HIV infection in sub-Saharan Africa. We assessed the performance of LiteRev using true and false predictive values, recall, and work saved over sampling. Results: LiteRev extracted, processed, and transformed text into a term frequency-inverse document frequency matrix of 631 unique papers from PubMed. The topic modeling module identified 16 topics and highlighted 2 topics of interest to the research question. Based on 18 key papers, the k-NNs module suggested 193 papers for screening out of 613 papers in total (31.5{\%} of the whole corpus) and correctly identified 64 relevant papers out of the 87 papers found by the manual abstract screening (recall rate of 73.6{\%}). Compared to the manual full text screening, LiteRev identified 42 relevant papers out of the 48 papers found manually (recall rate of 87.5{\%}). This represents a total work saved over sampling of 56{\%}. Conclusions: We presented the features and functionalities of LiteRev, an automation tool that uses natural language processing and machine learning methods to streamline and accelerate LRs and support researchers in getting quick and in-depth overviews on any topic of interest.},
  day      = {15},
  doi      = {10.2196/39736},
  file     = {:Orel2023 - An Automated Literature Review Tool (LiteRev) for Streamlining and Accelerating Research.pdf:PDF},
  keywords = {LiteRev; literature review; natural language processing; machine learning; automation; clustering; topic; acute; early; HIV},
  url      = {https://www.jmir.org/2023/1/e39736},
}

@TechReport{2022,
  author    = {UNESCO and InterAcademy Partnership},
  title     = {Identifying predatory academic journals and conferences},
  year      = {2022},
  month     = nov,
  doi       = {10.54677/vqwq5022},
  file      = {:2022 - Identifying Predatory Academic Journals and Conferences.pdf:PDF},
  publisher = {{UNESCO}},
  url       = {https://doi.org/10.54677/vqwq5022},
}

@Book{SuehlStrohmenger2024,
  editor      = {Wilfried Sühl-Strohmenger and Inka Tappenbeck},
  publisher   = {De Gruyter Saur},
  title       = {{Praxishandbuch Wissenschaftliche Bibliothekar:innen}},
  year        = {2024},
  address     = {Berlin, Boston},
  isbn        = {9783110790375},
  doi         = {10.1515/9783110790375},
  file        = {:SuehlStrohmenger2024 - Praxishandbuch Wissenschaftliche Bibliothekar_innen.pdf:PDF},
  keywords    = {Wissenschaftliche Bibliothek; Wissenschaftlicher Dienst; Rollenwandel; Digitalisierung},
  lastchecked = {2023-11-20},
  url         = {https://doi.org/10.1515/9783110790375},
}

@Article{Muka2020,
  author                 = {Muka, Taulant and Glisic, Marija and Milic, Jelena and Verhoog, Sanne and Bohlius, Julia and Bramer, Wichor and Chowdhury, Rajiv and Franco, Oscar H.},
  journal                = {Eur J Epidemiol},
  title                  = {A 24-step guide on how to design, conduct, and successfully publish a systematic review and meta-analysis in medical research.},
  year                   = {2020},
  month                  = jan,
  pages                  = {49--60},
  volume                 = {35},
  electronic-issn        = {1573-7284},
  linking-issn           = {0393-2990},
  abstract               = {To inform evidence-based practice in health care, guidelines and policies require accurate identification, collation, and integration of all available evidence in a comprehensive, meaningful, and time-efficient manner. Approaches to evidence synthesis such as carefully conducted systematic reviews and meta-analyses are essential tools to summarize specific topics. Unfortunately, not all systematic reviews are truly systematic, and their quality can vary substantially. Since well-conducted evidence synthesis typically involves a complex set of steps, we believe formulating a cohesive, step-by-step guide on how to conduct a systemic review and meta-analysis is essential. While most of the guidelines on systematic reviews focus on how to report or appraise systematic reviews, they lack guidance on how to synthesize evidence efficiently. To facilitate the design and development of evidence syntheses, we provide a clear and concise, 24-step guide on how to perform a systematic review and meta-analysis of observational studies and clinical trials. We describe each step, illustrate it with concrete examples, and provide relevant references for further guidance. The 24-step guide (1) simplifies the methodology of conducting a systematic review, (2) provides healthcare professionals and researchers with methodologically sound tools for conducting systematic reviews and meta-analyses, and (3) it can enhance the quality of existing evidence synthesis efforts. This guide will help its readers to better understand the complexity of the process, appraise the quality of published systematic reviews, and better comprehend (and use) evidence from medical literature.},
  address                = {Netherlands},
  article-doi            = {10.1007/s10654-019-00576-5},
  article-pii            = {10.1007/s10654-019-00576-5},
  completed              = {20230818},
  doi                    = {10.1007/s10654-019-00576-5},
  electronic-publication = {20191113},
  file                   = {:Muka2020 - A 24 Step Guide on How to Design, Conduct, and Successfully Publish a Systematic Review and Meta Analysis in Medical Research..pdf:PDF},
  grantno                = {RG/18/13/33946/BHF_/British Heart Foundation/United Kingdom},
  history                = {2019/11/14 06:00 [entrez]},
  issue                  = {1},
  keywords               = {Humans, Guidelines as Topic, *Meta-Analysis as Topic, *Systematic Reviews as Topic, 24 Steps, Evidence synthesis, Guideline, Meta-analysis, Systematic review},
  language               = {eng},
  location-id            = {10.1007/s10654-019-00576-5 [doi]},
  nlm-unique-id          = {8508062},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20230818},
  source                 = {Eur J Epidemiol. 2020 Jan;35(1):49-60. doi: 10.1007/s10654-019-00576-5. Epub 2019 Nov 13.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {Eur J Epidemiol},
}

@Article{FusarPoli2018,
  author    = {Paolo Fusar-Poli and Joaquim Radua},
  journal   = {Evid Based Ment Health},
  title     = {Ten simple rules for conducting umbrella reviews},
  year      = {2018},
  issn      = {1362-0347},
  note      = {PMID: 30006442 PMCID: PMC10270421},
  number    = {3},
  pages     = {95--100},
  volume    = {21},
  abstract  = {Objective Evidence syntheses such as systematic reviews and meta-analyses provide a rigorous and transparent knowledge base for translating clinical research into decisions, and thus they represent the basic unit of knowledge in medicine. Umbrella reviews are reviews of previously published systematic reviews or meta-analyses. Therefore, they represent one of the highest levels of evidence synthesis currently available, and are becoming increasingly influential in biomedical literature. However, practical guidance on how to conduct umbrella reviews is relatively limited.Methods We present a critical educational review of published umbrella reviews, focusing on the essential practical steps required to produce robust umbrella reviews in the medical field.Results The current manuscript discusses 10 key points to consider for conducting robust umbrella reviews. The points are: ensure that the umbrella review is really needed, prespecify the protocol, clearly define the variables of interest, estimate a common effect size, report the heterogeneity and potential biases, perform a stratification of the evidence, conduct sensitivity analyses, report transparent results, use appropriate software and acknowledge the limitations. We illustrate these points through recent examples from umbrella reviews and suggest specific practical recommendations.Conclusions The current manuscript provides a practical guidance for conducting umbrella reviews in medical areas. Researchers, clinicians and policy makers might use the key points illustrated here to inform the planning, conduction and reporting of umbrella reviews in medicine.},
  doi       = {10.1136/ebmental-2018-300014},
  eprint    = {https://mentalhealth.bmj.com/content/21/3/95.full.pdf},
  file      = {:FusarPoli2018 - Ten Simple Rules for Conducting Umbrella Reviews.pdf:PDF},
  publisher = {Royal College of Psychiatrists},
  url       = {https://mentalhealth.bmj.com/content/21/3/95},
}

@Article{Booth2008,
  author  = {Booth, Andrew},
  journal = {Health Info Libr J},
  title   = {Unpacking your literature search toolbox: on search styles and tactics},
  year    = {2008},
  number  = {4},
  pages   = {313--317},
  volume  = {25},
  doi     = {10.1111/j.1471-1842.2008.00825.x},
  eprint  = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1471-1842.2008.00825.x},
  file    = {:Booth2008 - Unpacking Your Literature Search Toolbox_ on Search Styles and Tactics.pdf:PDF},
  url     = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1471-1842.2008.00825.x},
}

@Article{Hirt2023,
  author       = {Julian Hirt and Thomas Nordhausen and Thomas Fuerst and Hannah Ewald and {TARCiS study group} and Christian Appenzeller-Herzog},
  journal      = {medRxiv},
  title        = {{The TARCiS statement: Guidance on terminology, application, and reporting of citation searching}},
  year         = {2023},
  abstract     = {Evidence syntheses adhering to systematic literature searching techniques are a cornerstone of evidence-based health care. Beyond term-based searching in electronic databases, citation searching is a prevalent search technique to identify relevant sources of evidence. However, for decades, citation searching methodology and terminology has not been standardized. We performed an evidence-guided four-round Delphi consensus study with 27 international methodological experts in order to develop the Terminology, Application, and Reporting of Citation Searching (TARCiS) statement. TARCiS comprises ten specific recommendations on when and how to conduct and report citation searching in the context of systematic literature searches and four research priorities. We encourage systematic reviewers and information specialists to incorporate TARCiS into their standardized workflows.Competing Interest StatementAll core and study group authors have completed the ICMJE uniform disclosure form at www.icmje.org/disclosure-of-interest/: JS received support from Alfred P. Sloan Foundation; JS was funded by NIH, NSF, US Office of Research Integrity, United States Institute of Museum and Library Services, UIUC; SK was funded by Cancer Research UK (grant C49297/A27294); the current work was unrelated to this funding; JS received book royalities from Morgan \&amp; Claypool; CAH received payments to his institution for a citation searching workshop by University of Applied Sciences Northwestern Switzerland; JH received consulting fees by Medical University Brandenburg and payments for lecturing by University of Applied Sciences Northwestern Switzerland, Catholic University of Applied Sciences, and Netzwerk Fachbibliotheken Gesundheit; JG received payments for lecturing by York Health Economics Consortium; MJS received consulting fees at Canadian Agency for Drugs and Technologies and National Academy of Medicine (formerly Institute of Medicine) and for lecturing and support for attending a meeting at Institute for Quality and Efficiency in Health Care; JS received consulting fees or honoraria from European Commission, Jump ARCHES, NSF, Medical Library Association; AW received payments to her institution for a citation analysis workshop run via York Health Economics Consortium; SK declares non-financial interests as a member of the UK EQUATOR Centre and a co-author of the PRISMA-S reporting guideline; PL is an employee of the National Institute for Health and Care Excellence; MR received payments by the Medical Library Association and declares non-financial interests as a member of the PhD program affiliated with BMJ Publishing Group; MJS has leadership role as Secretary of Ottawa Valley Health Library Association; JS received travel support by UIUC, contributes to CREC (Communication of Retractions, Removals, and Expressions of Concern) Working Group, has non-financial associations with Crossref, COPE, International Association of Scientific, Technical and Medical Publishers, the National Information Standards Organization; and the Center for Scientific Integrity (parent organization of Retraction Watch), and declares the National Information Standards Organization as a subawardee on her Alfred P. Sloan Foundation grant G-2022-19409; AB is a co-convenor of the Cochrane Qualitative and Implementation Methods Group and has authored methodological guidance on literature searching; all other authors have no competing interests to disclose.Funding StatementThe authors did not receive a specific grant for this study.Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:We did not anticipate panelists to be vulnerable and, with regard to the Swiss Human Research Act, our research did not concern human diseases nor the structure and function of the human body. Thus, we did not apply for ethical approval. The landing page of each Delphi round contained information on the study aim, data management, and data security. Panelists{\textquoteright} assessments were anonymous to other panelists but open to the study team. Panelists were aware that taking part indicated consent to participate. They did not receive an incentive for participation and could leave the process at any time. We prespecified this approach in our peer-reviewed study protocol: https://f1000research.com/articles/9-1386/v3I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines, such as any relevant EQUATOR Network research reporting checklist(s) and other pertinent material, if applicable.YesThe survey sheets and questionnaires that were used for this study are included in the supplementary content. Data generated and analyzed during this study (except sociodemographic information) is available on Open Science Framework (OSF; https://osf.io/y7kh3).https://osf.io/y7kh3},
  doi          = {10.1101/2023.10.25.23297543},
  elocation-id = {2023.10.25.23297543},
  eprint       = {https://www.medrxiv.org/content/early/2023/10/26/2023.10.25.23297543.full.pdf},
  file         = {:Hirt2023 - The TARCiS Statement_ Guidance on Terminology, Application, and Reporting of Citation Searching.pdf:PDF},
  publisher    = {Cold Spring Harbor Laboratory Press},
  url          = {https://www.medrxiv.org/content/early/2023/10/26/2023.10.25.23297543},
}

@Article{Janka2024,
  author    = {Janka, Heidrun and Metzendorf, Maria-Inti},
  journal   = {JEAHIL},
  title     = {High precision but variable recall – comparing the performance of five deduplication tools},
  year      = {2024},
  issn      = {1841-0715},
  month     = mar,
  number    = {1},
  pages     = {12--17},
  volume    = {20},
  doi       = {10.32384/jeahil20607},
  file      = {:Janka2024 - High Precision but Variable Recall – Comparing the Performance of Five Deduplication Tools.pdf:PDF},
  publisher = {European Association for Health Information and Libraries EAHIL},
  url       = {https://dx.doi.org/10.32384/jeahil20607},
}

@Article{Foster2015,
  author  = {Margaret J. Foster},
  journal = {JEAHIL},
  title   = {Overview of the role of librarians in systematic reviews: From expert search to project manager},
  year    = {2015},
  number  = {2},
  pages   = {3--7},
  volume  = {11},
  eprint  = {https://hdl.handle.net/1969.1/169677},
  file    = {:Foster2015 - Overview of the Role of Librarians in Systematic Reviews_ from Expert Search to Project Manager.pdf:PDF},
  url     = {https://hdl.handle.net/1969.1/169677},
}

@Article{Koffel2015,
  author    = {Koffel, Jonathan B.},
  journal   = {PLOS ONE},
  title     = {{Use of Recommended Search Strategies in Systematic Reviews and the Impact of Librarian Involvement: A Cross-Sectional Survey of Recent Authors}},
  year      = {2015},
  month     = may,
  number    = {5},
  pages     = {1--13},
  volume    = {10},
  abstract  = {Background Previous research looking at published systematic reviews has shown that their search strategies are often suboptimal and that librarian involvement, though recommended, is low. Confidence in the results, however, is limited due to poor reporting of search strategies the published articles.   Objectives To more accurately measure the use of recommended search methods in systematic reviews, the levels of librarian involvement, and whether librarian involvement predicts the use of recommended methods.   Methods A survey was sent to all authors of English-language systematic reviews indexed in the Database of Abstracts of Reviews of Effects (DARE) from January 2012 through January 2014. The survey asked about their use of search methods recommended by the Institute of Medicine, Cochrane Collaboration, and the Agency for Healthcare Research and Quality and if and how a librarian was involved in the systematic review. Rates of use of recommended methods and librarian involvement were summarized. The impact of librarian involvement on use of recommended methods was examined using a multivariate logistic regression.   Results 1560 authors completed the survey. Use of recommended search methods ranged widely from 98% for use of keywords to 9% for registration in PROSPERO and were generally higher than in previous studies. 51% of studies involved a librarian, but only 64% acknowledge their assistance. Librarian involvement was significantly associated with the use of 65% of recommended search methods after controlling for other potential predictors. Odds ratios ranged from 1.36 (95% CI 1.06 to 1.75) for including multiple languages to 3.07 (95% CI 2.06 to 4.58) for using controlled vocabulary.   Conclusions Use of recommended search strategies is higher than previously reported, but many methods are still under-utilized. Librarian involvement predicts the use of most methods, but their involvement is under-reported within the published article.},
  doi       = {10.1371/journal.pone.0125931},
  file      = {:Koffel2015 - Use of Recommended Search Strategies in Systematic Reviews and the Impact of Librarian Involvement_ a Cross Sectional Survey of Recent Authors.pdf:PDF},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0125931},
}

@Article{Fuchs2024,
  author                 = {Fuchs, Alexander and Koepp, Gabriela and Huber, Markus and Aebli, Jonas and Afshari, Arash and Bonfiglio, Rachele and Greif, Robert and Lusardi, Andrea C. and Romero, Carolina S. and von Gernler, Marc and Disma, Nicola and Riva, Thomas},
  journal                = {Brit J Anaesth},
  title                  = {Apnoeic oxygenation during paediatric tracheal intubation: a systematic review and meta-analysis.},
  year                   = {2024},
  month                  = feb,
  note                   = {PMID: 38030551},
  pages                  = {392--406},
  volume                 = {132},
  electronic-issn        = {1471-6771},
  linking-issn           = {0007-0912},
  abstract               = {BACKGROUND: Supplemental oxygen administration by apnoeic oxygenation during laryngoscopy for tracheal intubation is intended to prolong safe apnoea time, reduce the risk of hypoxaemia, and increase the success rate of first-attempt tracheal intubation under general anaesthesia. This systematic review examined the efficacy and effectiveness of apnoeic oxygenation during tracheal intubation in children. METHODS: This systematic review and meta-analysis included randomised controlled trials and non-randomised studies in paediatric patients requiring tracheal intubation, evaluating apnoeic oxygenation by any method compared with patients without apnoeic oxygenation. Searched databases were MEDLINE, Embase, Cochrane Library, CINAHL, ClinicalTrials.gov, International Clinical Trials Registry Platform (ICTRP), Scopus, and Web of Science from inception to March 22, 2023. Data extraction and risk of bias assessment followed the Grading of Recommendations Assessment, Development, and Evaluation (GRADE) recommendation. RESULTS: After initial selection of 40 708 articles, 15 studies summarising 9802 children were included (10 randomised controlled trials, four pre-post studies, one prospective observational study) published between 1988 and 2023. Eight randomised controlled trials were included for meta-analysis (n=1070 children; 803 from operating theatres, 267 from neonatal intensive care units). Apnoeic oxygenation increased intubation first-pass success with no physiological instability (risk ratio [RR] 1.27, 95% confidence interval [CI] 1.03-1.57, P=0.04, I(2)=0), higher oxygen saturation during intubation (mean difference 3.6%, 95% CI 0.8-6.5%, P=0.02, I(2)=63%), and decreased incidence of hypoxaemia (RR 0.24, 95% CI 0.17-0.33, P<0.01, I(2)=51%) compared with no supplementary oxygen administration. CONCLUSION: This systematic review with meta-analysis confirms that apnoeic oxygenation during tracheal intubation of children significantly increases first-pass intubation success rate. Furthermore, apnoeic oxygenation enables stable physiological conditions by maintaining oxygen saturation within the normal range. CLINICAL TRIAL REGISTRATION: Protocol registered prospectively on PROSPERO (registration number: CRD42022369000) on December 2, 2022.},
  address                = {England},
  article-doi            = {10.1016/j.bja.2023.10.039},
  article-pii            = {S0007-0912(23)00622-0},
  completed              = {20240122},
  doi                    = {10.1016/j.bja.2023.10.039},
  electronic-publication = {20231128},
  file                   = {:Fuchs2024 - Apnoeic Oxygenation during Paediatric Tracheal Intubation_ a Systematic Review and Meta Analysis..pdf:PDF},
  history                = {2023/11/29 22:06 [entrez]},
  issue                  = {2},
  keywords               = {Infant, Newborn, Humans, Child, *Intubation, Intratracheal/adverse effects/methods, *Respiration, Artificial/adverse effects, Hypoxia/prevention & control/etiology, Oxygen Inhalation Therapy/adverse effects, Oxygen, Randomized Controlled Trials as Topic, Observational Studies as Topic, airway, apnoea, apnoeic oxygenation, paediatric anaesthesia, supplemental oxygen, tracheal intubation},
  language               = {eng},
  location-id            = {10.1016/j.bja.2023.10.039 [doi]},
  nlm-unique-id          = {0372541},
  owner                  = {NLM},
  publication-status     = {ppublish},
  registry-number        = {S88TT14065 (Oxygen)},
  revised                = {20240417},
  source                 = {Br J Anaesth. 2024 Feb;132(2):392-406. doi: 10.1016/j.bja.2023.10.039. Epub 2023 Nov 28.},
  status                 = {MEDLINE},
  subset                 = {IM},
  termowner              = {NOTNLM},
  title-abbreviation     = {Br J Anaesth},
}

@Book{Cherry2024,
  editor    = {Cherry, M. Gemma and Dickson, Rumona and Boland, Angela},
  publisher = {Sage},
  title     = {{Doing a Systematic Review - A Student's Guide}},
  year      = {2024},
  address   = {London},
  edition   = {3},
  isbn      = {9781529740981},
  booktitle = {Doing a systematic review a student's guide},
  file      = {:Cherry2024 - Doing a Systematic Review a Student's Guide.pdf:PDF},
  keywords  = {Wissenschaftliches Arbeiten},
  language  = {eng},
  url       = {https://swisscovery.slsp.ch/permalink/41SLSP_UBE/17e6d97/alma99117483595305511},
}

@Article{Metzendorf2016,
  author   = {Maria-Inti Metzendorf},
  journal  = {JEAHIL},
  title    = {{Why medical information specialists should routinely form part of teams producing high quality systematic reviews - a Cochrane perspective}},
  year     = {2016},
  issn     = {1841-0715},
  month    = dec,
  number   = {4},
  pages    = {6--9},
  volume   = {12},
  abstract = {This article summarizes evidence from recent publications demonstrating that medical information specialists and librarians should routinely form part of teams producing systematic reviews in order to increase value and reduce waste in biomedical research. It additionally describes the involvement and role of the Cochrane Information Specialist during the production of Cochrane reviews.},
  eprint   = {http://ojs.eahil.eu/ojs/index.php/JEAHIL/issue/view/85/12_4},
  file     = {:Metzendorf2016 - Why Medical Information Specialists Should Routinely Form Part of Teams Producing High Quality Systematic Reviews a Cochrane Perspective.pdf:PDF},
  keywords = {librarians; professional role; biomedical research; information storage and retrieval; review literature as topic},
  url      = {http://ojs.eahil.eu/ojs/index.php/JEAHIL/issue/view/85/12_4},
}

@Misc{COPE2022,
  author       = {COPE and DOAJ and OASPA and WAME},
  howpublished = {{online}},
  month        = sep,
  title        = {{Principles of Transparencyand Best Practice in Scholarly Publishing}},
  year         = {2022},
  abstract     = {The Committee on Publication Ethics (COPE), the Directory of Open Access Journals (DOAJ), the Open Access Scholarly Publishing Association (OASPA), and the World Association of Medical Editors (WAME) are scholarly organisations that have collaborated to identify principles of transparency and best practice for scholarly publications. This is the fourth version of a work in progress (published September 15 2022). We encourage its wide dissemination.},
  doi          = {10.24318/cope.2019.1.12},
  file         = {:COPE2022 - Principles of Transparencyand Best Practice in Scholarly Publishing.pdf:PDF},
  institution  = {Committee on Publication Ethics},
  url          = {http://dx.doi.org/10.24318/cope.2019.1.12},
}

@Article{Hirt2024,
  author       = {Hirt, Julian and Nordhausen, Thomas and Fuerst, Thomas and Ewald, Hannah and Appenzeller-Herzog, Christian},
  journal      = {BMJ},
  title        = {{Guidance on terminology, application, and reporting of citation searching: the TARCiS statement}},
  year         = {2024},
  month        = mar,
  number       = {e078384},
  volume       = {385},
  doi          = {10.1136/bmj-2023-078384},
  elocation-id = {e078384},
  eprint       = {https://www.bmj.com/content/385/bmj-2023-078384.full.pdf},
  file         = {:Hirt2024 - Guidance on Terminology, Application, and Reporting of Citation Searching_ the TARCiS Statement.pdf:PDF},
  publisher    = {BMJ Publishing Group Ltd},
  url          = {https://www.bmj.com/content/385/bmj-2023-078384},
}

@Article{Townsend2017,
  author                 = {Townsend, Whitney A. and Anderson, Patricia F. and Ginier, Emily C. and MacEachern, Mark P. and Saylor, Kate M. and Shipman, Barbara L. and Smith, Judith E.},
  journal                = {J Med Libr Assoc},
  title                  = {A competency framework for librarians involved in systematic reviews.},
  year                   = {2017},
  month                  = jul,
  pages                  = {268--275},
  volume                 = {105},
  electronic-issn        = {1558-9439},
  linking-issn           = {1536-5050},
  print-issn             = {1536-5050},
  abstract               = {OBJECTIVE: The project identified a set of core competencies for librarians who are involved in systematic reviews. METHODS: A team of seven informationists with broad systematic review experience examined existing systematic review standards, conducted a literature search, and used their own expertise to identify core competencies and skills that are necessary to undertake various roles in systematic review projects. RESULTS: The team identified a total of six competencies for librarian involvement in systematic reviews: "Systematic review foundations," "Process management and communication," "Research methodology," "Comprehensive searching," "Data management," and "Reporting." Within each competency are the associated skills and knowledge pieces (indicators). Competence can be measured using an adaptation of Miller's Pyramid for Clinical Assessment, either through self-assessment or identification of formal assessment instruments. CONCLUSIONS: The Systematic Review Competencies Framework provides a standards-based, flexible way for librarians and organizations to identify areas of competence and areas in need of development to build capacity for systematic review integration. The framework can be used to identify or develop appropriate assessment tools and to target skill development opportunities.},
  address                = {United States},
  article-doi            = {10.5195/jmla.2017.189},
  article-pii            = {jmla-105-268},
  completed              = {20180112},
  doi                    = {10.5195/jmla.2017.189},
  electronic-publication = {20170701},
  file                   = {:Townsend2017 - A Competency Framework for Librarians Involved in Systematic Reviews..pdf:PDF:https\://jmla.pitt.edu/ojs/jmla/article/download/189/391},
  history                = {2017/07/01 00:00 [pmc-release]},
  issue                  = {3},
  keywords               = {Communication, Humans, *Librarians, *Professional Competence, *Review Literature as Topic, Search Engine},
  language               = {eng},
  location-id            = {10.5195/jmla.2017.189 [doi]},
  nlm-unique-id          = {101132728},
  owner                  = {NLM},
  publication-status     = {ppublish},
  revised                = {20181202},
  source                 = {J Med Libr Assoc. 2017 Jul;105(3):268-275. doi: 10.5195/jmla.2017.189. Epub 2017 Jul 1.},
  status                 = {MEDLINE},
  subset                 = {IM},
  title-abbreviation     = {J Med Libr Assoc},
}

@Article{Stokes2023,
  author    = {Stokes, Gillian and Sutcliffe, Katy and Thomas, James},
  journal   = {BMJ Evid Based Med},
  title     = {Is a one-size-fits-all {\textquoteleft}12-month rule{\textquoteright} appropriate when it comes to the last search date in systematic reviews?},
  year      = {2023},
  issn      = {2515-446X},
  number    = {6},
  pages     = {359--363},
  volume    = {28},
  doi       = {10.1136/bmjebm-2022-112060},
  eprint    = {https://ebm.bmj.com/content/28/6/359.full.pdf},
  file      = {:Stokes2023 - Is a One Size Fits All _12 Month Rule_ Appropriate When It Comes to the Last Search Date in Systematic Reviews_.pdf:PDF:https\://ebm.bmj.com/content/ebmed/28/6/359.full.pdf},
  publisher = {Royal Society of Medicine},
  url       = {https://ebm.bmj.com/content/28/6/359},
}

@Comment{jabref-meta: databaseType:bibtex;}
