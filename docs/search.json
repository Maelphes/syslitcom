[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SysLit Compendium",
    "section": "",
    "text": "Welcome\nThis is a compendium for the field of systematic literature searching. It contains technical terms, methods and background information related to the retrieval of references from literature databases.\nThe main idea is to inform anyone who undertakes a systematic literature search about relevant terms of the trade.\n\n\n\n\n\n\nWarning\n\n\n\nThis website is still being setup. It may contain errors and certainly raises no claims to completeness.\n\n\nIn 1  Databases you will learn about all kinds of data sources and search interfaces as well as their syntax.\nTechnical terms of all sorts are explained in 2  Technical terms.\n3  Tools tells you about various tools and useful concepts for creating your search for evidence.\nChapter 4  Methods describes various techniques of building and conducting a systematic search.\nThis website is created and maintained by Marc von Gernler (Medical Library, University Library of Bern, University of Bern). The “compendium” was originally written in German as a glossary for lectures and as a mnemonic for the author. It was originally typeset in LaTeX (Link to the original document).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "1  Databases",
    "section": "",
    "text": "1.1 Clinical Trials Registries\nBefore clinical trials are performed, they are registered in in dedicated databases, so-called clinical trials registries (CTR). The purpose of this practice is to combat publication bias (see Section 2.5) and to increase transparency and provide access to the clinical trials.\nThese records clinical trials registries usually comprise information such as study title, short description, study type, eligibility criteria for participants, interventions, randomization, study status and contact information. (See also Glanville et al. (2014), Knelangen et al. (2018)).\nA comprehensive list of resources is maintained by Julie Glanville and Carol Lefebvre.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-ctr",
    "href": "databases.html#sec-ctr",
    "title": "1  Databases",
    "section": "",
    "text": "Clinical Trial Registries\n\n\n\n\n\n\n\n\nCountry\nWebsite\n\n\n\n\nAU/NZ\nAustralian and New Zealand Clinical Trials Registry (ANZCTR)\n\n\nCH\nSwiss National Clinical Trials Portal (SNCTP)\n\n\nCN\nChinese Clinical Trial Registry (ChiCTR)\n\n\nDE\nGerman Clinical Trials Register (DRKS)\n\n\nEU\nEU Clinical Trials Register (EUCTR) (only records prior to 31-01-2022)\n\n\nEU\nClinical Trials Information System (CTIS)\n\n\nIN\nClinical Trials Registry India (CTRI)\n\n\nNL\nOverview of Medical Research in the Netherlands (OMON)\n\n\nUK\nISRCTN\n\n\nUS\nClinialTrials.gov\n\n\nWHO\nInternational Clinical Trials Registry Platform (ICTRP)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-cochranelibrary",
    "href": "databases.html#sec-cochranelibrary",
    "title": "1  Databases",
    "section": "1.2 Cochrane Library",
    "text": "1.2 Cochrane Library\nThe Cochrane Library is the collection of Cochrane’s databases, most importantly the Cochrane Database of Systematic Reviews (CDSR) and the Cochrane Central Register of Controlled Trials (CENTRAL), which contain different types evidence to inform healthcare decision-making.\nThe Cochrane Library is not freely available. Switzerland has complete access to the Cochrane Library due to a national license (currently until 2024).\n\n1.2.1 Cochrane Database of Systematic Reviews (CDSR)\nThe Cochrane Database of Systematic Reviews (CDSR) is a leading journal (ISSN: 1469-493X) and database for systematic reviews in health care. Cochrane Reviews are published in CDSR, which is accessible via the Cochrane Library.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-pubmed",
    "href": "databases.html#sec-pubmed",
    "title": "1  Databases",
    "section": "1.3 PubMed",
    "text": "1.3 PubMed\nPubMed is a public and freely available database, maintained by the National Center of Biotechnology Information (NCBI) at the U.S. National Library of Medicine (NLM). In 2024, it contains over 37 million records of biomedical and life science literature.\nPubMed and MEDLINE are often used synonymously. However, there is a difference, explained in detail at https://nlm.nih.gov/bsd/difference.html.\nPubMed facilitates searching within the databases MEDLINE, PubMed Central (PMC) and Bookshelf.\nAll records in PubMed possess a unique identifier, the PubMed ID.\nRoughly 84 percent of the records in PubMed are indexed using Medical Subject Headings (MeSH).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-pmc",
    "href": "databases.html#sec-pmc",
    "title": "1  Databases",
    "section": "1.4 PubMed Central",
    "text": "1.4 PubMed Central\nPubMed Central (PMC) is a free full-text database of the NLM. It features Open Access articles from biomedicine and life sciences.\nPMC can be searched directly or as part of the PubMed database.\nPMC records possess the PubMed Central ID as a digital identifier.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-embase",
    "href": "databases.html#sec-embase",
    "title": "1  Databases",
    "section": "1.5 Embase",
    "text": "1.5 Embase\nEmbase (acronym for Excerpta Medica Database) is a subscription-based bibliographic database, produced by Elsevier. In the year 2024 it contains over 32 million references to biomedical and pharmacological articles and conference abstracs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-entrez",
    "href": "databases.html#sec-entrez",
    "title": "1  Databases",
    "section": "1.6 Entrez",
    "text": "1.6 Entrez\nEntrez ist a cross-database search system maintained by the National Center for Biotechnology Information (NCBI). It comprises 39 databases, such as PubMed, MeSH, the NCBI-Bookshelf and PubMed Central.\nEntrez can be accessed using the NCBI website or using the Entrez Programming Utitilites (E-utilities).\n\n\n\n\nGlanville, Julie M., Steven Duffy, Rachael McCool, and Danielle Varley. 2014. “Searching ClinicalTrials.gov and the International Clinical Trials Registry Platform to inform systematic reviews: what are the optimal search approaches?” J Med Libr Assoc 102 (25031558): 177–83. https://doi.org/10.3163/1536-5050.102.3.007.\n\n\nKnelangen, Marco, Elke Hausner, Maria-Inti Metzendorf, Sibylle Sturtz, and Siw Waffenschmidt. 2018. “Trial Registry Searches for Randomized Controlled Trials of New Drugs Required Registry-Specific Adaptation to Achieve Adequate Sensitivity.” J Clin Epidemiol 94: 69–75. https://doi.org/10.1016/j.jclinepi.2017.11.003.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "technicalterms.html",
    "href": "technicalterms.html",
    "title": "2  Technical terms",
    "section": "",
    "text": "2.1 abstract\nAn abstract is the short summary at the beginning of scientific publications, e.g. journal articles, theses or conference papers. The abstract is among the most important parts of a publication as it is usually the only part of the text which is freely available and can be retrieved from bibliographic databases. Title and abstract are the key elements of a textword search. (Cals and Kotz (2013), Pitkin and Branagan (1998))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-ambiguity",
    "href": "technicalterms.html#sec-ambiguity",
    "title": "2  Technical terms",
    "section": "2.2 ambiguity",
    "text": "2.2 ambiguity\nA term or statement which has more than one possible meaning or definition is ambiguous. Ambiguity proves to be an obstacle in creating search strategies, because any free text search with ambiguous terms will inevitably retrieve records for all meanings of the term regardless of the context. In this case, it is an option to render such terms more specific by using phrases or proximity operators.\n\n\n\n\n\n\nExamples\n\n\n\n\napothecary might refer to the occupation of pharmacist or the community pharmacy as a location or institution.\nThe term pharmacy may refer to the pharmaceutical sciences, the manufacture of drugs or the pharmacy as a retail shop.\nIn anatomy, a styloid process is a pointed outgrowth from a bone. However, there are serveral of these in the human body, for instance in the temporal bone, the radius bone, the ulna bone or the metacarpal bones.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-appendix",
    "href": "technicalterms.html#sec-appendix",
    "title": "2  Technical terms",
    "section": "2.3 appendix",
    "text": "2.3 appendix\nAn appendix provides additional content to a publication and is often called supplementary material or supplementary information. Usually any content which goes beyond the constraints of the publication is provided there. Examples are the full search strategies of systematic literature searches, detailed descriptions of methods or measurements.\nIt is also possible to publish such supplementary information or research data independently in online repositories.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-authorkeywords",
    "href": "technicalterms.html#sec-authorkeywords",
    "title": "2  Technical terms",
    "section": "2.4 author keyword",
    "text": "2.4 author keyword\nPublishers often require the authors of a publication to provide keywords describing the content of the publication. These keywords don’t necessarily correspond to controlled vocabulary (i.e. index terms, which are assigned to the records by the database) and should not be confused with them. (Névéol, Doğan, and Lu (2010))\nAuthor keywords are often used as part of the free text search.\n\n\n\n\n\n\nExamples\n\n\n\nWithin PubMed the data field [Other Term]) can be searched for author keywords. This field is automatically searched when [Title/Abstract] or [Text Word] are used. (See PubMed Search Field Tags).\nIn Ovid MEDLINE the corresponding field codes .kw or .kf can be used for searching the author keywords.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-bias",
    "href": "technicalterms.html#sec-bias",
    "title": "2  Technical terms",
    "section": "2.5 bias",
    "text": "2.5 bias\nBias is a systematic deviation between results and facts that may lead to under- or over-estimation of intervention effects. As a result bias might lead to conclusions which do not accurately represent the truth. There are various types and sources for bias, as well as methods to avoid some forms of bias, such as randomization or blinding of participants in clinical trials.\nSystematic literature searching is a means to reduce bias. Systematic reviews strive to minimise these deviations by assessing the risk of bias in results of included studies. (Braun et al. (2021), Boutron et al. (2022), Gough, Oliver, and Thomas (2017))\n\n2.5.1 selection bias\nSystematic differences between comparison groups lead to a deviation from the true effect of an intervention. This so-called selection bias can be prevented by measures such as the sufficient randomization and concealment of allocation of trial participants to different study arms.(Gough, Oliver, and Thomas (2017), Odgaard‐Jensen et al. (2011))\n\n\n2.5.2 publication bias\nResults perceived as “positive” are more likely to be published than those results which are perceived as “negative”, which gives the positive results more weight. (Gough, Oliver, and Thomas (2017))\n\n\n2.5.3 language of publication bias\nIn systematic literature searches it is often tempting to restrict the search to languages which are easily understood by the screeners and researchers. Not only will this practive keep the number of records at a more manageable level, it also makes the translation of foreign publications unnecessary. However, this so-called language of publication bias can have a significant impact on the quality of the review. (Gough, Oliver, and Thomas (2017), Morrison et al. (2012), Moher et al. (2003))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-bibdb",
    "href": "technicalterms.html#sec-bibdb",
    "title": "2  Technical terms",
    "section": "2.6 bibliographic database",
    "text": "2.6 bibliographic database\nBibliographic databases comprise references to publications, such as articles in peer-reviewed journals, reports, patents, book chapters or conference proceedings.\nAs opposed to full text databases, bibliographic databases only provide bibliographic information or metadata. Bibliographic records typically include title, abstract, author(s), publication year, journal name, and the DOI or other persistent identifiers.\nReferences in bibliographic databases are often indexed with subject headings to facilitate the retrieval of relevant records, for instance during a systematic literature search.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-class-metrics",
    "href": "technicalterms.html#sec-class-metrics",
    "title": "2  Technical terms",
    "section": "2.7 classification metrics",
    "text": "2.7 classification metrics\nIn information retrieval the performance of a systematic search, a search strategy or a search filter is described by certain metrics for binary classification tasks, such as accuracy, precision, sensitivity and specificity.\nA classifier (the search) makes a prediction about the condition of a record (by retrieving or not retrieving the record). The classification (the search result) is evaluated by comparing the prediction with the actual condition (the relevance of the records).\nIn other words: The literature search is supposed to retrieve mostly relevant references and ignore non-relevant ones. A retrieved relevant record equals a true positive (tp), whereas a retrieved non-relevant record equals a false positive (fp). See Table 2.1 for reference.\n\n\n\nTable 2.1: Truth table\n\n\n\n\n\nrecord\nrelevant\nirrelevant\n\n\n\n\nretrieved\ntp\nfp\n\n\nnot retrieved\nfn\ntn\n\n\n\n\n\n\n\n2.7.1 accuracy\nAccuracy, also called fraction correct (FC), is a statistical measure of how well a binary classifier correctly (“true”) identifies a condition (“positive or negative”). It is defined as the ratio of all true classifications (true positives and true negatives) to the total number of classifications. (Haynes and Wilczynski (2004), Lefebvre et al. (2017), Fawcett (2006))\nIt can be calculated according to the following equation: \\[\n\\text{accuracy} = \\tfrac{tp + tn}{tp + fp + fn + tn}\n\\]\n\n\n2.7.2 precision\nPrecision, also called positive predictive value (PPV), is a performance metric for the retrieval of information. It is the fraction of all relevant records among all retrieved records, which can be written as:\n\\[\n\\text{precision} = \\tfrac{tp}{tp + fp}\n\\]\nA high-precision search tries to retrieve as few non-relevant records as possible, usually missing out on relevant records.\n\n\n2.7.3 sensitivity\nSensitivity, also called true positive rate (TPR), recall or hit rate, is a performance metric for the retrieval of informaton, similar to the precision. It equals the probability with which relevant records are correctly identified. (See Haynes and Wilczynski (2004), Lefebvre et al. (2017)).\nIt is the ratio of all relevant retrieved records and the total of all relevant records: \\[\n\\text{sensitivity} = \\tfrac{tp}{tp + fn}\n\\] The idea of a sensitive search is to retrieve as many relevant records as possible, which results in retrieving more non-relevant records in the process.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-datafield",
    "href": "technicalterms.html#sec-datafield",
    "title": "2  Technical terms",
    "section": "2.8 data field",
    "text": "2.8 data field\nA data field (also called field or column) is a set of values of a particular data type within a database. For instance the data fields for the author or the title contain text strings whereas the fields for the issue, volume or PubMed ID contain numerical values.\nData fields possess designations in the form of field codes or search field tags such as UID, AU, TI and AB for the fields of unique identifier, author, title and abstract.\n\n\n\nTable 2.2: Data fields UID, AU, TI shown for three records\n\n\n\n\n\n\n\n\n\n\nUID\nAU\nTI\n\n\n\n\n7616995\nJ. P. Kassirer, M. Angell\nRedundant publication: a reminder\n\n\n16040884\nA. K. Akobeng\nPrinciples of evidence based medicine\n\n\n22071866\nT. Young,S.  Hopewell\nMethods for obtaining unpublished data\n\n\n\n\n\n\nIt always depends on the syntax of the database or search interface which fields can be searched and by what code they are searchable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-dataset",
    "href": "technicalterms.html#sec-dataset",
    "title": "2  Technical terms",
    "section": "2.9 dataset",
    "text": "2.9 dataset\nDatasets or records of a database are collections of data. In a tabular database they correspond to the rows of the table, as shown in Table 2.2. A record in such a database consists of values for the given columns or data fields of the table.\nRecords of bibliographic databases are called references. These contain the metadata referring to a publication, such as title, abstract, authors, journal name or publication date.\nDatasets within clinical trials registries contain metadata for clinical trials, such as registration number, study type, research institution, study status, etc.\nRecords within fulltext databases also feature a fulltext document, as opposed to bibliographic databases.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-doi",
    "href": "technicalterms.html#sec-doi",
    "title": "2  Technical terms",
    "section": "2.10 digital object identifier",
    "text": "2.10 digital object identifier\nA digital object identifier (DOI) is a persistent identifier issued by the DOI foundation. It is used to uniquely identify publications.\nDOIs take the form of character strings which consist of a prefix and a suffix, separated by a slash /. The prefix identifies the registrant of the DOI (usually the publisher of an article) and takes the form 10.xxxx, where xxxx is a number greater than or equal to 1000. After the prefix and the slash follows the suffix, which is chosen by the registrant for the particular digital object.\nDOIs can be resolved using the website of the International DOI Foundation or the Handle.Net Registry.\n\n\n\n\n\n\nExample\n\n\n\ndoi:10.1000/182 can be resolved via https://doi.org/10.1000/182 or https://hdl.handle.net/10.1000/182 and leads to the DOI handbook.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-eligibilitycriteria",
    "href": "technicalterms.html#sec-eligibilitycriteria",
    "title": "2  Technical terms",
    "section": "2.11 eligibility criteria",
    "text": "2.11 eligibility criteria\nA very important step at the beginning of any review project is the definition of certain eligibility criteria on the basis of the research question. There are two types of criteria:\nInclusion criteria must be met by studies in order for them to be included in the review. In contrast, if a study meets one or more of the exclusion criteria, it will be excluded from the review. See also McKenzie et al. (2022), Gough, Oliver, and Thomas (2017).\n\n\n\n\n\n\nExample: systematic review about chronic non-cancer pain\n\n\n\n\nInclusion criteria:\n\nadults (18 years or older)\npatients with chronic non-cancer pain\nrandomized controlled trials\n\nExclusion criteria:\n\nacute pain, post-surgical pain\nchronic cancer pain\npregnancy",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-fulltext",
    "href": "technicalterms.html#sec-fulltext",
    "title": "2  Technical terms",
    "section": "2.12 full-text",
    "text": "2.12 full-text\nThe complete texts of publications (e.g. articles, books, chapters, reports, …) are called full-texts.\nMost of the available databases for literature searching are bibliographic databases, which means they do not contain the full-text, but bibliographic references to the publications, in most cases including a link to the publisher, where the full-text can be obtained.\nOpen Access publications can be accessed freely, whereas non-open access publications usually require a paid subscription or access fee. Alternatively, they can be ordered using the document delivery service of a university library.\n\n\n\n\n\n\nfull-text retrieval tools\n\n\n\nThere are tools that can help to identify the shortest path to the full-text:\n\nLean Library\nLibKey Nomad\nUnpaywall\nOpen Access Button\n\nAlso reference management programs often provide ways to retrieve available full-texts for the managed references. Sometimes this automated retrieval fails due to incompatibility or security measures of the publishers, even when the full-text would be otherwise accessible (e.g. EndNote).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-indexing",
    "href": "technicalterms.html#sec-indexing",
    "title": "2  Technical terms",
    "section": "2.13 indexing",
    "text": "2.13 indexing\nIndexing is the process in which index terms are assigned to records. This is done by the database provider in order to indicate what the referenced document is about, independent of its explicit title or abstract. In other words, an indexed record can be retrieved systematically based on its contextual meaning and implicit contents, rather than by searching verbatim expressions in the text.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-orphanline",
    "href": "technicalterms.html#sec-orphanline",
    "title": "2  Technical terms",
    "section": "2.14 orphan line",
    "text": "2.14 orphan line\nAll parts of a search strategy are supposed to contribute to the overall result of the database search. In case a search query within a search strategy is not connected (using operators) to the rest of the search strategy, it is called an orphan line.\n\n\n\nTable 2.3: Line 5 is an orphan line.\n\n\n1   hypertension/\n2   (hypertension or high blood pressure).ti,ab.\n3   *patient attitude/\n4   *patient satisfaction/\n5   (choice$ or empower$).ti.\n6   1 or 2\n7   3 or 4\n8   6 and 7",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-pmid-pmcid",
    "href": "technicalterms.html#sec-pmid-pmcid",
    "title": "2  Technical terms",
    "section": "2.15 PMID and PMCID",
    "text": "2.15 PMID and PMCID\nThe PubMed ID (PMID) and the PubMed Central ID (PMCID) are unique identifiers assigned to the records within the databases PubMed and PubMed Central. They are similar to the digital object identifier (DOI).\nPMIDs are unique integer values, e.g. 32256971, PMCIDs are composed of the prefix PMC followed by a series of numbers, e.g. PMC7106990.\nPubMed records can easily be found simply by entering their PMIDs as search terms into the PubMed search.\n\n\n\n\n\n\nConversion tool\n\n\n\nThe National Library of Medicine provides a tool for the conversion of the PMID, PMCID and DOI into one another. This tool only works for records which are both part of PubMed and PubMed Central.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-syntax",
    "href": "technicalterms.html#sec-syntax",
    "title": "2  Technical terms",
    "section": "2.16 syntax",
    "text": "2.16 syntax\nSimilar to programming, the syntax is the set of rules that applies for setting up search queries and building search strategies in databases. It defines the operators, field codes and special characters (such as wildcard symbols, parentheses, slashes, quotation marks, etc.) that are available within a particular search interface.\nAs a consequence, search strategies cannot be used freely in every database. They have to be translated due to different syntax and due to different index terms. (See Clark et al. (2020), Glanville et al. (2019), Wanner and Baumann (2019), Damarell, Tieman, and Sladek (2013)).\n\n\n\nTable 2.4: Examples for syntax in different search interfaces\n\n\n\n\n\n\n\n\n\nPubMed\n\"ocular hypertension\"[tiab]\n\n\nEmbase\n'ocular hypertension':ti,ab\n\n\nOvid\n\"ocular hypertension\".ti,ab.\n\n\nCochrane Library\n\"ocular hypertension\":ti,ab\n\n\nScopus\nTITLE-ABS({ocular hypertension})\n\n\nWeb of Science\nTI=(\"ocular hypertension\") OR AB=(\"ocular hypertension\")\n\n\nEBSCOhost\n(TI \"ocular hypertension\") OR (AB \"ocular hypertension\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-thesaurus",
    "href": "technicalterms.html#sec-thesaurus",
    "title": "2  Technical terms",
    "section": "2.17 thesaurus",
    "text": "2.17 thesaurus\nA thesaurus (ancient greek: θησαυρός (thesaurós) ‘treasury’) is a dictionary of synonyms, which are often ordered alphabetically or hierarchically.\nIn the context of literature searching, a thesaurus contains a database-specific controlled vocabulary of index terms.\n\n\n\nTable 2.5: Commonly known databases and their thesauri\n\n\n\n\n\nDatabase\nThesaurus\n\n\n\n\nPubMed/MEDLINE\nMedical Subject Headings (MeSH)\n\n\nEmbase\nEmtree\n\n\nCochrane Library\nMedical Subject Headings (MeSH)\n\n\nCINAHL\nCINAHL Subject Headings\n\n\nAPA PsycInfo\nThesaurus of Psychological Index Terms\n\n\nGlobal Health\nCABI Thesaurus\n\n\n\n\n\n\nThese vocabularies usually list preferred terms for indexing, their definitions as well as lists of synonyms for each of those index terms. The index terms are arranged hierarchically, ranging from very broad categories to very specific terms.\n\n\n\n\n\n\nMeSH hierarchy from the top of the MeSH tree to Pleural Cavity\n\n\n\nAll MeSH Categories\n  Anatomy Category\n    Body Regions\n      Torso\n        Thorax\n          Thoracic Cavity\n            Pleural Cavity\n\n\nThe controlled vocabularies are regularly updated, new index terms are introduced or hierarchies rearranged. (See What’s New in MeSH for example).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-wildcard",
    "href": "technicalterms.html#sec-wildcard",
    "title": "2  Technical terms",
    "section": "2.18 wildcard",
    "text": "2.18 wildcard\nWildcards are special characters used for truncation. The usage and meaning of the available wildcards for this purpose depends on the syntax of the database or search interface.\n\n\n\nTable 2.6: commonly used wildcard symbols\n\n\n\n\n\ncharacter\nname\n\n\n\n\n*\nasterisk\n\n\n$\ndollar sign\n\n\n?\nquestion mark\n\n\n#\nhash sign, pound sign\n\n\n\n\n\n\n\n\n\n\nBoutron, I., M. J. Page, J. P. T. Higgins, D. G. Altman, A. Lundh, and A. Hróbjartsson. 2022. “Chapter 7: Considering Bias and Conflicts of Interest Among the Included Studies.” In Cochrane Handbook for Systematic Reviews of Interventions, edited by J. P. T. Higgins, J. Thomas, J. Chandler, M. Cumpston, T. Li, M. J. Page, and V. A. Welch. Cochrane.\n\n\nBraun, Cordula, Christine Schmucker, Monika Nothacker, Kai Nitschke, Corinna Schaefer, Claudia Bollig, Cathleen Muche-Borowski, Ina B. Kopp, and Jörg Meerpohl. 2021. “Manual Bewertung des Biasrisikos in Interventionsstudien.” Albert-Ludwigs-Universität Freiburg. https://doi.org/10.6094/UNIFR/194900.\n\n\nCals, Jochen W. L., and Daniel Kotz. 2013. “Effective writing and publishing scientific papers, part II: title and abstract.” J Clin Epidemiol 66 (6): 585. https://doi.org/10.1016/j.jclinepi.2013.01.005.\n\n\nClark, Justin Michael, Sharon Sanders, Matthew Carter, David Honeyman, Gina Cleo, Yvonne Auld, Debbie Booth, et al. 2020. “Improving the translation of search strategies using the Polyglot Search Translator: a randomized controlled trial.” J Med Libr Assoc 108 (2): 195–207. https://doi.org/10.5195/jmla.2020.834.\n\n\nDamarell, Raechel A., Jennifer J. Tieman, and Ruth M. Sladek. 2013. “OvidSP Medline-to-PubMed search filter translation: a methodology for extending search filter range to include PubMed’s unique content.” BMC Med Res Methodol 13 (1): 86. https://doi.org/10.1186/1471-2288-13-86.\n\n\nFawcett, Tom. 2006. “An Introduction to ROC Analysis.” Pattern Recognit Lett 27 (8): 861–74. https://doi.org/10.1016/j.patrec.2005.10.010.\n\n\nGlanville, Julie, Ruth Foxlee, Susi Wisniewski, Anna Noel-Storr, Mary Edwards, and Gordon Dooley. 2019. “Translating the Cochrane EMBASE RCT filter from the Ovid interface to Embase.com: a case study.” Health Info Libr J 36 (3): 264–77. https://doi.org/10.1111/hir.12269.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews. Second. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically strong studies of diagnosis from Medline: analytical survey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nLefebvre, Carol, Julie Glanville, Sophie Beale, Charles Boachie, Steven Duffy, Cynthia Fraser, Jenny Harbour, Rachael McCool, and Lynne Smith. 2017. “Assessing the Performance of Methodological Search Filters to Improve the Efficiency of Evidence Information Retrieval: Five Literature Reviews and a Qualitative Study.” Health Technol Assess 21 (69): 1–148. https://doi.org/10.3310/hta21690.\n\n\nMcKenzie, J. E., S. E. Brennan, R. E. Ryan, H. J. Thomson, R. V. Johnston, and J. Thomas. 2022. “Chapter 3: Defining the Criteria for Including Studies and How They Will Be Grouped for the Synthesis.” In Cochrane Handbook for Systematic Reviews of Interventions, edited by J. P. T. Higgins, J. Thomas, J. Chandler, M. Cumpston, T. Li, M. J. Page, and V. A. Welch. Cochrane.\n\n\nMoher, D., B. Pham, M. L. Lawson, and T. P. Klassen. 2003. “The inclusion of reports of randomised trials published in languages other than English in systematic reviews.” Health Technol Assess 7: 1–90. https://doi.org/10.3310/hta7410.\n\n\nMorrison, Andra, Julie Polisena, Don Husereau, Kristen Moulton, Michelle Clark, Michelle Fiander, Monika Mierzwinski-Urban, et al. 2012. “The effect of English-language restriction on systematic review-based meta-analyses: a systematic review of empirical studies.” Int J Technol Assess Health Care 28 (2): 138–44. https://doi.org/10.1017/S0266462312000086.\n\n\nNévéol, Aurélie, Rezarta Islamaj Doğan, and Zhiyong Lu. 2010. “Author Keywords in Biomedical Journal Articles.” AMIA Annu Symp Proc 2010 (November): 537–41. https://pubmed.ncbi.nlm.nih.gov/21347036/.\n\n\nOdgaard‐Jensen, Jan, Gunn E. Vist, Antje Timmer, R. Kunz, Elie A. Akl, Holger Schünemann, Matthias Briel, Alain J. Nordmann, Silvia Pregno, and Andrew D. Oxman. 2011. “Randomisation to Protect Against Selection Bias in Healthcare Trials.” Cochrane Database Syst Rev   (4). https://doi.org/10.1002/14651858.MR000012.pub3.\n\n\nPitkin, Roy M., and Mary Ann Branagan. 1998. “Can the Accuracy of Abstracts Be Improved by Providing Specific Instructions? A Randomized Controlled Trial.” JAMA 280 (3): 267–69. https://doi.org/10.1001/jama.280.3.267.\n\n\nWanner, Amanda, and Niki Baumann. 2019. “Design and implementation of a tool for conversion of search strategies between PubMed and Ovid MEDLINE.” Res Syn Meth 10 (2): 154–60. https://doi.org/10.1002/jrsm.1314.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "3  Tools",
    "section": "",
    "text": "3.1 Entrez Programming Utilities\nThe Entrez Programming Utilities (E-utilities) are a set of nine programs which provide an API to the Entrez database system of the NCBI. Comprehensive information about the E-utilifies is available in the official E-utilities Help.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-e-utilities",
    "href": "tools.html#sec-e-utilities",
    "title": "3  Tools",
    "section": "",
    "text": "3.1.1 E-utilities via URL\nThese programs are server-based and can be deployed using different URLs. These URLs to query Entrez are composed of the base URL https://eutils.ncbi.nlm.nih.gov/entrez/eutils/ to which a string with the desired utility and the query is attached, for instance esearch.fcgi?db=pubmed&term=BMJ[journal]+AND+hernia+AND+2010[pdat]\nThe results for these queries are usually returned as XML-structured data.\n\n\n3.1.2 Entrez Direct\nThe E-utilities are also available directly on a Unix shell under Linux or macOS by using the package Entrez Direct (EDirect).\nOne of the main advantages of EDirect are the commands that are available on the shell, for example grep, sort, uniq or wc, which allow the results to be processed directly. Also shell scripts can be used to automate the processing.\n\n\n\n\n\n\nExample: Retrieve similar articles\n\n\n\nThe command\nelink -db pubmed -id 25554246,29463298 -related -cmd neighbor | \nxtract -pattern LinkSetDb -element Id\nwill return all PMIDs of publications which PubMed identifies as Similar Articles for the PMIDs 25554246 and 29463298.\nOn PubMed the Similar Articles search can be carried out for only one PMID at a time, whereas using the E-utilities it is possible to search with many PMIDs in a single query.\n\n\n\n\n\n\n\n\nUnix Shell on Windows\n\n\n\n\n\nThere is a quick and easy way to get access to Linux and its shell even when one is running a modern Windows PC: The Windows Subsystem for Linux (WSL) provides an environment to install Linux from within Windows (10 or later).\nFor more on this, see\n\nHow to install Linux on Windows with WSL\n\nLibrary Carpentry: The Unix Shell",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-finer",
    "href": "tools.html#sec-finer",
    "title": "3  Tools",
    "section": "3.2 FINER",
    "text": "3.2 FINER\nFINER is an acronym for the five criteria feasible, interesting, novel, ethical and relevant which can be used as guidance when formulating a good clinical research question. See Table 3.1. (Cummings, Browner, and Hulley (2013))\n\n\n\nTable 3.1\n\n\n\n\n\n\nCriterion\nMeaning\n\n\n\n\nfeasible\nThe research question should not exceed the available resources, i.e. participants, expertise, time and money).\n\n\ninteresting\nThe research question should in itself be interesting, not only to the researcher, but also to a broader public.\n\n\nnovel\nThe gain of knowledge and new information should be at the heart of the question. Research usually does not only reiterate already established data unless it is designed as a confirmatory study.\n\n\nethical\nProper research has to be ethical and must not bear unacceptable risks for its participants.\n\n\nrelevant\nThe expected impact of the research on scientific knowledge and clinical processes can be a good measurement parameter for the relevance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-pico",
    "href": "tools.html#sec-pico",
    "title": "3  Tools",
    "section": "3.3 PICO",
    "text": "3.3 PICO\nPICO is a mnemonic for the concepts Population, Intervention, Comparison and Outcome. Concepts like these are used for defining research questions as well as eligibility criteria for the studies relevant for answering the question.\nThere are other concepts and mnemonics for different kinds of research questions, such as SPIDER, ECLIPSE, PIRD or PICOS. (Munn et al. (2018), Methley et al. (2014), Eriksen and Frandsen (2018))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-press",
    "href": "tools.html#sec-press",
    "title": "3  Tools",
    "section": "3.4 PRESS",
    "text": "3.4 PRESS\nPeer Review of Electronic Search Strategies (PRESS) by McGowan et al. (2016) is an evidence-based guideline for the peer review of search strategies. It is mainly focused on systematic review projects, health technology assesments (HTAs) and other kinds of reviews. A main tool for PRESS is a checklist which guides the reader through the process of peer review.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-prisma",
    "href": "tools.html#sec-prisma",
    "title": "3  Tools",
    "section": "3.5 PRISMA",
    "text": "3.5 PRISMA\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) by Page, McKenzie, et al. (2021) is a set of minimum requirements for the reporting and documentation of systematic reviews. The goal of PRISMA is to set standards for reporting and in doing so increase the overall quality of systematic reviews. A detailed explanatory paper was published by Page, Moher, et al. (2021).\nPRISMA also provides tools such as a checklist and a flowchart, which can be used for creating the recommended tables and figures for publication. (M. Rethlefsen and Page (2021))\nThere are additional extensions of PRISMA for various purposes, such as PRISMA-S for the documentation of systematic literature searches (M. L. Rethlefsen et al. (2021)) or PRISMA-ScR for scoping reviews (Tricco et al. (2018)).\nSee also https://prisma-statement.org.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-refmanagement",
    "href": "tools.html#sec-refmanagement",
    "title": "3  Tools",
    "section": "3.6 Reference Management software",
    "text": "3.6 Reference Management software\nBibliographic records and similar sets of data such as clinical study metadata can be stored and managed using reference management programs (also called citation management software).\nThese programs are usually able to perform tasks with the records, such as\n\nimport and export of various formats (e.g. RIS, NBIB, BIB, TXT, CSV, XML)\ncreation, editing and updating\ndeduplication\nretrieval of full-texts\noutput of citations in various styles\n\n\n\n\n\n\n\nExamples of reference managers\n\n\n\n\n\n\nCitavi\nEndNote\nJabRef\nMendeley\nZotero\n\n\n\n\nFor comparisons of reference management software see also https://mediatum.ub.tum.de/1320978 and https://en.wikipedia.org/wiki/Comparison_of_reference_management_software.\n\n\n\n\nCummings, Steven R., Warren S. Browner, and Stephen B. Hulley. 2013. “Conceiving the Research Question and Developing the Study Plan.” In Designing Clinical Research, edited by Stephen B. Hulley, Steven R. Cummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman, 4. ed., 14–22. Philadelphia: Lippincott Williams & Wilkins. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/99pfpl/alma99117040391205511.\n\n\nEriksen, Mette Brandt, and Tove Faber Frandsen. 2018. “The impact of patient, intervention, comparison, outcome (PICO) as a search strategy tool on literature search quality: a systematic review.” J Med Libr Assoc 106 (4): 420–31. https://doi.org/10.5195/jmla.2018.345.\n\n\nMcGowan, Jessie, Margaret Sampson, Douglas M. Salzwedel, Elise Cogo, Vicki Foerster, and Carol Lefebvre. 2016. “PRESS Peer Review of Electronic Search Strategies: 2015 Guideline Statement.” J Clin Epidemiol 75: 40–46. https://doi.org/10.1016/j.jclinepi.2016.01.021.\n\n\nMethley, Abigail M., Stephen Campbell, Carolyn Chew-Graham, Rosalind McNally, and Sudeh Cheraghi-Sohi. 2014. “PICO, PICOS and SPIDER: a comparison study of specificity and sensitivity in three search tools for qualitative systematic reviews.” BMC Health Serv Res 14 (1): 579. https://doi.org/10.1186/s12913-014-0579-0.\n\n\nMunn, Z., C. Stern, E. Aromataris, C. Lockwood, and Z. Jordan. 2018. “What kind of systematic review should I conduct? A proposed typology and guidance for systematic reviewers in the medical and health sciences.” Journal Article. BMC Med Res Methodol 18 (1): 5. https://doi.org/10.1186/s12874-017-0468-4.\n\n\nPage, Matthew J., Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle Boutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021. “The PRISMA 2020 statement: an updated guideline for reporting systematic reviews.” BMJ 372. https://doi.org/10.1136/bmj.n71.\n\n\nPage, Matthew J., David Moher, Patrick M. Bossuyt, Isabelle Boutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021. “PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews.” BMJ 372. https://doi.org/10.1136/bmj.n160.\n\n\nRethlefsen, Melissa L., Shona Kirtley, Siw Waffenschmidt, Ana Patricia Ayala, David Moher, Matthew J. Page, Jonathan B. Koffel, et al. 2021. “PRISMA-S: an extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews.” Syst Rev 10 (1): 39. https://doi.org/10.1186/s13643-020-01542-z.\n\n\nRethlefsen, Melissa, and Matthew J. Page. 2021. “PRISMA 2020 and PRISMA-S: Common Questions on Tracking Records and the Flow Diagram.” MetaArXiv. https://doi.org/10.31222/osf.io/439ju.\n\n\nTricco, A. C., E. Lillie, W. Zarin, K. K. O’Brien, H. Colquhoun, D. Levac, D. Moher, et al. 2018. “PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation.” Journal Article. Ann Intern Med 169 (7): 467–73. https://doi.org/10.7326/M18-0850.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "4  Methods",
    "section": "",
    "text": "4.1 Boolean operators\nDatabases usually allow a search to be structured using the three basic operations of Boolean algebra, which are expressed with the Boolean operators AND (conjunction), OR (disjunction) and NOT (negation). The AND operator creates an intersection of sets, OR creates a union of sets and NOT excludes sets (see Figure 4.1).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-boolean",
    "href": "methods.html#sec-boolean",
    "title": "4  Methods",
    "section": "",
    "text": "Figure 4.1: Boolean Operators\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\nThe query \"heart attack\" AND diabetes AND obesity retrieves only records featuring all three terms.\nThe query \"cardiac arrest\" OR asystole retrieves records containing at least one of the two terms.\nThe query animals NOT humans removes all records mentioning humans from the set animals.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nUsing the NOT operator can be dangerous, as it excludes records regardless of any relevant search terms they might contain. The above example excludes also records with animals if they mention humans.\n\n\n\nProperties\nThe Boolean operators AND and OR possess similar properties as the multiplication and addition. See Table 4.1. (O’Regan (2012))\n1 (a OR b) = (b OR a)\n (a AND b) = (b AND a)\n ----\n2 (a OR b) OR c = a OR (b OR c)\n (a AND b) AND c = a AND (b AND c)\n ----\n3 a AND (b OR c) = (a AND b) OR (a AND c)\n a OR (b AND c) = (a OR b) AND (a OR c)\n\n\n\nTable 4.1\n\n\n\n1\n\ncommutative property\n\n2\n\nassociative property\n\n3\n\ndistributive property",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-citationanalysis",
    "href": "methods.html#sec-citationanalysis",
    "title": "4  Methods",
    "section": "4.2 citation searching",
    "text": "4.2 citation searching\nRelevant references can be retrieved by analyzing citation relationships between known relevant articles, called seed papers (also known as core papers) and cited or citing references. This technique is called citation searching, citation analysis or citation tracking (Hirt et al. (2021), Belter (2016), Hinde and Spackman (2015)).\n\n\n\n\n\n\nThe TARCiS Statement\n\n\n\nThe TARCiS Statement by Hirt et al. (2024) provides guidance on terminology, applications, and the reporting of citation searching in the context of systematic searching.\n\n\nCitation searching can be advisable at the very beginning of a systematic literature search in order to find additional core papers and to identify additional search terms. After finishing the final search it can be used to find additional relevant studies that were not retrieved by systematic searching using search strategies.\nSome research questions are hard to search by a conventional Boolean approach, for instance due to very ambiguous search terms or very recent research topics for which no index terms and no established terminology exists, yet. In these cases a citation search can be more useful than a Boolean search as it relies solely on the citation relationships between known and yet unknown publications.\nThere are different approaches to searching citations: First, in the backward citation searching method the lists of references cited in the seed papers are screened for relevant articles. Second, the analysis of publications citing the seed paper as a reference is called forward citation searching. See Figure 4.2.\n\n\n\n\n\n\nFigure 4.2: backward and forward citation searching\n\n\n\nThird, the identification of relevant literature by counting co-cited or co-citing references which connect the seed paper with other papers is called co-citation searching. In theory, the relevance of these other papers should increase with an increasing number of connecting publications.\n\n4.2.1 co-cited citation searching\nA seed paper (SP) is connected to other relevant publications (ORP) if both the SP and the ORP are cited by the same paper. In this case the SP and the ORP are co-cited by a number of publications. See Figure 4.3.\n\n\n\n\n\n\nFigure 4.3: co-cited citation searching retrieves publications which share citations with the core paper\n\n\n\n\n\n4.2.2 co-citing citation searching\nA similar relationship exists between the SP and ORP if they both share a number of mutual references. In this case they are co-citing a set of common literature. See Figure 4.4.\n\n\n\n\n\n\nFigure 4.4: co-citing citation searching retrieves publications which share references with the core paper",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-criticalappraisal",
    "href": "methods.html#sec-criticalappraisal",
    "title": "4  Methods",
    "section": "4.3 critical appraisal",
    "text": "4.3 critical appraisal\nOne of the main steps in evidence-based medicine is the critical appraisal of evidence. Critical appraisal checklists help to assess the methodological quality of a studies and to determine the extent to which a study has excluded or minimized the possibility of bias in its design, conduct and analysis.\n\n\n\n\n\n\nSources for critical appraisal checklists\n\n\n\n\n\n\nJBI\nCentre for Evidence-Based Medicine (CEBM)\nCritical Appraisal Skills Programme (CASP)\nScottish Intercollegiate Guidelines Network (SIGN)\nJAMAevidence\n\n\n\n\nSee also: Twells (2021), Buccheri and Sharifi (2017), Fineout-Overholt et al. (2010a), Fineout-Overholt et al. (2010b), Fineout-Overholt et al. (2010c)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-deduplication",
    "href": "methods.html#sec-deduplication",
    "title": "4  Methods",
    "section": "4.4 deduplication",
    "text": "4.4 deduplication\nWhenever multiple databases are searched it is unavoidable that various references are retrieved more than once due to the overlapping of contents. The removal of duplicate records from a dataset is called deduplication.\nDeduplication can be carried out manually using reference management software or in an automated way using review tools. The methods and tools for deduplication differ in their mode of operation and the quality of results (Janka and Metzendorf (2024), McKeown and Mir (2021), Bramer et al. (2016)).\nAn unwelcome practice, which makes deduplication (and concomitantly any scientific work) more difficult, is repetitive, duplicate or redundant publishing (Ding et al. (2020), Johnson (2006), Kassirer and Angell (1995)).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-filters",
    "href": "methods.html#sec-filters",
    "title": "4  Methods",
    "section": "4.5 filters",
    "text": "4.5 filters\nFilters (also search filters, filter strategies or hedges) are search strategies designed to retrieve records for a specific concept of the research question.\nThere are filters for specific patient groups or diseases, outcomes, study types (for instance to retrieve only randomized controlled trials (RCTs), or filters for other aspects of the research question, e.g. adverse effects, diagnostic accuracy or patient values. (Waffenschmidt et al. (2020), Salvador-Oliván, Marco-Cuenca, and Arquero-Avilés (2021), Lee et al. (2012), Golder et al. (2006))\nValidated filters are developed, tested and optimized for sensitivity and precision by experts. (Haynes and Wilczynski (2004), Glanville et al. (2008))\nFilter strategies can be implemented in a search strategy just like any concept of the research question. Table 4.2 illustrates a search strategy with a short qualitative research filter in lines 8 to 11, which is added to the overall search in line 12.\n\n\n\nTable 4.2\n\n\n1   hypertension/\n2   (hypertension or high blood pressure).ti,ab.\n3   1 or 2\n4   exp patient attitude/\n5   *patient satisfaction/\n6   (choice$ or empower$).ti.\n7   or/4-6\n8   interview$.mp.\n9   experience$.mp.\n10  qualitative.tw.\n11  or/8-10\n12  3 and 7 and 11\n\n\n\n\n\n\n\n\n\nSources of filter strategies\n\n\n\n\n\n\nISSG Search Filter Resource\nCanadian Agency for Drugs and Technologies in Health (CADTH)\nSIGN Health Improvement Scotland\nMcMaster University\nCochrane\nOvid (Wolters Kluwer)\nPubMed Clinical Queries",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-fieldcode",
    "href": "methods.html#sec-fieldcode",
    "title": "4  Methods",
    "section": "4.6 field code",
    "text": "4.6 field code\nThe data fields of databases possess short designations called field codes, field tags or field labels, which allow to search the fields separately as part of a search query or search strategy.\nDepending on the syntax of the database or search interface different field codes are available for searching. If no field code is used in a search query, the search term is usually searched in all fields or a preset variety of fields.\n\n\n\n\n\n\nExample\n\n\n\nIn PubMed the query hypnosis[TIAB] will basically search for records with “hypnosis” in the title or abstract. In Ovid the same search would be written as hypnosis.ti,ab.\n\n\nSee also PubMed Search field tags and Ovid Medline Fields.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-focustopic",
    "href": "methods.html#sec-focustopic",
    "title": "4  Methods",
    "section": "4.7 focus topic",
    "text": "4.7 focus topic\nFocus topics (also called major topics) are weighted index terms. If a particular topic is at the heart of a publication, index terms for that topic will be assigned as a so-called focus topic. This is often displayed in the databases by writing an asterisk before or after the index term.\n\n\n\n\n\n\nRisk of confusion\n\n\n\nThe asterisk * appears also as a wildcard character for truncation. The two look the same, but have different meanings and uses. Don’t let them confound you.\n\n\nBy labeling an index term this way, its significance for the publication is visualized. Moreover, searching for the focus topic instead of the index term allows for a search to be focused only on the most important papers for a particular topic.\n\n\n\n\n\n\nExample\n\n\n\n\nA systematic review on hypertension will most likely feature the focus topic *hypertension, whereas an artikle about vascular diseases might be indexed with hypertension as a normal subject heading. Searching for hypertension[majr] in PubMed or *hypertension/ in Ovid would yield only the first of those two articles. A search for hypertension[mh] hypertension/ would find both of them.\nThe article Apnoeic oxygenation during paediatric tracheal intubation by Fuchs et al. (2024) is indexed with Intubation, Intratracheal* / adverse effects and Intubation, Intratracheal* / methods as major topics, whereas Hypoxia / etiology was added as a regular MeSH term as it is not the main focus of the article.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-frequencyops",
    "href": "methods.html#sec-frequencyops",
    "title": "4  Methods",
    "section": "4.8 frequency operators",
    "text": "4.8 frequency operators\nRecords in which a relevant expression occurs multiple times might be more relevant than records with fewer instances of the same expression. Therefore some search interfaces allow the use of a so-called frequency operator, which only retrieves records only if the search term occurs at least the specified number of times in the searched data field.\n\n\n\n\n\n\nExample\n\n\n\nExample from Ovid: The query \"pharmacy\".ab/freq=5 will retrieve articles, in which the term pharmacy occurs at least five times within the abstract.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-indexterms",
    "href": "methods.html#sec-indexterms",
    "title": "4  Methods",
    "section": "4.9 index terms",
    "text": "4.9 index terms\nIndex terms, also called subject headings (or sometimes descriptor) are expressions defined for the purpose of indexing. They represent content-related concepts and are organized as a controlled vocabulary. By adding index terms to a record it becomes retrievable based on its contents.\nUsing index terms in a search is an essential part of a systematic literature search. The index term search can be focused by employing subheadings or searching the terms as focus topics.\nIndex terms should not be confused with free text terms or author keywords.\n\n\n\n\n\n\nExample\n\n\n\nThe MeSH term for the concept of heart attack or cardiovascular stroke is Myocardial infarction The Emtree term (index term in Embase) for the same concept is heart infarction.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-limits",
    "href": "methods.html#sec-limits",
    "title": "4  Methods",
    "section": "4.10 limits",
    "text": "4.10 limits\nThere are various means to restrict the results of a search. One of them are so-called limits which are filter options provided by the search interface, which allow the search results to be limited to characteristics such as publication type, language or year of publication.\n\n\n\n\n\n\nWarning\n\n\n\n\nDatabase limits are not to be mistaken for validated filter strategies. Limits are usually based on certain data fields, whereas validated search filters are more complex search strategies. See also Section 4.5.\nDatabase limits based on index terms may lead to the unintended exclusion of non-indexed records.\nThe usage of database limits is not always evident from the search history. If it is not possible to display applied limits in the search history, its use should be reported in the documentation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-nesting",
    "href": "methods.html#sec-nesting",
    "title": "4  Methods",
    "section": "4.11 nesting",
    "text": "4.11 nesting\nNesting refers to the use of parentheses ( ) to group search terms within a query. The purpose of nesting a search query is to define the order in which the search terms and operators processed. The properties of the operators in combination with parentheses are displayed in Table 4.1.\nWithout nesting the order in which the elements of a search query are processed depends on the rules of the respective search interface. This means that the same query might produce very different results in the individual databases.\n\n\n\n\n\n\nExamples\n\n\n\n\nWithin PubMed all searches are processed in a left-to-right sequence.\n\nThus the following PubMed queries yield completely different results:\n\nexercise[MH] AND infection[MH] OR heart[MH]\nexercise[MH] AND heart[MH] OR infection[MH]\nheart[MH] OR infection[MH] AND exercise[MH]\n\nOn the other hand the following nested queries are identical:\n\nexercise[MH] AND (infection[MH] OR heart[MH])\nexercise[MH] AND (heart[MH] OR infection[MH])\n(heart[MH] OR infection[MH]) AND exercise[MH]\n\n\nWeb of Science executes the search in an order of precedence of the operators.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-phrases",
    "href": "methods.html#sec-phrases",
    "title": "4  Methods",
    "section": "4.12 phrases",
    "text": "4.12 phrases\nMost databases can be searched for verbatim expressions, called phrases or literal strings, by putting search terms in quotation marks \" \".\n\n\n\n\n\n\nEffects\n\n\n\nThe use of phrases usually terminates any automatically applied techniques, such as lemmatization, stemming or automated term mapping (ATM) for those expressions. In this way, the use of phrases usually reduces the amount of search results as it makes the search more precise and less sensitive.\nExample:\nDue to automated term mapping the PubMed query heart arrest will be translated to\n\"heart arrest\"[MeSH Terms] OR \"heart\"[All Fields] AND \"arrest\"[All Fields] OR \"heart arrest\"[All Fields]\nHowever, the query \"heart arrest\" translates to \"heart arrest\"[All Fields], because phrases are not automatically mapped in PubMed.\n\n\n\n\n\n\n\n\nPhrases and Truncation\n\n\n\nIn some cases the simultaneous use of phrases and truncation is not supported by the search interface.\nSearching for \"hearing aid*\" in the Cochrane Library will prompt an error message suggesting the use of the NEXT operator to work around the problem. In other words, the search query should be hearing NEXT aid* instead.\n\n\n\n\n\n\n\n\nRequired quotation marks\n\n\n\nPhrases are absolutely necessary when the search string contains a special character or anything the search interface would interpret as an operator or syntax. Examples for Ovid:\n\n\"go/no-go\".ti,ab. – Without the quotation marks the forward slash / would be understood as command to search the expression go as an index term.\n\"Sensitivity and Specificity\"/ – and is also an operator and must be escaped using the quotation marks.\n\"5\".ip – This search retrieves all records with the number 5 in the Issue/Part field. Without the quotation marks, the query would search for the contents of line 5 in the field .ip. (That procedure is called postqualification of search sets).\n\n\n\n\n\n\n\n\n\nStraight quotes vs. curly quotes\n\n\n\nThere are several types of quotation marks. Search interfaces often only understand so-called straight quotes \" \" (the ones that have been used in typewriters). Modern word processors often change straight quotes automatically into the typographically correct curly quotes “ ” (the way they are printed in books), which can cause a syntax error, if they are copied into a search query. This is a known issue in Ovid.\nOptions to counter this problem:\n\nDeactivation of the responsible autocorrection feature of the word processor.\nUsing a simpler plain text editor.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-searchstrategy",
    "href": "methods.html#sec-searchstrategy",
    "title": "4  Methods",
    "section": "4.13 search strategy",
    "text": "4.13 search strategy\nA search strategy is a coherent set of search queries designed to retrieve references for a particular topic. A search strategy is dependent on the syntax and index terms of the searched database. As a consequence, the search strategy needs to be translated for the use in other databases.\nSearch strategies are supposed to be consistent with the predefined eligibility criteria of the research project (Gough, Oliver, and Thomas (2017)).\nDepending on the purpose and detail of the search, the extent of a search strategy might range from a simple search string to numerous lines of search terms connected by Boolean operators.\nTable 4.3 and Table 4.4 show examples for both types of search strategies.\n\n\n\nTable 4.3: Single-line PubMed Search strategy\n\n\n\"analgesics\"[MH] OR \"analgesic*\"[TIAB] OR \"analgesic*\"[PA] OR \"anodynes\"[TIAB] \nOR \"antinociceptive*\"[TIAB]) AND \"pain management\"[MAJR]\n\n\n\n\n\n\nTable 4.4: Multi-line search strategy for Ovid MEDLINE\n\n\n1 exp analgesics/\n2 (analge#ic? or anodyne? or antinoceptive?).ti,ab,kw.\n3 *pain management/\n4 (1 or 2) and 3",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-subheading",
    "href": "methods.html#sec-subheading",
    "title": "4  Methods",
    "section": "4.14 subheading",
    "text": "4.14 subheading\nPublications in bibliographic databases are often indexed using index terms. In cases where the index term does not sufficiently describe the content of the article, so-called subheadings or qualifiers can be applied to the index term to specify certain aspects.\n\n\n\n\n\n\nExample\n\n\n\nThe PubMed search query Respiratory Tract Infections/drug therapy[MeSH] (or short Respiratory Tract Infections/dt[mh]) retrieves references focusing on the drug therapy of respiratory tract infections.\n\n\nTypical subheadings are ´adverse effects´´, ´complications´, ´diagnosis´, ´drug therapy´, ´economics´, ´epidemiology´, ´history´, ´methods´, ´pathology´, ´pharmacology´, ´psychology´, ´standards´, ´therapeutic use´, ´toxicology´.\nSometimes it may be required to retrieve all publications featuring a certain subheading regardless of the index terms, for instance when one is interested in reports of adverse effects. In order to do that the subheading can be searched alone as a so-called floating subheading, for example adverse effects[sh] in PubMed or ae.fs in Ovid MEDLINE.\nFor more information about subheadings in PubMed see https://pubmed.gov/help/#mesh-subheadings or https://nlm.nih.gov/mesh/qualifiers_scopenotes.html.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-syslitsearch",
    "href": "methods.html#sec-syslitsearch",
    "title": "4  Methods",
    "section": "4.15 systematic literature searching",
    "text": "4.15 systematic literature searching\nConducting a systematic literature search (also called systematic search) means to search multiple databases for references to relevant articles and studies in a structured, planned and iterative manner. A systematic search is well-documented, transparent and (to a certain degree) reproducible.\n\n\n\n\n\n\nInformation specialists and librarians\n\n\n\nSystematic searches are best conducted or at least accompanied by information specialists or librarians. For more on this topic, see Spencer and Eldredge (2018), Metzendorf (2016), Foster (2015), Koffel (2015), Rethlefsen et al. (2015), Schellinger et al. (2021), Meert, Torabi, and Costella (2016).\n\n\nThe purpose of a systematic literature search is to find relevant literature in the desired degree of completeness. For a systematic review the search should be very sensitive as to find all the relevant evidence. In contrast, the literature search as part of a rapid review or narrative review may still be done systematically, but can be designed in a more precise manner, since in those cases it may be acceptable to miss some relevant articles. (See @#sec-class-metrics about sensitivity and precision).\nThere are various guidelines which can be followed to conduct systematic searches, such as the Cochrane Handbook (Higgins et al. (2022)) or the JBI Manual (Aromataris and Munn (2020)). Depending on the desired type of review (e.g. systematic, scoping, narrative, …, see Munn et al. (2018), Munn et al. (2018) or Pearson et al. (2015))\n\n\n\n\n\n\nimportant steps of a systematic search\n\n\n\n\ndefinition of a research question\nselection of databases\ncompilation of search terms\nsetup of an initial search\niterative refinement of the search strategy\npeer review of the search strategy\ntranslation to other databases\nfinal search and export of results\ndocumentation of the search\n\n\n\nVarious methods are applied in the design of search strategies. Keywords and index terms are connected using operators. The search queries are structured by nesting. The precision and sensitivity of the search is adjusted using truncation, by the choice of search fields or the use of term explosion.\nA systematic search is best peer-reviewed by colleagues (e.g. by information specialists, other researchers, or fellow students), following the PRESS guideline by McGowan et al. (2016).\nIdeally, the systematic search is documented according the PRISMA-S extension by Rethlefsen et al. (2021).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-termexplosion",
    "href": "methods.html#sec-termexplosion",
    "title": "4  Methods",
    "section": "4.16 term explosion",
    "text": "4.16 term explosion\nIndex terms in databases are usually hierarchically organized, starting with very broad terms in the top categories to very specific terms further down the branches of the hierarchy.\nWhen searching using an index term, it is often possible to include all subordinate index terms in the search. This simultaneous search option is called term explosion.\n\n\n\n\n\n\nWarning\n\n\n\nKeep in mind that depending on the search interface or database, the term explosion might be active by default, as it is the case in PubMed. This can be avoided by using the field codes [mh:noexp] or [majr:noexp] instead of [mh] or [majr].\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\nThe PubMed search query Psychotherapy[MH] automatically retrieves records featuring the MeSH term psychotherapy as well as aromatherapy, behaviour therapy, crisis intervention, hypnosis, or logotherapy, because in PubMed the term explosion is active by default. However, the query Psychotherapy[MH:NoExp] retrieves only records indexed with psychotherapy.\nIn Ovid MEDLINE, the search for psychotherapy/ looks only for references indexed with psychotherapy, whereas the query exp psychotherapy/ searches the exploded term, i.e. it uses the subordinate index terms such as aromatherapy, crisis intervention, etc. in the search, too.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-truncation",
    "href": "methods.html#sec-truncation",
    "title": "4  Methods",
    "section": "4.17 truncation",
    "text": "4.17 truncation\nIn general, to truncate means to reduce something down to its trunk, to shorten something, to cut something off.\nIn literature searching truncation is a technique that allows to search several variations of a term at once by searching with a reduced (truncated) version of the search term. A term is truncated by replacing one or more characters with a so-called wildcard character, such as *, $, ?, #.\nThe most common form of truncation is the unlimited truncation (usually using the asterisk * or the dollar sign $) at the end of the search term. In some databases it is possible to limit the truncation to a fixed number of characters or to replace just one character. The kinds of truncation that are available depend on the syntax of the database or search interface.\n\n\n\nTable 4.5: Truncation examples in Ovid\n\n\n\n\n\n\n\n\n\nquery\ncovered search terms\n\n\n\n\ndiscolo$\ndiscolor, discolors, discolored, discolouring, discolorations, …\n\n\ndiscolo$3\ndiscolor, discolors, discolored\n\n\ncolo$r\ncolor, colour, colorimeter, colonizer, coloarticular, …\n\n\ncolo?r\ncolor, colour\n\n\nwom#n\nwoman, women, womon, womxn, womyn\n\n\n\n\n\n\nUsually only free text terms are truncated. While it might be possible to truncate index terms, it is not very practical; truncated index terms are rarely used meaningfully, for instance in valiated search filters, such as the search term diagnostic*[MeSH:noexp] in the diagnosis filter by Kastner et al. (2009).\n\n\n\n\nAromataris, E., and Z. Munn, eds. 2020. JBI Manual for Evidence Synthesis. Book. JBI. https://doi.org/10.46658/JBIMES-20-01.\n\n\nBelter, Christopher W. 2016. “Citation Analysis as a Literature Search Method for Systematic Reviews.” J Assn Inf Sci Tec 67 (11): 2766–77. https://doi.org/10.1002/asi.23605.\n\n\nBramer, Wichor, Dean Giustini, Gerdien de Jonge, Leslie Holland, and Tanja Bekhuis. 2016. “De-duplication of database search results for systematic reviews in EndNote.” J Med Libr Assoc 104 (3): 240–43. https://doi.org/10.5195/jmla.2016.24.\n\n\nBuccheri, Robin K., and Claire Sharifi. 2017. “Critical Appraisal Tools and Reporting Guidelines for Evidence-Based Practice.” Worldviews Evid Based Nurs 14 (6): 463–72. https://doi.org/10.1111/wvn.12258.\n\n\nDing, Ding, Binh Nguyen, Klaus Gebel, Adrian Bauman, and Lisa Bero. 2020. “Duplicate and salami publication: a prevalence study of journal policies.” Int J Epidemiol 49 (1): 281–88. https://doi.org/10.1093/ije/dyz187.\n\n\nFineout-Overholt, Ellen, Bernadette Mazurek Melnyk, Susan B. Stillwell, and Kathleen M. Williamson. 2010a. “Evidence-Based Practice Step by Step: Critical Appraisal of the Evidence: Part I.” Am J Nurs 110 (7). https://doi.org/10.1097/01.NAJ.0000383935.22721.9c.\n\n\n———. 2010b. “Evidence-Based Practice, Step by Step: Critical Appraisal of the Evidence: Part II.” Am J Nurs 110 (9). https://doi.org/10.1097/01.NAJ.0000388264.49427.f9.\n\n\n———. 2010c. “Evidence-Based Practice, Step by Step: Critical Appraisal of the Evidence: Part III.” Am J Nurs 110 (11). https://doi.org/10.1097/01.NAJ.0000390523.99066.b5.\n\n\nFoster, Margaret J. 2015. “Overview of the Role of Librarians in Systematic Reviews: From Expert Search to Project Manager.” JEAHIL 11 (2): 3–7. https://hdl.handle.net/1969.1/169677.\n\n\nFuchs, Alexander, Gabriela Koepp, Markus Huber, Jonas Aebli, Arash Afshari, Rachele Bonfiglio, Robert Greif, et al. 2024. “Apnoeic Oxygenation During Paediatric Tracheal Intubation: A Systematic Review and Meta-Analysis.” Brit J Anaesth 132 (February): 392–406. https://doi.org/10.1016/j.bja.2023.10.039.\n\n\nGlanville, Julie, Sue Bayliss, Andrew Booth, Yenal Dundar, Hasina Fernandes, Nigel David Fleeman, Louise Foster, et al. 2008. “So Many Filters, so Little Time: The Development of a Search Filter Appraisal Checklist.” J Med Libr Assoc 96 (18974813): 356–61. https://doi.org/10.3163/1536-5050.96.4.011.\n\n\nGolder, Su, Heather M. McIntosh, Steve Duffy, and Julie Glanville. 2006. “Developing efficient search strategies to identify reports of adverse effects in MEDLINE and EMBASE.” Health Info Libr J 23 (March): 3–12. https://doi.org/10.1111/j.1471-1842.2006.00634.x.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews. Second. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically strong studies of diagnosis from Medline: analytical survey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nHiggins, Julian P. T., James Thomas, Jacqueline Chandler, Miranda Cumpston, Tianjing Li, Matthew J. Page, and Vivian A. Welch, eds. 2022. Cochrane Handbook for Systematic Reviews of Interventions. 6.3 ed. Cochrane; Cochrane. https://training.cochrane.org/handbook.\n\n\nHinde, Sebastian, and Eldon Spackman. 2015. “Bidirectional Citation Searching to Completion: An Exploration of Literature Searching Methods.” PharmacoEconomics 33 (1): 5–11. https://doi.org/10.1007/s40273-014-0205-3.\n\n\nHirt, Julian, Thomas Nordhausen, Christian Appenzeller-Herzog, and Hannah Ewald. 2021. “Using citation tracking for systematic literature searching – study protocol for a scoping review of methodological studies and a Delphi study.” F1000Res 9 (September): 1386. https://doi.org/10.12688/f1000research.27337.3.\n\n\nHirt, Julian, Thomas Nordhausen, Thomas Fuerst, Hannah Ewald, and Christian Appenzeller-Herzog. 2024. “Guidance on terminology, application, and reporting of citation searching: the TARCiS statement.” BMJ 385 (e078384). https://doi.org/10.1136/bmj-2023-078384.\n\n\nJanka, Heidrun, and Maria-Inti Metzendorf. 2024. “High Precision but Variable Recall – Comparing the Performance of Five Deduplication Tools.” JEAHIL 20 (1): 12–17. https://doi.org/10.32384/jeahil20607.\n\n\nJohnson, Claire. 2006. “Repetitive, Duplicate, and Redundant Publications: A Review for Authors and Readers.” J Manipulative Physiol Ther 29 (7): 505–9. https://doi.org/10.1016/j.jmpt.2006.07.001.\n\n\nKassirer, Jerome P., and Marcia Angell. 1995. “Redundant Publication: A Reminder.” N Engl J Med 333 (7): 449–50. https://doi.org/10.1056/NEJM199508173330709.\n\n\nKastner, Monika, Nancy L. Wilczynski, Ann K. McKibbon, Amit X. Garg, and R. Brian Haynes. 2009. “Diagnostic test systematic reviews: Bibliographic search filters (‘Clinical Queries’) for diagnostic accuracy studies perform well.” J Clin Epidemiol 62 (9): 974–81. https://doi.org/10.1016/j.jclinepi.2008.11.006.\n\n\nKoffel, Jonathan B. 2015. “Use of Recommended Search Strategies in Systematic Reviews and the Impact of Librarian Involvement: A Cross-Sectional Survey of Recent Authors.” PLOS ONE 10 (5): 1–13. https://doi.org/10.1371/journal.pone.0125931.\n\n\nLee, Edwin, Maureen Dobbins, Kara DeCorby, Lyndsey McRae, Daiva Tirilis, and Heather Husson. 2012. “An Optimal Search Filter for Retrieving Systematic Reviews and Meta-Analyses.” BMC Med Res Methodol 12 (1): 51. https://doi.org/10.1186/1471-2288-12-51.\n\n\nMcGowan, Jessie, Margaret Sampson, Douglas M. Salzwedel, Elise Cogo, Vicki Foerster, and Carol Lefebvre. 2016. “PRESS Peer Review of Electronic Search Strategies: 2015 Guideline Statement.” J Clin Epidemiol 75: 40–46. https://doi.org/10.1016/j.jclinepi.2016.01.021.\n\n\nMcKeown, Sandra, and Zuhaib M. Mir. 2021. “Considerations for Conducting Systematic Reviews: Evaluating the Performance of Different Methods for de-Duplicating References.” Syst Rev 10 (1): 38. https://doi.org/10.1186/s13643-021-01583-y.\n\n\nMeert, Deborah, Nazi Torabi, and John Costella. 2016. “Impact of Librarians on Reporting of the Literature Searching Component of Pediatric Systematic Reviews.” J Med Libr Assoc 104 (October): 267–77. https://doi.org/10.3163/1536-5050.104.4.004.\n\n\nMetzendorf, Maria-Inti. 2016. “Why medical information specialists should routinely form part of teams producing high quality systematic reviews - a Cochrane perspective.” JEAHIL 12 (4): 6–9. http://ojs.eahil.eu/ojs/index.php/JEAHIL/issue/view/85/12_4.\n\n\nMunn, Z., M. D. J. Peters, C. Stern, C. Tufanaru, A. McArthur, and E. Aromataris. 2018. “Systematic Review or Scoping Review? Guidance for Authors When Choosing Between a Systematic or Scoping Review Approach.” Journal Article. BMC Med Res Methodol 18 (1): 143. https://doi.org/10.1186/s12874-018-0611-x.\n\n\nO’Regan, Gerard. 2012. A Brief History of Computing. Second. Springer, London. https://doi.org/10.1007/978-1-4471-2359-0.\n\n\nPearson, A., H. White, F. Bath-Hextall, S. Salmond, J. Apostolo, and P. Kirkpatrick. 2015. “A Mixed-Methods Approach to Systematic Reviews.” Journal Article. Int J Evid Based Healthc 13 (3): 121–31. https://doi.org/10.1097/XEB.0000000000000052.\n\n\nRethlefsen, Melissa L., Ann M. Farrell, Leah C. Osterhaus Trzasko, and Tara J. Brigham. 2015. “Librarian Co-Authors Correlated with Higher Quality Reported Search Strategies in General Internal Medicine Systematic Reviews.” J Clin Epidemiol 68 (June): 617–26. https://doi.org/10.1016/j.jclinepi.2014.11.025.\n\n\nRethlefsen, Melissa L., Shona Kirtley, Siw Waffenschmidt, Ana Patricia Ayala, David Moher, Matthew J. Page, Jonathan B. Koffel, et al. 2021. “PRISMA-S: an extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews.” Syst Rev 10 (1): 39. https://doi.org/10.1186/s13643-020-01542-z.\n\n\nSalvador-Oliván, José Antonio, Gonzalo Marco-Cuenca, and Rosario Arquero-Avilés. 2021. “Development of an efficient search filter to retrieve systematic reviews from PubMed.” J Med Libr Assoc 109 (4). https://doi.org/10.5195/jmla.2021.1223.\n\n\nSchellinger, Jana, Kerry Sewell, Jamie E. Bloss, Tristan Ebron, and Carrie Forbes. 2021. “The Effect of Librarian Involvement on the Quality of Systematic Reviews in Dental Medicine.” PLoS One 16: e0256833. https://doi.org/10.1371/journal.pone.0256833.\n\n\nSpencer, Angela J., and Jonathan D. Eldredge. 2018. “Roles for Librarians in Systematic Reviews: A Scoping Review.” J Med Libr Assoc 106 (January): 46–56. https://doi.org/10.5195/jmla.2018.82.\n\n\nTwells, Laurie K. 2021. “Evidence-Based Decision-Making 1: Critical Appraisal.” In Clinical Epidemiology: Practice and Methods, edited by Patrick S. Parfrey and Brendan J. Barrett, 389–404. New York, NY: Springer US. https://doi.org/10.1007/978-1-0716-1138-8_21.\n\n\nWaffenschmidt, Siw, Tamara Navarro-Ruan, Nick Hobson, Elke Hausner, Stefan Sauerland, and R. Brian Haynes. 2020. “Development and validation of study filters for identifying controlled non-randomized studies in PubMed and Ovid MEDLINE.” Res Syn Meth 11 (5): 617–26. https://doi.org/10.1002/jrsm.1425.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "publicationtypes.html",
    "href": "publicationtypes.html",
    "title": "5  Publication Types",
    "section": "",
    "text": "5.1 Reviews",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Publication Types</span>"
    ]
  },
  {
    "objectID": "publicationtypes.html#sec-review",
    "href": "publicationtypes.html#sec-review",
    "title": "5  Publication Types",
    "section": "",
    "text": "Figure 5.1: What Type of Review is Right for you? - adopted from Cornell University Library (2019)\n\n\n\n\n5.1.1 systematic review\nA systematic review (SR) is a comprehensive review of the best available evidence (i.e. all relevant research results) pertaining to a certain topic or research question. SRs are usually conducted by research groups over the time of several months. The purpose of SRs is to inform evidence-based decision making.\nSRs are regarded as the gold standard in evidence synthesis due to the strict and rigorous methodology that should be followed by the SR project team.\nIn many cases a so-called meta-analysis is also performed, which quantifies the results of the systematic review. (See Murad et al. (2014), Nagendrababu et al. (2020), Mulrow (1994))\n\n\n\n\n\n\nRecommended reading\n\n\n\n\nDoing a Systematic Review by Cherry, Dickson, and Boland (2024)\n\nSystematic Reviews in Health Research by Egger, Higgins, and Smith (2022)\n\nAn Introduction to Systematic Reviews by Gough, Oliver, and Thomas (2017)\n\n\n\n\n\n\n\nCherry, M. Gemma, Rumona Dickson, and Angela Boland, eds. 2024. Doing a Systematic Review - A Student’s Guide. 3rd ed. London: Sage. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/17e6d97/alma99117483595305511.\n\n\nCornell University Library. 2019. “What Type of Review is Right for You?” Online. https://guides.library.cornell.edu/evidence-synthesis/service.\n\n\nEgger, Matthias, Julian P. T. Higgins, and George Davey Smith, eds. 2022. Systematic Reviews in Health Research: Meta-Analysis in Context. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781119099369.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews. Second. London: SAGE Publications.\n\n\nMulrow, Cynthia D. 1994. “Rationale For Systematic Reviews.” BMJ 309 (6954): 597–99. http://www.jstor.org/stable/29724645.\n\n\nMurad, Mohammad Hassan, Victor M. Montori, John P. A. Ioannidis, Roman Jaeschke, P. J. Devereaux, Kameshwar Prasad, Ignacio Neumann, et al. 2014. “How to Read a Systematic Review and Meta-analysis and Apply the Results to Patient Care: Users’ Guides to the Medical Literature.” JAMA 312 (2): 171–79. https://doi.org/10.1001/jama.2014.5559.\n\n\nNagendrababu, V., P. Dilokthornsakul, P. Jinatongthai, S. K. Veettil, S. J. Pulikkotil, H. F. Duncan, and P. M. H. Dummer. 2020. “Glossary for Systematic Reviews and Meta-Analyses.” Int Endod J 53 (2): 232–49. https://doi.org/10.1111/iej.13217.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Publication Types</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aromataris, E., and Z. Munn, eds. 2020. JBI\nManual for Evidence Synthesis. Book. JBI. https://doi.org/10.46658/JBIMES-20-01.\n\n\nBelter, Christopher W. 2016. “Citation Analysis as a Literature\nSearch Method for Systematic Reviews.” J Assn Inf Sci\nTec 67 (11): 2766–77. https://doi.org/10.1002/asi.23605.\n\n\nBoutron, I., M. J. Page, J. P. T. Higgins, D. G. Altman, A. Lundh, and\nA. Hróbjartsson. 2022. “Chapter 7: Considering Bias and Conflicts\nof Interest Among the Included Studies.” In Cochrane Handbook\nfor Systematic Reviews of Interventions, edited by J. P. T.\nHiggins, J. Thomas, J. Chandler, M. Cumpston, T. Li, M. J. Page, and V.\nA. Welch. Cochrane.\n\n\nBramer, Wichor, Dean Giustini, Gerdien de Jonge, Leslie Holland, and\nTanja Bekhuis. 2016. “De-duplication of\ndatabase search results for systematic reviews in\nEndNote.” J Med Libr Assoc 104 (3): 240–43. https://doi.org/10.5195/jmla.2016.24.\n\n\nBraun, Cordula, Christine Schmucker, Monika Nothacker, Kai Nitschke,\nCorinna Schaefer, Claudia Bollig, Cathleen Muche-Borowski, Ina B. Kopp,\nand Jörg Meerpohl. 2021. “Manual Bewertung\ndes Biasrisikos in Interventionsstudien.”\nAlbert-Ludwigs-Universität Freiburg. https://doi.org/10.6094/UNIFR/194900.\n\n\nBuccheri, Robin K., and Claire Sharifi. 2017. “Critical Appraisal Tools and Reporting Guidelines for\nEvidence-Based Practice.” Worldviews Evid Based\nNurs 14 (6): 463–72. https://doi.org/10.1111/wvn.12258.\n\n\nCals, Jochen W. L., and Daniel Kotz. 2013. “Effective writing and publishing scientific papers, part\nII: title and abstract.” J Clin Epidemiol 66 (6):\n585. https://doi.org/10.1016/j.jclinepi.2013.01.005.\n\n\nCherry, M. Gemma, Rumona Dickson, and Angela Boland, eds. 2024.\nDoing a Systematic Review - A Student’s\nGuide. 3rd ed. London: Sage. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/17e6d97/alma99117483595305511.\n\n\nClark, Justin Michael, Sharon Sanders, Matthew Carter, David Honeyman,\nGina Cleo, Yvonne Auld, Debbie Booth, et al. 2020. “Improving the translation of search strategies using the\nPolyglot Search Translator: a randomized controlled\ntrial.” J Med Libr Assoc 108 (2): 195–207. https://doi.org/10.5195/jmla.2020.834.\n\n\nCornell University Library. 2019. “What Type\nof Review is Right for You?” Online. https://guides.library.cornell.edu/evidence-synthesis/service.\n\n\nCummings, Steven R., Warren S. Browner, and Stephen B. Hulley. 2013.\n“Conceiving the Research Question and\nDeveloping the Study Plan.” In Designing\nClinical Research, edited by Stephen B. Hulley, Steven R.\nCummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman, 4.\ned., 14–22. Philadelphia: Lippincott Williams & Wilkins. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/99pfpl/alma99117040391205511.\n\n\nDamarell, Raechel A., Jennifer J. Tieman, and Ruth M. Sladek. 2013.\n“OvidSP Medline-to-PubMed search filter\ntranslation: a methodology for extending search filter range to include\nPubMed’s unique content.” BMC Med Res Methodol 13\n(1): 86. https://doi.org/10.1186/1471-2288-13-86.\n\n\nDing, Ding, Binh Nguyen, Klaus Gebel, Adrian Bauman, and Lisa Bero.\n2020. “Duplicate and salami publication: a\nprevalence study of journal policies.” Int J\nEpidemiol 49 (1): 281–88. https://doi.org/10.1093/ije/dyz187.\n\n\nEgger, Matthias, Julian P. T. Higgins, and George Davey Smith, eds.\n2022. Systematic Reviews in Health Research:\nMeta-Analysis in Context. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781119099369.\n\n\nEriksen, Mette Brandt, and Tove Faber Frandsen. 2018. “The impact of patient, intervention, comparison, outcome\n(PICO) as a search strategy tool on literature search quality: a\nsystematic review.” J Med Libr Assoc 106 (4):\n420–31. https://doi.org/10.5195/jmla.2018.345.\n\n\nFawcett, Tom. 2006. “An Introduction to ROC\nAnalysis.” Pattern Recognit Lett 27 (8): 861–74. https://doi.org/10.1016/j.patrec.2005.10.010.\n\n\nFineout-Overholt, Ellen, Bernadette Mazurek Melnyk, Susan B. Stillwell,\nand Kathleen M. Williamson. 2010a. “Evidence-Based Practice Step by Step: Critical Appraisal\nof the Evidence: Part I.” Am J Nurs 110 (7). https://doi.org/10.1097/01.NAJ.0000383935.22721.9c.\n\n\n———. 2010b. “Evidence-Based Practice, Step by\nStep: Critical Appraisal of the Evidence: Part II.” Am\nJ Nurs 110 (9). https://doi.org/10.1097/01.NAJ.0000388264.49427.f9.\n\n\n———. 2010c. “Evidence-Based Practice, Step by\nStep: Critical Appraisal of the Evidence: Part III.”\nAm J Nurs 110 (11). https://doi.org/10.1097/01.NAJ.0000390523.99066.b5.\n\n\nFoster, Margaret J. 2015. “Overview of the Role of Librarians in\nSystematic Reviews: From Expert Search to Project Manager.”\nJEAHIL 11 (2): 3–7. https://hdl.handle.net/1969.1/169677.\n\n\nFuchs, Alexander, Gabriela Koepp, Markus Huber, Jonas Aebli, Arash\nAfshari, Rachele Bonfiglio, Robert Greif, et al. 2024. “Apnoeic\nOxygenation During Paediatric Tracheal Intubation: A Systematic Review\nand Meta-Analysis.” Brit J Anaesth 132 (February):\n392–406. https://doi.org/10.1016/j.bja.2023.10.039.\n\n\nGlanville, Julie M., Steven Duffy, Rachael McCool, and Danielle Varley.\n2014. “Searching ClinicalTrials.gov and the\nInternational Clinical Trials Registry Platform to inform systematic\nreviews: what are the optimal search approaches?” J\nMed Libr Assoc 102 (25031558): 177–83. https://doi.org/10.3163/1536-5050.102.3.007.\n\n\nGlanville, Julie, Sue Bayliss, Andrew Booth, Yenal Dundar, Hasina\nFernandes, Nigel David Fleeman, Louise Foster, et al. 2008. “So\nMany Filters, so Little Time: The Development of a Search Filter\nAppraisal Checklist.” J Med Libr Assoc 96 (18974813):\n356–61. https://doi.org/10.3163/1536-5050.96.4.011.\n\n\nGlanville, Julie, Ruth Foxlee, Susi Wisniewski, Anna Noel-Storr, Mary\nEdwards, and Gordon Dooley. 2019. “Translating the Cochrane EMBASE RCT filter from the Ovid\ninterface to Embase.com: a case study.” Health Info\nLibr J 36 (3): 264–77. https://doi.org/10.1111/hir.12269.\n\n\nGolder, Su, Heather M. McIntosh, Steve Duffy, and Julie Glanville. 2006.\n“Developing efficient search strategies to\nidentify reports of adverse effects in MEDLINE and\nEMBASE.” Health Info Libr J 23 (March): 3–12. https://doi.org/10.1111/j.1471-1842.2006.00634.x.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews.\nSecond. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically\nstrong studies of diagnosis from Medline: analytical\nsurvey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nHiggins, Julian P. T., James Thomas, Jacqueline Chandler, Miranda\nCumpston, Tianjing Li, Matthew J. Page, and Vivian A. Welch, eds. 2022.\nCochrane Handbook for Systematic Reviews of\nInterventions. 6.3 ed. Cochrane; Cochrane. https://training.cochrane.org/handbook.\n\n\nHinde, Sebastian, and Eldon Spackman. 2015. “Bidirectional Citation Searching to Completion: An\nExploration of Literature Searching Methods.”\nPharmacoEconomics 33 (1): 5–11. https://doi.org/10.1007/s40273-014-0205-3.\n\n\nHirt, Julian, Thomas Nordhausen, Christian Appenzeller-Herzog, and\nHannah Ewald. 2021. “Using citation tracking\nfor systematic literature searching – study protocol for a scoping\nreview of methodological studies and a Delphi study.”\nF1000Res 9 (September): 1386. https://doi.org/10.12688/f1000research.27337.3.\n\n\nHirt, Julian, Thomas Nordhausen, Thomas Fuerst, Hannah Ewald, and\nChristian Appenzeller-Herzog. 2024. “Guidance\non terminology, application, and reporting of citation searching: the\nTARCiS statement.” BMJ 385 (e078384). https://doi.org/10.1136/bmj-2023-078384.\n\n\nJanka, Heidrun, and Maria-Inti Metzendorf. 2024. “High Precision\nbut Variable Recall – Comparing the Performance of Five Deduplication\nTools.” JEAHIL 20 (1): 12–17. https://doi.org/10.32384/jeahil20607.\n\n\nJohnson, Claire. 2006. “Repetitive,\nDuplicate, and Redundant Publications: A Review for Authors and\nReaders.” J Manipulative Physiol Ther 29 (7):\n505–9. https://doi.org/10.1016/j.jmpt.2006.07.001.\n\n\nKassirer, Jerome P., and Marcia Angell. 1995. “Redundant\nPublication: A Reminder.” N Engl J Med 333 (7):\n449–50. https://doi.org/10.1056/NEJM199508173330709.\n\n\nKastner, Monika, Nancy L. Wilczynski, Ann K. McKibbon, Amit X. Garg, and\nR. Brian Haynes. 2009. “Diagnostic test\nsystematic reviews: Bibliographic search filters (‘Clinical\nQueries’) for diagnostic accuracy studies perform\nwell.” J Clin Epidemiol 62 (9): 974–81. https://doi.org/10.1016/j.jclinepi.2008.11.006.\n\n\nKnelangen, Marco, Elke Hausner, Maria-Inti Metzendorf, Sibylle Sturtz,\nand Siw Waffenschmidt. 2018. “Trial Registry Searches for\nRandomized Controlled Trials of New Drugs Required Registry-Specific\nAdaptation to Achieve Adequate Sensitivity.” J Clin\nEpidemiol 94: 69–75. https://doi.org/10.1016/j.jclinepi.2017.11.003.\n\n\nKoffel, Jonathan B. 2015. “Use of Recommended\nSearch Strategies in Systematic Reviews and the Impact of Librarian\nInvolvement: A Cross-Sectional Survey of Recent Authors.”\nPLOS ONE 10 (5): 1–13. https://doi.org/10.1371/journal.pone.0125931.\n\n\nLee, Edwin, Maureen Dobbins, Kara DeCorby, Lyndsey McRae, Daiva Tirilis,\nand Heather Husson. 2012. “An Optimal Search Filter for Retrieving\nSystematic Reviews and Meta-Analyses.” BMC Med Res\nMethodol 12 (1): 51. https://doi.org/10.1186/1471-2288-12-51.\n\n\nLefebvre, Carol, Julie Glanville, Sophie Beale, Charles Boachie, Steven\nDuffy, Cynthia Fraser, Jenny Harbour, Rachael McCool, and Lynne Smith.\n2017. “Assessing the Performance of Methodological Search Filters\nto Improve the Efficiency of Evidence Information Retrieval: Five\nLiterature Reviews and a Qualitative Study.” Health Technol\nAssess 21 (69): 1–148. https://doi.org/10.3310/hta21690.\n\n\nMcGowan, Jessie, Margaret Sampson, Douglas M. Salzwedel, Elise Cogo,\nVicki Foerster, and Carol Lefebvre. 2016. “PRESS Peer Review of Electronic Search Strategies: 2015\nGuideline Statement.” J Clin Epidemiol 75: 40–46.\nhttps://doi.org/10.1016/j.jclinepi.2016.01.021.\n\n\nMcKenzie, J. E., S. E. Brennan, R. E. Ryan, H. J. Thomson, R. V.\nJohnston, and J. Thomas. 2022. “Chapter 3: Defining the Criteria\nfor Including Studies and How They Will Be Grouped for the\nSynthesis.” In Cochrane Handbook for Systematic Reviews of\nInterventions, edited by J. P. T. Higgins, J. Thomas, J. Chandler,\nM. Cumpston, T. Li, M. J. Page, and V. A. Welch. Cochrane.\n\n\nMcKeown, Sandra, and Zuhaib M. Mir. 2021. “Considerations for\nConducting Systematic Reviews: Evaluating the Performance of Different\nMethods for de-Duplicating References.” Syst Rev 10 (1):\n38. https://doi.org/10.1186/s13643-021-01583-y.\n\n\nMeert, Deborah, Nazi Torabi, and John Costella. 2016. “Impact of\nLibrarians on Reporting of the Literature Searching Component of\nPediatric Systematic Reviews.” J Med Libr Assoc 104\n(October): 267–77. https://doi.org/10.3163/1536-5050.104.4.004.\n\n\nMethley, Abigail M., Stephen Campbell, Carolyn Chew-Graham, Rosalind\nMcNally, and Sudeh Cheraghi-Sohi. 2014. “PICO, PICOS and SPIDER: a comparison study of specificity\nand sensitivity in three search tools for qualitative systematic\nreviews.” BMC Health Serv Res 14 (1): 579. https://doi.org/10.1186/s12913-014-0579-0.\n\n\nMetzendorf, Maria-Inti. 2016. “Why medical\ninformation specialists should routinely form part of teams producing\nhigh quality systematic reviews - a Cochrane perspective.”\nJEAHIL 12 (4): 6–9. http://ojs.eahil.eu/ojs/index.php/JEAHIL/issue/view/85/12_4.\n\n\nMoher, D., B. Pham, M. L. Lawson, and T. P. Klassen. 2003. “The inclusion of reports of randomised trials published\nin languages other than English in systematic reviews.”\nHealth Technol Assess 7: 1–90. https://doi.org/10.3310/hta7410.\n\n\nMorrison, Andra, Julie Polisena, Don Husereau, Kristen Moulton, Michelle\nClark, Michelle Fiander, Monika Mierzwinski-Urban, et al. 2012.\n“The effect of English-language restriction\non systematic review-based meta-analyses: a systematic review of\nempirical studies.” Int J Technol Assess Health\nCare 28 (2): 138–44. https://doi.org/10.1017/S0266462312000086.\n\n\nMulrow, Cynthia D. 1994. “Rationale For Systematic\nReviews.” BMJ 309 (6954): 597–99. http://www.jstor.org/stable/29724645.\n\n\nMunn, Z., M. D. J. Peters, C. Stern, C. Tufanaru, A. McArthur, and E.\nAromataris. 2018. “Systematic Review or Scoping Review? Guidance\nfor Authors When Choosing Between a Systematic or Scoping Review\nApproach.” Journal Article. BMC Med Res Methodol 18 (1):\n143. https://doi.org/10.1186/s12874-018-0611-x.\n\n\nMunn, Z., C. Stern, E. Aromataris, C. Lockwood, and Z. Jordan. 2018.\n“What kind of systematic review should I\nconduct? A proposed typology and guidance for systematic reviewers in\nthe medical and health sciences.” Journal Article. BMC\nMed Res Methodol 18 (1): 5. https://doi.org/10.1186/s12874-017-0468-4.\n\n\nMurad, Mohammad Hassan, Victor M. Montori, John P. A. Ioannidis, Roman\nJaeschke, P. J. Devereaux, Kameshwar Prasad, Ignacio Neumann, et al.\n2014. “How to Read a Systematic Review and\nMeta-analysis and Apply the Results to Patient Care: Users’ Guides to\nthe Medical Literature.” JAMA 312 (2): 171–79. https://doi.org/10.1001/jama.2014.5559.\n\n\nNagendrababu, V., P. Dilokthornsakul, P. Jinatongthai, S. K. Veettil, S.\nJ. Pulikkotil, H. F. Duncan, and P. M. H. Dummer. 2020. “Glossary\nfor Systematic Reviews and Meta-Analyses.” Int Endod J\n53 (2): 232–49. https://doi.org/10.1111/iej.13217.\n\n\nNévéol, Aurélie, Rezarta Islamaj Doğan, and Zhiyong Lu. 2010.\n“Author Keywords in Biomedical Journal\nArticles.” AMIA Annu Symp Proc 2010 (November):\n537–41. https://pubmed.ncbi.nlm.nih.gov/21347036/.\n\n\nO’Regan, Gerard. 2012. A Brief History of\nComputing. Second. Springer, London. https://doi.org/10.1007/978-1-4471-2359-0.\n\n\nOdgaard‐Jensen, Jan, Gunn E. Vist, Antje Timmer, R. Kunz, Elie A. Akl,\nHolger Schünemann, Matthias Briel, Alain J. Nordmann, Silvia Pregno, and\nAndrew D. Oxman. 2011. “Randomisation to Protect Against Selection\nBias in Healthcare Trials.” Cochrane Database Syst Rev  \n(4). https://doi.org/10.1002/14651858.MR000012.pub3.\n\n\nPage, Matthew J., Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle\nBoutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al.\n2021. “The PRISMA 2020 statement: an updated\nguideline for reporting systematic reviews.” BMJ\n372. https://doi.org/10.1136/bmj.n71.\n\n\nPage, Matthew J., David Moher, Patrick M. Bossuyt, Isabelle Boutron,\nTammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021.\n“PRISMA 2020 explanation and elaboration:\nupdated guidance and exemplars for reporting systematic\nreviews.” BMJ 372. https://doi.org/10.1136/bmj.n160.\n\n\nPearson, A., H. White, F. Bath-Hextall, S. Salmond, J. Apostolo, and P.\nKirkpatrick. 2015. “A Mixed-Methods Approach to Systematic\nReviews.” Journal Article. Int J Evid Based Healthc 13\n(3): 121–31. https://doi.org/10.1097/XEB.0000000000000052.\n\n\nPitkin, Roy M., and Mary Ann Branagan. 1998. “Can the Accuracy of Abstracts Be Improved by Providing\nSpecific Instructions? A Randomized Controlled Trial.”\nJAMA 280 (3): 267–69. https://doi.org/10.1001/jama.280.3.267.\n\n\nRethlefsen, Melissa L., Ann M. Farrell, Leah C. Osterhaus Trzasko, and\nTara J. Brigham. 2015. “Librarian Co-Authors Correlated with\nHigher Quality Reported Search Strategies in General Internal Medicine\nSystematic Reviews.” J Clin Epidemiol 68 (June): 617–26.\nhttps://doi.org/10.1016/j.jclinepi.2014.11.025.\n\n\nRethlefsen, Melissa L., Shona Kirtley, Siw Waffenschmidt, Ana Patricia\nAyala, David Moher, Matthew J. Page, Jonathan B. Koffel, et al. 2021.\n“PRISMA-S: an extension to the PRISMA\nStatement for Reporting Literature Searches in Systematic\nReviews.” Syst Rev 10 (1): 39. https://doi.org/10.1186/s13643-020-01542-z.\n\n\nRethlefsen, Melissa, and Matthew J. Page. 2021. “PRISMA 2020 and PRISMA-S: Common Questions on Tracking\nRecords and the Flow Diagram.” MetaArXiv. https://doi.org/10.31222/osf.io/439ju.\n\n\nSalvador-Oliván, José Antonio, Gonzalo Marco-Cuenca, and Rosario\nArquero-Avilés. 2021. “Development of an\nefficient search filter to retrieve systematic reviews from\nPubMed.” J Med Libr Assoc 109 (4). https://doi.org/10.5195/jmla.2021.1223.\n\n\nSchellinger, Jana, Kerry Sewell, Jamie E. Bloss, Tristan Ebron, and\nCarrie Forbes. 2021. “The Effect of Librarian Involvement on the\nQuality of Systematic Reviews in Dental Medicine.” PLoS\nOne 16: e0256833. https://doi.org/10.1371/journal.pone.0256833.\n\n\nSpencer, Angela J., and Jonathan D. Eldredge. 2018. “Roles for\nLibrarians in Systematic Reviews: A Scoping Review.” J Med\nLibr Assoc 106 (January): 46–56. https://doi.org/10.5195/jmla.2018.82.\n\n\nTricco, A. C., E. Lillie, W. Zarin, K. K. O’Brien, H. Colquhoun, D.\nLevac, D. Moher, et al. 2018. “PRISMA\nExtension for Scoping Reviews (PRISMA-ScR): Checklist and\nExplanation.” Journal Article. Ann Intern Med 169\n(7): 467–73. https://doi.org/10.7326/M18-0850.\n\n\nTwells, Laurie K. 2021. “Evidence-Based Decision-Making 1:\nCritical Appraisal.” In Clinical Epidemiology:\nPractice and Methods, edited by Patrick S. Parfrey and Brendan J.\nBarrett, 389–404. New York, NY: Springer US. https://doi.org/10.1007/978-1-0716-1138-8_21.\n\n\nWaffenschmidt, Siw, Tamara Navarro-Ruan, Nick Hobson, Elke Hausner,\nStefan Sauerland, and R. Brian Haynes. 2020. “Development and validation of study filters for\nidentifying controlled non-randomized studies in PubMed and Ovid\nMEDLINE.” Res Syn Meth 11 (5): 617–26. https://doi.org/10.1002/jrsm.1425.\n\n\nWanner, Amanda, and Niki Baumann. 2019. “Design and implementation of a tool for conversion of\nsearch strategies between PubMed and Ovid MEDLINE.”\nRes Syn Meth 10 (2): 154–60. https://doi.org/10.1002/jrsm.1314.",
    "crumbs": [
      "References"
    ]
  }
]