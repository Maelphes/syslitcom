[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SysLit Compendium",
    "section": "",
    "text": "Welcome\nThis is a compendium for the field of systematic literature searching. It contains technical terms, methods and background information related to the retrieval of references from literature databases.\nThe main idea is to inform anyone who undertakes a systematic literature search about relevant terms of the trade.\n\n\n\n\n\n\nWarning\n\n\n\nThis website is still being setup. It may contain errors and certainly raises no claims to completeness.\n\n\nIn 1  Databases you will learn about all kinds of data sources and search interfaces as well as their syntax.\nTechnical terms of all sorts are explained in 2  Technical terms.\n3  Tools tells you about various tools and useful concepts for creating your search for evidence.\nChapter 4  Methods describes various techniques of building and conducting a systematic search.\nThis website is created and maintained by Marc von Gernler (Medical Library, University Library of Bern, University of Bern). The “compendium” was originally written in German as a glossary for lectures and as a mnemonic for the author. It was originally typeset in LaTeX (Link to the original document).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "1  Databases",
    "section": "",
    "text": "1.1 Clinical Trials Registries\nBefore clinical trials are performed, they are registered in in dedicated databases, so-called clinical trials registries (CTR). The purpose of this practice is to combat publication bias (see Section 2.5) and to increase transparency and provide access to the clinical trials.\nThese records clinical trials registries usually comprise information such as study title, short description, study type, eligibility criteria for participants, interventions, randomization, study status and contact information. (See also Glanville et al. (2014), Knelangen et al. (2018)).\nA comprehensive list of resources is maintained by Julie Glanville and Carol Lefebvre.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-ctr",
    "href": "databases.html#sec-ctr",
    "title": "1  Databases",
    "section": "",
    "text": "Clinical Trial Registries\n\n\n\n\n\n\n\n\nCountry\nWebsite\n\n\n\n\nAU/NZ\nAustralian and New Zealand Clinical Trials Registry (ANZCTR)\n\n\nCH\nSwiss National Clinical Trials Portal (SNCTP)\n\n\nCN\nChinese Clinical Trial Registry (ChiCTR)\n\n\nDE\nGerman Clinical Trials Register (DRKS)\n\n\nEU\nEU Clinical Trials Register (EUCTR) (only records prior to 31-01-2022)\n\n\nEU\nClinical Trials Information System (CTIS)\n\n\nIN\nClinical Trials Registry India (CTRI)\n\n\nNL\nOverview of Medical Research in the Netherlands (OMON)\n\n\nUK\nISRCTN\n\n\nUS\nClinialTrials.gov\n\n\nWHO\nInternational Clinical Trials Registry Platform (ICTRP)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-cochranelibrary",
    "href": "databases.html#sec-cochranelibrary",
    "title": "1  Databases",
    "section": "1.2 Cochrane Library",
    "text": "1.2 Cochrane Library\nThe Cochrane Library is the collection of Cochrane’s databases, most importantly the Cochrane Database of Systematic Reviews (CDSR) and the Cochrane Central Register of Controlled Trials (CENTRAL), which contain different types evidence to inform healthcare decision-making. Switzerland has complete access to the Cochrane Library due to a national license.\n\n1.2.1 Cochrane Database of Systematic Reviews (CDSR)\nThe Cochrane Database of Systematic Reviews (CDSR) is a leading journal (ISSN: 1469-493X) and database for systematic reviews in health care. Cochrane Reviews are published in CDSR, which is accessible via the Cochrane Library.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-pubmed",
    "href": "databases.html#sec-pubmed",
    "title": "1  Databases",
    "section": "1.3 PubMed",
    "text": "1.3 PubMed\nPubMed is a public and freely available database, maintained by the National Center of Biotechnology Information (NCBI) at the U.S. National Library of Medicine (NLM). In 2024, it contains over 37 million records of biomedical and life science literature.\nPubMed and MEDLINE are often used synonymously. However, there is a difference, explained in detail at https://nlm.nih.gov/bsd/difference.html.\nPubMed facilitates searching within the databases MEDLINE, PubMed Central (PMC) and Bookshelf.\nAll records in PubMed possess a unique identifier, the PubMed ID (PMID), see also Section 2.7.\nRoughly 84 percent of the records in PubMed are indexed using Medical Subject Headings (MeSH).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-pmc",
    "href": "databases.html#sec-pmc",
    "title": "1  Databases",
    "section": "1.4 PubMed Central",
    "text": "1.4 PubMed Central\nPubMed Central (PMC) is a free full-text database of the NLM. It features Open Access articles from biomedicine and life sciences.\nPMC can be searched directly or as part of the PubMed database.\nPMC records possess the PubMed Central ID (PMCID) as a digital identifier, see Section 2.7.\n\n\n\n\nGlanville, Julie M., Steven Duffy, Rachael McCool, and Danielle Varley. 2014. “Searching ClinicalTrials.gov and the International Clinical Trials Registry Platform to inform systematic reviews: what are the optimal search approaches?” J Med Libr Assoc 102 (25031558): 177–83. https://doi.org/10.3163/1536-5050.102.3.007.\n\n\nKnelangen, Marco, Elke Hausner, Maria-Inti Metzendorf, Sibylle Sturtz, and Siw Waffenschmidt. 2018. “Trial Registry Searches for Randomized Controlled Trials of New Drugs Required Registry-Specific Adaptation to Achieve Adequate Sensitivity.” J Clin Epidemiol 94: 69–75. https://doi.org/10.1016/j.jclinepi.2017.11.003.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Databases</span>"
    ]
  },
  {
    "objectID": "technicalterms.html",
    "href": "technicalterms.html",
    "title": "2  Technical terms",
    "section": "",
    "text": "2.1 abstract\nAn abstract is the short summary at the beginning of scientific publications, e.g. journal articles, theses or conference papers. The abstract is among the most important parts of a publication as it is usually the only part of the text which is freely available and can be retrieved from bibliographic databases. Title and abstract are the key elements of a textword search. (Cals and Kotz (2013), Pitkin and Branagan (1998))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-ambiguity",
    "href": "technicalterms.html#sec-ambiguity",
    "title": "2  Technical terms",
    "section": "2.2 ambiguity",
    "text": "2.2 ambiguity\nA term or statement which has more than one possible meaning or definition is ambiguous. Ambiguity proves to be an obstacle in creating search strategies, because any free text search with ambiguous terms will inevitably retrieve records for all meanings of the term regardless of the context. In this case, it is an option to render such terms more specific by using phrases or proximity operators.\n\n\n\n\n\n\nExamples\n\n\n\n\napothecary might refer to the occuopation of pharmacist or the community pharmacy as a location or institution.\nThe term pharmacy may refer to the pharmaceutical sciences, the manufacture of drugs or the pharmacy as a retail shop.\nIn anatomy, a styloid process is a pointed outgrowth from a bone. However, there are serveral of these in the human body, for instance in the temporal bone, the radius bone, the ulna bone or the metacarpal bones.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-appendix",
    "href": "technicalterms.html#sec-appendix",
    "title": "2  Technical terms",
    "section": "2.3 appendix",
    "text": "2.3 appendix\nAn appendix provides additional content to a publication and is often called supplementary material or supplementary information. Usually any content which goes beyond the constraints of the publication is provided there. Examples are the full search strategies of systematic literature searches, detailed descriptions of methods or measurements.\nIt is also possible to publish such supplementary information or research data independently in online repositories.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-authorkeywords",
    "href": "technicalterms.html#sec-authorkeywords",
    "title": "2  Technical terms",
    "section": "2.4 author keyword",
    "text": "2.4 author keyword\nPublishers often require the authors of a publication to provide keywords describing the content of the publication. These keywords don’t necessarily correspond to controlled vocabulary (i.e. index terms, which are assigned to the records by the database) and should not be confused with them. (Névéol, Doğan, and Lu (2010))\nAuthor keywords are often used as part of the free text search.\n\n\n\n\n\n\nExamples\n\n\n\nWithin PubMed the field codes [OT] or [Other Term] can be used for searching the author keywords. This field is automatically searched when [TIAB](or [Title/Abstract]) or [TW] (or [Text Word]) are used.\nIn Ovid MEDLINE the corresponding field codes .kw or .kf can be used for searching the author keywords.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-bias",
    "href": "technicalterms.html#sec-bias",
    "title": "2  Technical terms",
    "section": "2.5 bias",
    "text": "2.5 bias\nBias is a systematic deviation between results and facts that may lead to under- or over-estimation of intervention effects. As a result bias might lead to conclusions which do not accurately represent the truth. There are various types and sources for bias, as well as methods to avoid some forms of bias, such as randomization or blinding of participants in clinical trials.\nSystematic literature searching is a means to reduce bias. Systematic reviews strive to minimise these deviations by assessing the risk of bias in results of included studies. (Braun et al. (2021), Boutron et al. (2022), Gough, Oliver, and Thomas (2017))\n\n2.5.1 selection bias\nSystematic differences between comparison groups lead to a deviation from the true effect of an intervention. This so-called selection bias can be prevented by measures such as the sufficient randomization and concealment of allocation of trial participants to different study arms.(Gough, Oliver, and Thomas (2017), Odgaard‐Jensen et al. (2011))\n\n\n2.5.2 publication bias\nResults perceived as “positive” are more likely to be published than those results which are perceived as “negative”, which gives the positive results more weight. (Gough, Oliver, and Thomas (2017))\n\n\n2.5.3 language of publication bias\nIn systematic literature searches it is often tempting to restrict the search to languages which are easily understood by the screeners and researchers. Not only will this practive keep the number of records at a more manageable level, it also makes the translation of foreign publications unnecessary. However, this so-called language of publication bias can have a significant impact on the quality of the review. (Gough, Oliver, and Thomas (2017), Morrison et al. (2012), Moher et al. (2003))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-class-metrics",
    "href": "technicalterms.html#sec-class-metrics",
    "title": "2  Technical terms",
    "section": "2.6 classification metrics",
    "text": "2.6 classification metrics\nIn information retrieval the performance of a systematic search, a search strategy or a search filter is described by certain metrics for binary classification tasks, such as accuracy, precision, sensitivity and specificity.\nA classifier (the search) makes a prediction about the condition of a record (by retrieving or not retrieving the record). The classification (the search result) is evaluated by comparing the prediction with the actual condition (the relevance of the records).\nIn other words: The literature search is supposed to retrieve mostly relevant references and ignore non-relevant ones. A retrieved relevant record equals a true positive (tp), whereas a retrieved non-relevant record equals a false positive (fp). See Table 2.1 for reference.\n\n\n\nTable 2.1: Truth table\n\n\n\n\n\nrecord\nrelevant\nirrelevant\n\n\n\n\nretrieved\ntp\nfp\n\n\nnot retrieved\nfn\ntn\n\n\n\n\n\n\n\n2.6.1 accuracy\nAccuracy, also called fraction correct (FC), is a statistical measure of how well a binary classifier correctly (“true”) identifies a condition (“positive or negative”). It is defined as the ratio of all true classifications (true positives and true negatives) to the total number of classifications. (Haynes and Wilczynski (2004), Lefebvre et al. (2017), Fawcett (2006))\nIt can be calculated according to the following equation: \\[\n\\text{accuracy} = \\tfrac{tp + tn}{tp + fp + fn + tn}\n\\]\n\n\n2.6.2 precision\nPrecision, also called positive predictive value (PPV), is a performance metric for the retrieval of information. It is the fraction of all relevant records among all retrieved records, which can be written as:\n\\[\n\\text{precision} = \\tfrac{tp}{tp + fp}\n\\]\nA high-precision search tries to retrieve as few non-relevant records as possible, usually missing out on relevant records.\n\n\n2.6.3 sensitivity\nSensitivity, also called true positive rate (TPR), recall or hit rate, is a performance metric for the retrieval of informaton, similar to the precision. It equals the probability with which relevant records are correctly identified. (See Haynes and Wilczynski (2004), Lefebvre et al. (2017)).\nIt is the ratio of all relevant retrieved records and the total of all relevant records: \\[\n\\text{sensitivity} = \\tfrac{tp}{tp + fn}\n\\] The idea of a sensitive search is to retrieve as many relevant records as possible, which results in retrieving more non-relevant records in the process.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-pmid-pmcid",
    "href": "technicalterms.html#sec-pmid-pmcid",
    "title": "2  Technical terms",
    "section": "2.7 PMID and PMCID",
    "text": "2.7 PMID and PMCID\nThe PubMed ID (PMID) and the PubMed Central ID (PMCID) are unique identifiers assigned to the records within the databases PubMed and PubMed Central. They are similar to the digital object identifier (DOI).\nPMIDs are unique integer values, e.g. 32256971, PMCIDs are composed of the prefix PMC followed by a series of numbers, e.g. PMC7106990.\nPubMed records can easily be found simply by entering their PMIDs as search terms into the PubMed search.\n\n\n\n\n\n\nConversion tool\n\n\n\nThe National Library of Medicine provides a tool for the conversion of the PMID, PMCID and DOI into one another. This tool only works for records which are both part of PubMed and PubMed Central.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "technicalterms.html#sec-syntax",
    "href": "technicalterms.html#sec-syntax",
    "title": "2  Technical terms",
    "section": "2.8 Syntax",
    "text": "2.8 Syntax\nSimilar to programming, the syntax is the set of rules that applies for setting up search queries and building search strategies in databases. It defines the operators, field codes and special characters (such as wildcard symbols, parentheses, slashes, quotation marks, etc.) that are available within a particular search interface.\nAs a consequence, search strategies cannot be used freely in every database. They have to be translated due to different syntax and due to different index terms. (See Clark et al. (2020), Glanville et al. (2019), Wanner and Baumann (2019), Damarell, Tieman, and Sladek (2013)).\n\n\n\nTable 2.2: Examples for syntax in different search interfaces\n\n\n\n\n\n\n\n\n\nPubMed\n\"ocular hypertension\"[tiab]\n\n\nEmbase\n'ocular hypertension':ti,ab\n\n\nOvid\n\"ocular hypertension\".ti,ab.\n\n\nCochrane Library\n\"ocular hypertension\":ti,ab\n\n\nScopus\nTITLE-ABS({ocular hypertension})\n\n\nWeb of Science\nTI=(\"ocular hypertension\") OR AB=(\"ocular hypertension\")\n\n\nEBSCOhost\n(TI \"ocular hypertension\") OR (AB \"ocular hypertension\")\n\n\n\n\n\n\n\n\n\n\nBoutron, I., M. J. Page, J. P. T. Higgins, D. G. Altman, A. Lundh, and A. Hróbjartsson. 2022. “Chapter 7: Considering Bias and Conflicts of Interest Among the Included Studies.” In Cochrane Handbook for Systematic Reviews of Interventions, edited by J. P. T. Higgins, J. Thomas, J. Chandler, M. Cumpston, T. Li, M. J. Page, and V. A. Welch. Cochrane.\n\n\nBraun, Cordula, Christine Schmucker, Monika Nothacker, Kai Nitschke, Corinna Schaefer, Claudia Bollig, Cathleen Muche-Borowski, Ina B. Kopp, and Jörg Meerpohl. 2021. “Manual Bewertung des Biasrisikos in Interventionsstudien.” Albert-Ludwigs-Universität Freiburg. https://doi.org/10.6094/UNIFR/194900.\n\n\nCals, Jochen W. L., and Daniel Kotz. 2013. “Effective writing and publishing scientific papers, part II: title and abstract.” J Clin Epidemiol 66 (6): 585. https://doi.org/10.1016/j.jclinepi.2013.01.005.\n\n\nClark, Justin Michael, Sharon Sanders, Matthew Carter, David Honeyman, Gina Cleo, Yvonne Auld, Debbie Booth, et al. 2020. “Improving the translation of search strategies using the Polyglot Search Translator: a randomized controlled trial.” J Med Libr Assoc 108 (2): 195–207. https://doi.org/10.5195/jmla.2020.834.\n\n\nDamarell, Raechel A., Jennifer J. Tieman, and Ruth M. Sladek. 2013. “OvidSP Medline-to-PubMed search filter translation: a methodology for extending search filter range to include PubMed’s unique content.” BMC Med Res Methodol 13 (1): 86. https://doi.org/10.1186/1471-2288-13-86.\n\n\nFawcett, Tom. 2006. “An Introduction to ROC Analysis.” Pattern Recognit Lett 27 (8): 861–74. https://doi.org/10.1016/j.patrec.2005.10.010.\n\n\nGlanville, Julie, Ruth Foxlee, Susi Wisniewski, Anna Noel-Storr, Mary Edwards, and Gordon Dooley. 2019. “Translating the Cochrane EMBASE RCT filter from the Ovid interface to Embase.com: a case study.” Health Info Libr J 36 (3): 264–77. https://doi.org/10.1111/hir.12269.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews. Second. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically strong studies of diagnosis from Medline: analytical survey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nLefebvre, Carol, Julie Glanville, Sophie Beale, Charles Boachie, Steven Duffy, Cynthia Fraser, Jenny Harbour, Rachael McCool, and Lynne Smith. 2017. “Assessing the Performance of Methodological Search Filters to Improve the Efficiency of Evidence Information Retrieval: Five Literature Reviews and a Qualitative Study.” Health Technol Assess 21 (69): 1–148. https://doi.org/10.3310/hta21690.\n\n\nMoher, D., B. Pham, M. L. Lawson, and T. P. Klassen. 2003. “The inclusion of reports of randomised trials published in languages other than English in systematic reviews.” Health Technol Assess 7: 1–90. https://doi.org/10.3310/hta7410.\n\n\nMorrison, Andra, Julie Polisena, Don Husereau, Kristen Moulton, Michelle Clark, Michelle Fiander, Monika Mierzwinski-Urban, et al. 2012. “The effect of English-language restriction on systematic review-based meta-analyses: a systematic review of empirical studies.” Int J Technol Assess Health Care 28 (2): 138–44. https://doi.org/10.1017/S0266462312000086.\n\n\nNévéol, Aurélie, Rezarta Islamaj Doğan, and Zhiyong Lu. 2010. “Author Keywords in Biomedical Journal Articles.” AMIA Annu Symp Proc 2010 (November): 537–41. https://pubmed.ncbi.nlm.nih.gov/21347036/.\n\n\nOdgaard‐Jensen, Jan, Gunn E. Vist, Antje Timmer, R. Kunz, Elie A. Akl, Holger Schünemann, Matthias Briel, Alain J. Nordmann, Silvia Pregno, and Andrew D. Oxman. 2011. “Randomisation to Protect Against Selection Bias in Healthcare Trials.” Cochrane Database Syst Rev   (4). https://doi.org/10.1002/14651858.MR000012.pub3.\n\n\nPitkin, Roy M., and Mary Ann Branagan. 1998. “Can the Accuracy of Abstracts Be Improved by Providing Specific Instructions? A Randomized Controlled Trial.” JAMA 280 (3): 267–69. https://doi.org/10.1001/jama.280.3.267.\n\n\nWanner, Amanda, and Niki Baumann. 2019. “Design and implementation of a tool for conversion of search strategies between PubMed and Ovid MEDLINE.” Res Syn Meth 10 (2): 154–60. https://doi.org/10.1002/jrsm.1314.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Technical terms</span>"
    ]
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "3  Tools",
    "section": "",
    "text": "3.1 FINER\nFINER is an acronym for the five criteria feasible, interesting, novel, ethical and relevant which can be used as guidance when formulating a good clinical research question. See Table 3.1. (Cummings, Browner, and Hulley (2013))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-finer",
    "href": "tools.html#sec-finer",
    "title": "3  Tools",
    "section": "",
    "text": "Table 3.1\n\n\n\n\n\n\nCriterion\nMeaning\n\n\n\n\nfeasible\nThe research question should not exceed the available resources, i.e. participants, expertise, time and money).\n\n\ninteresting\nThe research question should in itself be interesting, not only to the researcher, but also to a broader public.\n\n\nnovel\nThe gain of knowledge and new information should be at the heart of the question. Research usually does not only reiterate already established data unless it is designed as a confirmatory study.\n\n\nethical\nProper research has to be ethical and must not bear unacceptable risks for its participants.\n\n\nrelevant\nThe expected impact of the research on scientific knowledge and clinical processes can be a good measurement parameter for the relevance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-pico",
    "href": "tools.html#sec-pico",
    "title": "3  Tools",
    "section": "3.2 PICO",
    "text": "3.2 PICO\nPICO is a mnemonic for the concepts Population, Intervention, Comparison and Outcome. Concepts like these are used for defining research questions as well as eligibility criteria for the studies relevant for answering the question.\nThere are other concepts and mnemonics for different kinds of research questions, such as SPIDER, ECLIPSE, PIRD or PICOS. (Munn et al. (2018), Methley et al. (2014), Eriksen and Frandsen (2018))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-press",
    "href": "tools.html#sec-press",
    "title": "3  Tools",
    "section": "3.3 PRESS",
    "text": "3.3 PRESS\nPeer Review of Electronic Search Strategies (PRESS) by McGowan et al. (2016) is an evidence-based guideline for the peer review of search strategies. It is mainly focused on systematic review projects, health technology assesments (HTAs) and other kinds of reviews. A main tool for PRESS is a checklist which guides the reader through the process of peer review.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-prisma",
    "href": "tools.html#sec-prisma",
    "title": "3  Tools",
    "section": "3.4 PRISMA",
    "text": "3.4 PRISMA\nPreferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) by Page, McKenzie, et al. (2021) is a set of minimum requirements for the reporting and documentation of systematic reviews. The goal of PRISMA is to set standards for reporting and in doing so increase the overall quality of systematic reviews. A detailed explanatory paper was published by Page, Moher, et al. (2021).\nPRISMA also provides tools such as a checklist and a flowchart, which can be used for creating the recommended tables and figures for publication. (M. Rethlefsen and Page (2021))\nThere are additional extensions of PRISMA for various purposes, such as PRISMA-S for the documentation of systematic literature searches (M. L. Rethlefsen et al. (2021)) or PRISMA-ScR for scoping reviews (Tricco et al. (2018)).\nSee also https://prisma-statement.org.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "tools.html#sec-refmanagement",
    "href": "tools.html#sec-refmanagement",
    "title": "3  Tools",
    "section": "3.5 Reference Management software",
    "text": "3.5 Reference Management software\nBibliographic records and similar sets of data such as clinical study metadata can be stored and managed using reference management programs (also called citation management software).\nThese programs are usually able to perform tasks with the records, such as\n\nimport and export of various formats (e.g. RIS, NBIB, BIB, TXT, CSV, XML)\ncreation, editing and updating\ndeduplication\nretrieval of full-texts\noutput of citations in various styles\n\n\n\n\n\n\n\nExamples of reference managers\n\n\n\n\n\n\nCitavi\nEndNote\nJabRef\nMendeley\nZotero\n\n\n\n\nFor comparisons of reference management software see also https://mediatum.ub.tum.de/1320978 and https://en.wikipedia.org/wiki/Comparison_of_reference_management_software.\n\n\n\n\nCummings, Steven R., Warren S. Browner, and Stephen B. Hulley. 2013. “Conceiving the Research Question and Developing the Study Plan.” In Designing Clinical Research, edited by Stephen B. Hulley, Steven R. Cummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman, 4. ed., 14–22. Philadelphia: Lippincott Williams & Wilkins. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/99pfpl/alma99117040391205511.\n\n\nEriksen, Mette Brandt, and Tove Faber Frandsen. 2018. “The impact of patient, intervention, comparison, outcome (PICO) as a search strategy tool on literature search quality: a systematic review.” J Med Libr Assoc 106 (4): 420–31. https://doi.org/10.5195/jmla.2018.345.\n\n\nMcGowan, Jessie, Margaret Sampson, Douglas M. Salzwedel, Elise Cogo, Vicki Foerster, and Carol Lefebvre. 2016. “PRESS Peer Review of Electronic Search Strategies: 2015 Guideline Statement.” J Clin Epidemiol 75: 40–46. https://doi.org/10.1016/j.jclinepi.2016.01.021.\n\n\nMethley, Abigail M., Stephen Campbell, Carolyn Chew-Graham, Rosalind McNally, and Sudeh Cheraghi-Sohi. 2014. “PICO, PICOS and SPIDER: a comparison study of specificity and sensitivity in three search tools for qualitative systematic reviews.” BMC Health Serv Res 14 (1): 579. https://doi.org/10.1186/s12913-014-0579-0.\n\n\nMunn, Z., C. Stern, E. Aromataris, C. Lockwood, and Z. Jordan. 2018. “What kind of systematic review should I conduct? A proposed typology and guidance for systematic reviewers in the medical and health sciences.” Journal Article. BMC Med Res Methodol 18 (1): 5. https://doi.org/10.1186/s12874-017-0468-4.\n\n\nPage, Matthew J., Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle Boutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021. “The PRISMA 2020 statement: an updated guideline for reporting systematic reviews.” BMJ 372. https://doi.org/10.1136/bmj.n71.\n\n\nPage, Matthew J., David Moher, Patrick M. Bossuyt, Isabelle Boutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021. “PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews.” BMJ 372. https://doi.org/10.1136/bmj.n160.\n\n\nRethlefsen, Melissa L., Shona Kirtley, Siw Waffenschmidt, Ana Patricia Ayala, David Moher, Matthew J. Page, Jonathan B. Koffel, et al. 2021. “PRISMA-S: an extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews.” Syst Rev 10 (1): 39. https://doi.org/10.1186/s13643-020-01542-z.\n\n\nRethlefsen, Melissa, and Matthew J. Page. 2021. “PRISMA 2020 and PRISMA-S: Common Questions on Tracking Records and the Flow Diagram.” MetaArXiv. https://doi.org/10.31222/osf.io/439ju.\n\n\nTricco, A. C., E. Lillie, W. Zarin, K. K. O’Brien, H. Colquhoun, D. Levac, D. Moher, et al. 2018. “PRISMA Extension for Scoping Reviews (PRISMA-ScR): Checklist and Explanation.” Journal Article. Ann Intern Med 169 (7): 467–73. https://doi.org/10.7326/M18-0850.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "4  Methods",
    "section": "",
    "text": "4.1 Boolean operators\nDatabases usually allow a search to be structured using the three basic operations of Boolean algebra, which are expressed with the Boolean operators AND (conjunction), OR (disjunction) and NOT (negation). The AND operator creates an intersection of sets, OR creates a union of sets and NOT excludes sets (see Figure 4.1).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-boolean",
    "href": "methods.html#sec-boolean",
    "title": "4  Methods",
    "section": "",
    "text": "Figure 4.1: Boolean Operators\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\nThe query \"heart attack\" AND diabetes AND obesity retrieves only records featuring all three terms.\nThe query \"cardiac arrest\" OR asystole retrieves records containing at least one of the two terms.\nThe query animals NOT humans removes all records mentioning humans from the set animals.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nUsing the NOT operator can be dangerous, as it excludes records regardless of any relevant search terms they might contain. The above example excludes also records with animals if they mention humans.\n\n\n\nProperties\nThe Boolean operators AND and OR possess similar properties as the multiplication and addition. See Table 4.1. (O’Regan (2012))\n1 (a OR b) = (b OR a)\n (a AND b) = (b AND a)\n ----\n2 (a OR b) OR c = a OR (b OR c)\n (a AND b) AND c = a AND (b AND c)\n ----\n3 a AND (b OR c) = (a AND b) OR (a AND c)\n a OR (b AND c) = (a OR b) AND (a OR c)\n\n\n\nTable 4.1\n\n\n\n1\n\ncommutative property\n\n2\n\nassociative property\n\n3\n\ndistributive property",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-citationanalysis",
    "href": "methods.html#sec-citationanalysis",
    "title": "4  Methods",
    "section": "4.2 citation analysis",
    "text": "4.2 citation analysis\nRelevant references can be retrieved by analyzing citation relationships between known relevant articles (core papers) and cited or citing references. This technique is called citation analysis or citation tracking (Hirt et al. (2021), Belter (2016), Hinde and Spackman (2015).\nCitation analysis can be advisable at the very beginning of a systematic literature search in order to find additional core papers and to identify additional search terms. After finishing the final search it can be used to find additional relevant studies that were not retrieved by systematic searching using search strategies.\nThere are different approaches to tracking citations: First, in the backward citation tracking method the lists of references cited in the core papers are screened for relevant articles. Second, the analysis of publications citing the core paper as reference is called forward citation tracking. See Figure 4.2.\n\n\n\n\n\n\nFigure 4.2: backward and forward citation tracking\n\n\n\nThird, the identification of relevant literature by counting co-cited or co-citing references is called co-citation tracking, see Figure 4.3 and Figure 4.4.\n\n\n\n\n\n\nFigure 4.3: co-citation tracking using the citing articles which the core paper has in common with other papers\n\n\n\n\n\n\n\n\n\nFigure 4.4: co-citation tracking using the cited references which the core paper has in common with other papers",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-filters",
    "href": "methods.html#sec-filters",
    "title": "4  Methods",
    "section": "4.3 filters",
    "text": "4.3 filters\nFilters (also search filters, filter strategies or hedges) are search strategies designed to retrieve records for a specific concept of the research question.\nThere are filters for specific patient groups or diseases, outcomes, study types (for instance to retrieve only randomized controlled trials (RCTs), or filters for other aspects of the research question, e.g. adverse effects, diagnostic accuracy or patient values. (Waffenschmidt et al. (2020), Salvador-Oliván, Marco-Cuenca, and Arquero-Avilés (2021), Lee et al. (2012), Golder et al. (2006))\nValidated filters are developed, tested and optimized for sensitivity and precision by experts. (Haynes and Wilczynski (2004), Glanville et al. (2008))\nFilter strategies can be implemented in a search strategy just like any concept of the research question. Table 4.2 illustrates a search strategy with a short qualitative research filter in lines 8 to 11, which is added to the overall search in line 12. (see also Section 4.10).\n\n\n\nTable 4.2\n\n\n1   hypertension/\n2   (hypertension or high blood pressure).ti,ab.\n3   1 or 2\n4   exp patient attitude/\n5   *patient satisfaction/\n6   (choice$ or empower$).ti.\n7   or/4-6\n8   interview$.mp.\n9   experience$.mp.\n10  qualitative.tw.\n11  or/8-10\n12  3 and 7 and 11\n\n\n\n\n\n\n\n\n\nSources of filter strategies\n\n\n\n\n\n\nISSG Search Filter Resource\nCanadian Agency for Drugs and Technologies in Health (CADTH)\nSIGN Health Improvement Scotland\nMcMaster University\nCochrane\nOvid (Wolters Kluwer)\nPubMed Clinical Queries",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-fieldcode",
    "href": "methods.html#sec-fieldcode",
    "title": "4  Methods",
    "section": "4.4 field code",
    "text": "4.4 field code\nThe data fields of databases possess short designations called field codes, field tags or field labels, which allow to search the fields separately as part of a search query or search strategy (see Section 4.10). Depending on the syntax of the database or search interface different field codes are available for searching. If no field code is used in a search query, the search term is usually searched in all fields or a preset variety of fields.\n\n\n\n\n\n\nExample\n\n\n\nIn PubMed the query hypnosis[TIAB] will basically search for records with “hypnosis” in the title or abstract. In Ovid the same search would be written as hypnosis.ti,ab.\n\n\nSee also https://pubmed.gov/help/#search-tags and https://ospguides.ovid.com/OSPguides/medline.htm#search.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#focus",
    "href": "methods.html#focus",
    "title": "4  Methods",
    "section": "4.5 focus",
    "text": "4.5 focus\nFocus topics (also called major topics) are weighted index terms. If a particular topic is at the heart of a publication, index terms for that topic will be assigned as a so-called focus topic. This is often displayed in the databases by writing an asterisk before or after the index term.\n\n\n\n\n\n\nRisk of confusion\n\n\n\nThe asterisk * appears also as a wildcard character for truncation. The two look the same, but have different meanings and uses. Don’t let them confound you.\n\n\nBy labeling an index term this way, its significance for the publication is visualized. Moreover, searching for the focus topic instead of the index term allows for a search to be focused only on the most important papers for a particular topic.\n\n\n\n\n\n\nExample\n\n\n\n\nA systematic review on hypertension will most likely feature the focus topic *hypertension, whereas an artikle about vascular diseases might be indexed with hypertension as a normal subject heading. Searching for hypertension[majr] in PubMed or *hypertension/ in Ovid would yield only the first of those two articles. A search for hypertension[mh] hypertension/ would find both of them.\nThe article Apnoeic oxygenation during paediatric tracheal intubation by Fuchs et al. (2024) is indexed with Intubation, Intratracheal* / adverse effects and Intubation, Intratracheal* / methods as major topics, whereas Hypoxia / etiology was added as a regular MeSH term as it is not the main focus of the article.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-frequencyops",
    "href": "methods.html#sec-frequencyops",
    "title": "4  Methods",
    "section": "4.6 frequency operators",
    "text": "4.6 frequency operators\nRecords in which a relevant expression occurs multiple times might be more relevant than records with fewer instances of the same expression. Therefore some search interfaces allow the use of a so-called frequency operator, which only retrieves records only if the search term occurs at least the specified number of times in the searched data field.\n\n\n\n\n\n\nExample\n\n\n\nExample from Ovid: The query \"pharmacy\".ab/freq=5 will retrieve articles, in which the term pharmacy occurs at least five times within the abstract.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-limits",
    "href": "methods.html#sec-limits",
    "title": "4  Methods",
    "section": "4.7 limits",
    "text": "4.7 limits\nThere are various means to restrict the results of a search. One of them are so-called limits which are filter options provided by the search interface, which allow the search results to be limited to characteristics such as publication type, language or year of publication.\n\n\n\n\n\n\nWarning\n\n\n\n\nDatabase limits are not to be mistaken for validated filter strategies. Limits are usually based on certain data fields, whereas validated search filters are more complex search strategies. See also Section 4.3.\nDatabase limits based on index terms may lead to the unintended exclusion of non-indexed records.\nThe usage of database limits is not always evident from the search history. If it is not possible to display applied limits in the search history, its use should be reported in the documentation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-nesting",
    "href": "methods.html#sec-nesting",
    "title": "4  Methods",
    "section": "4.8 nesting",
    "text": "4.8 nesting\nNesting refers to the use of parentheses ( ) to group search terms within a query. The purpose of nesting a search query is to define the order in which the search terms and operators processed. The properties of the operators in combination with parentheses are displayed in Table 4.1.\nWithout nesting the order in which the elements of a search query are processed depends on the rules of the respective search interface. This means that the same query might produce very different results in the individual databases.\n\n\n\n\n\n\nExamples\n\n\n\n\nWithin PubMed all searches are processed in a left-to-right sequence.\n\nThus the following PubMed queries yield completely different results:\n\nexercise[MH] AND infection[MH] OR heart[MH]\nexercise[MH] AND heart[MH] OR infection[MH]\nheart[MH] OR infection[MH] AND exercise[MH]\n\nOn the other hand the following nested queries are identical:\n\nexercise[MH] AND (infection[MH] OR heart[MH])\nexercise[MH] AND (heart[MH] OR infection[MH])\n(heart[MH] OR infection[MH]) AND exercise[MH]\n\n\nWeb of Science executes the search in an order of precedence of the operators.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-phrases",
    "href": "methods.html#sec-phrases",
    "title": "4  Methods",
    "section": "4.9 phrases",
    "text": "4.9 phrases\nMost databases can be searched for verbatim expressions, called phrases or literal strings, by putting search terms in quotation marks \" \".\n\n\n\n\n\n\nEffects\n\n\n\nThe use of phrases usually terminates any automatically applied techniques, such as lemmatization, stemming or automated term mapping (ATM) for those expressions. In this way, the use of phrases usually reduces the amount of search results as it makes the search more precise and less sensitive.\nExample:\nDue to automated term mapping the PubMed query heart arrest will be translated to\n\"heart arrest\"[MeSH Terms] OR \"heart\"[All Fields] AND \"arrest\"[All Fields] OR \"heart arrest\"[All Fields]\nHowever, the query \"heart arrest\" translates to \"heart arrest\"[All Fields], because phrases are not automatically mapped in PubMed.\n\n\n\n\n\n\n\n\nPhrases and Truncation\n\n\n\nIn some cases the simultaneous use of phrases and truncation is not supported by the search interface.\nSearching for \"hearing aid*\" in the Cochrane Library will prompt an error message suggesting the use of the NEXT operator to work around the problem. In other words, the search query should be hearing NEXT aid* instead.\n\n\n\n\n\n\n\n\nRequired quotation marks\n\n\n\nPhrases are absolutely necessary when the search string contains a special character or anything the search interface would interpret as an operator or syntax. Examples for Ovid:\n\n\"go/no-go\".ti,ab. – Without the quotation marks the forward slash / would be understood as command to search the expression go as an index term.\n\"Sensitivity and Specificity\"/ – and is also an operator and must be escaped using the quotation marks.\n\"5\".ip – This search retrieves all records with the number 5 in the Issue/Part field. Without the quotation marks, the query would search for the contents of line 5 in the field .ip. (That procedure is called postqualification of search sets).\n\n\n\n\n\n\n\n\n\nStraight quotes vs. curly quotes\n\n\n\nThere are several types of quotation marks. Search interfaces often only understand so-called straight quotes \" \" (the ones that have been used in typewriters). Modern word processors often change straight quotes automatically into the typographically correct curly quotes “ ” (the way they are printed in books), which can cause a syntax error, if they are copied into a search query. This is a known issue in Ovid.\nOptions to counter this problem:\n\nDeactivation of the responsible autocorrection feature of the word processor.\nUsing a simpler plain text editor.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "methods.html#sec-searchstrategy",
    "href": "methods.html#sec-searchstrategy",
    "title": "4  Methods",
    "section": "4.10 search strategy",
    "text": "4.10 search strategy\nA search strategy is a coherent set of search queries designed to retrieve references for a particular topic. A search strategy is dependent on the syntax and index terms of the searched database. As a consequence, the search strategy needs to be translated for the use in other databases.\nSearch strategies are supposed to be consistent with the predefined eligibility criteria of the research project (Gough, Oliver, and Thomas (2017)).\nDepending on the purpose and detail of the search, the extent of a search strategy might range from a simple search string to numerous lines of search terms connected by boolean operators (see Section 4.1).\nTable 4.3 and Table 4.4 show examples for both types of search strategies.\n\n\n\nTable 4.3: Single-line PubMed Search strategy\n\n\n\"analgesics\"[MH] OR \"analgesic*\"[TIAB] OR \"analgesic*\"[PA] OR \"anodynes\"[TIAB] \nOR \"antinociceptive*\"[TIAB]) AND \"pain management\"[MAJR]\n\n\n\n\n\n\nTable 4.4: Multi-line search strategy for Ovid MEDLINE\n\n\n1 exp analgesics/\n2 (analge#ic? or anodyne? or antinoceptive?).ti,ab,kw.\n3 *pain management/\n4 (1 or 2) and 3\n\n\n\n\n\n\n\nBelter, Christopher W. 2016. “Citation Analysis as a Literature Search Method for Systematic Reviews.” J Assn Inf Sci Tec 67 (11): 2766–77. https://doi.org/10.1002/asi.23605.\n\n\nFuchs, Alexander, Gabriela Koepp, Markus Huber, Jonas Aebli, Arash Afshari, Rachele Bonfiglio, Robert Greif, et al. 2024. “Apnoeic Oxygenation During Paediatric Tracheal Intubation: A Systematic Review and Meta-Analysis.” Brit J Anaesth 132 (February): 392–406. https://doi.org/10.1016/j.bja.2023.10.039.\n\n\nGlanville, Julie, Sue Bayliss, Andrew Booth, Yenal Dundar, Hasina Fernandes, Nigel David Fleeman, Louise Foster, et al. 2008. “So Many Filters, so Little Time: The Development of a Search Filter Appraisal Checklist.” J Med Libr Assoc 96 (18974813): 356–61. https://doi.org/10.3163/1536-5050.96.4.011.\n\n\nGolder, Su, Heather M. McIntosh, Steve Duffy, and Julie Glanville. 2006. “Developing efficient search strategies to identify reports of adverse effects in MEDLINE and EMBASE.” Health Info Libr J 23 (March): 3–12. https://doi.org/10.1111/j.1471-1842.2006.00634.x.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews. Second. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically strong studies of diagnosis from Medline: analytical survey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nHinde, Sebastian, and Eldon Spackman. 2015. “Bidirectional Citation Searching to Completion: An Exploration of Literature Searching Methods.” PharmacoEconomics 33 (1): 5–11. https://doi.org/10.1007/s40273-014-0205-3.\n\n\nHirt, Julian, Thomas Nordhausen, Christian Appenzeller-Herzog, and Hannah Ewald. 2021. “Using citation tracking for systematic literature searching – study protocol for a scoping review of methodological studies and a Delphi study.” F1000Res 9 (September): 1386. https://doi.org/10.12688/f1000research.27337.3.\n\n\nLee, Edwin, Maureen Dobbins, Kara DeCorby, Lyndsey McRae, Daiva Tirilis, and Heather Husson. 2012. “An Optimal Search Filter for Retrieving Systematic Reviews and Meta-Analyses.” BMC Med Res Methodol 12 (1): 51. https://doi.org/10.1186/1471-2288-12-51.\n\n\nO’Regan, Gerard. 2012. A Brief History of Computing. Second. Springer, London. https://doi.org/10.1007/978-1-4471-2359-0.\n\n\nSalvador-Oliván, José Antonio, Gonzalo Marco-Cuenca, and Rosario Arquero-Avilés. 2021. “Development of an efficient search filter to retrieve systematic reviews from PubMed.” J Med Libr Assoc 109 (4). https://doi.org/10.5195/jmla.2021.1223.\n\n\nWaffenschmidt, Siw, Tamara Navarro-Ruan, Nick Hobson, Elke Hausner, Stefan Sauerland, and R. Brian Haynes. 2020. “Development and validation of study filters for identifying controlled non-randomized studies in PubMed and Ovid MEDLINE.” Res Syn Meth 11 (5): 617–26. https://doi.org/10.1002/jrsm.1425.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "publicationtypes.html",
    "href": "publicationtypes.html",
    "title": "5  Publication Types",
    "section": "",
    "text": "5.1 Reviews",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Publication Types</span>"
    ]
  },
  {
    "objectID": "publicationtypes.html#sec-review",
    "href": "publicationtypes.html#sec-review",
    "title": "5  Publication Types",
    "section": "",
    "text": "Figure 5.1: What Type of Review is Right for you? - adopted from Cornell University Library (2019)\n\n\n\n\n\n\n\nCornell University Library. 2019. “What Type of Review is Right for You?” Online. https://guides.library.cornell.edu/evidence-synthesis/service.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Publication Types</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Belter, Christopher W. 2016. “Citation Analysis as a Literature\nSearch Method for Systematic Reviews.” J Assn Inf Sci\nTec 67 (11): 2766–77. https://doi.org/10.1002/asi.23605.\n\n\nBoutron, I., M. J. Page, J. P. T. Higgins, D. G. Altman, A. Lundh, and\nA. Hróbjartsson. 2022. “Chapter 7: Considering Bias and Conflicts\nof Interest Among the Included Studies.” In Cochrane Handbook\nfor Systematic Reviews of Interventions, edited by J. P. T.\nHiggins, J. Thomas, J. Chandler, M. Cumpston, T. Li, M. J. Page, and V.\nA. Welch. Cochrane.\n\n\nBraun, Cordula, Christine Schmucker, Monika Nothacker, Kai Nitschke,\nCorinna Schaefer, Claudia Bollig, Cathleen Muche-Borowski, Ina B. Kopp,\nand Jörg Meerpohl. 2021. “Manual Bewertung\ndes Biasrisikos in Interventionsstudien.”\nAlbert-Ludwigs-Universität Freiburg. https://doi.org/10.6094/UNIFR/194900.\n\n\nCals, Jochen W. L., and Daniel Kotz. 2013. “Effective writing and publishing scientific papers, part\nII: title and abstract.” J Clin Epidemiol 66 (6):\n585. https://doi.org/10.1016/j.jclinepi.2013.01.005.\n\n\nClark, Justin Michael, Sharon Sanders, Matthew Carter, David Honeyman,\nGina Cleo, Yvonne Auld, Debbie Booth, et al. 2020. “Improving the translation of search strategies using the\nPolyglot Search Translator: a randomized controlled\ntrial.” J Med Libr Assoc 108 (2): 195–207. https://doi.org/10.5195/jmla.2020.834.\n\n\nCornell University Library. 2019. “What Type\nof Review is Right for You?” Online. https://guides.library.cornell.edu/evidence-synthesis/service.\n\n\nCummings, Steven R., Warren S. Browner, and Stephen B. Hulley. 2013.\n“Conceiving the Research Question and\nDeveloping the Study Plan.” In Designing\nClinical Research, edited by Stephen B. Hulley, Steven R.\nCummings, Warren S. Browner, Deborah G. Grady, and Thomas B. Newman, 4.\ned., 14–22. Philadelphia: Lippincott Williams & Wilkins. https://swisscovery.slsp.ch/permalink/41SLSP_UBE/99pfpl/alma99117040391205511.\n\n\nDamarell, Raechel A., Jennifer J. Tieman, and Ruth M. Sladek. 2013.\n“OvidSP Medline-to-PubMed search filter\ntranslation: a methodology for extending search filter range to include\nPubMed’s unique content.” BMC Med Res Methodol 13\n(1): 86. https://doi.org/10.1186/1471-2288-13-86.\n\n\nEriksen, Mette Brandt, and Tove Faber Frandsen. 2018. “The impact of patient, intervention, comparison, outcome\n(PICO) as a search strategy tool on literature search quality: a\nsystematic review.” J Med Libr Assoc 106 (4):\n420–31. https://doi.org/10.5195/jmla.2018.345.\n\n\nFawcett, Tom. 2006. “An Introduction to ROC\nAnalysis.” Pattern Recognit Lett 27 (8): 861–74. https://doi.org/10.1016/j.patrec.2005.10.010.\n\n\nFuchs, Alexander, Gabriela Koepp, Markus Huber, Jonas Aebli, Arash\nAfshari, Rachele Bonfiglio, Robert Greif, et al. 2024. “Apnoeic\nOxygenation During Paediatric Tracheal Intubation: A Systematic Review\nand Meta-Analysis.” Brit J Anaesth 132 (February):\n392–406. https://doi.org/10.1016/j.bja.2023.10.039.\n\n\nGlanville, Julie M., Steven Duffy, Rachael McCool, and Danielle Varley.\n2014. “Searching ClinicalTrials.gov and the\nInternational Clinical Trials Registry Platform to inform systematic\nreviews: what are the optimal search approaches?” J\nMed Libr Assoc 102 (25031558): 177–83. https://doi.org/10.3163/1536-5050.102.3.007.\n\n\nGlanville, Julie, Sue Bayliss, Andrew Booth, Yenal Dundar, Hasina\nFernandes, Nigel David Fleeman, Louise Foster, et al. 2008. “So\nMany Filters, so Little Time: The Development of a Search Filter\nAppraisal Checklist.” J Med Libr Assoc 96 (18974813):\n356–61. https://doi.org/10.3163/1536-5050.96.4.011.\n\n\nGlanville, Julie, Ruth Foxlee, Susi Wisniewski, Anna Noel-Storr, Mary\nEdwards, and Gordon Dooley. 2019. “Translating the Cochrane EMBASE RCT filter from the Ovid\ninterface to Embase.com: a case study.” Health Info\nLibr J 36 (3): 264–77. https://doi.org/10.1111/hir.12269.\n\n\nGolder, Su, Heather M. McIntosh, Steve Duffy, and Julie Glanville. 2006.\n“Developing efficient search strategies to\nidentify reports of adverse effects in MEDLINE and\nEMBASE.” Health Info Libr J 23 (March): 3–12. https://doi.org/10.1111/j.1471-1842.2006.00634.x.\n\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An Introduction to Systematic Reviews.\nSecond. London: SAGE Publications.\n\n\nHaynes, R. Brian, and Nancy L. Wilczynski. 2004. “Optimal search strategies for retrieving scientifically\nstrong studies of diagnosis from Medline: analytical\nsurvey.” BMJ 328 (7447): 1040. https://doi.org/10.1136/bmj.38068.557998.EE.\n\n\nHinde, Sebastian, and Eldon Spackman. 2015. “Bidirectional Citation Searching to Completion: An\nExploration of Literature Searching Methods.”\nPharmacoEconomics 33 (1): 5–11. https://doi.org/10.1007/s40273-014-0205-3.\n\n\nHirt, Julian, Thomas Nordhausen, Christian Appenzeller-Herzog, and\nHannah Ewald. 2021. “Using citation tracking\nfor systematic literature searching – study protocol for a scoping\nreview of methodological studies and a Delphi study.”\nF1000Res 9 (September): 1386. https://doi.org/10.12688/f1000research.27337.3.\n\n\nKnelangen, Marco, Elke Hausner, Maria-Inti Metzendorf, Sibylle Sturtz,\nand Siw Waffenschmidt. 2018. “Trial Registry Searches for\nRandomized Controlled Trials of New Drugs Required Registry-Specific\nAdaptation to Achieve Adequate Sensitivity.” J Clin\nEpidemiol 94: 69–75. https://doi.org/10.1016/j.jclinepi.2017.11.003.\n\n\nLee, Edwin, Maureen Dobbins, Kara DeCorby, Lyndsey McRae, Daiva Tirilis,\nand Heather Husson. 2012. “An Optimal Search Filter for Retrieving\nSystematic Reviews and Meta-Analyses.” BMC Med Res\nMethodol 12 (1): 51. https://doi.org/10.1186/1471-2288-12-51.\n\n\nLefebvre, Carol, Julie Glanville, Sophie Beale, Charles Boachie, Steven\nDuffy, Cynthia Fraser, Jenny Harbour, Rachael McCool, and Lynne Smith.\n2017. “Assessing the Performance of Methodological Search Filters\nto Improve the Efficiency of Evidence Information Retrieval: Five\nLiterature Reviews and a Qualitative Study.” Health Technol\nAssess 21 (69): 1–148. https://doi.org/10.3310/hta21690.\n\n\nMcGowan, Jessie, Margaret Sampson, Douglas M. Salzwedel, Elise Cogo,\nVicki Foerster, and Carol Lefebvre. 2016. “PRESS Peer Review of Electronic Search Strategies: 2015\nGuideline Statement.” J Clin Epidemiol 75: 40–46.\nhttps://doi.org/10.1016/j.jclinepi.2016.01.021.\n\n\nMethley, Abigail M., Stephen Campbell, Carolyn Chew-Graham, Rosalind\nMcNally, and Sudeh Cheraghi-Sohi. 2014. “PICO, PICOS and SPIDER: a comparison study of specificity\nand sensitivity in three search tools for qualitative systematic\nreviews.” BMC Health Serv Res 14 (1): 579. https://doi.org/10.1186/s12913-014-0579-0.\n\n\nMoher, D., B. Pham, M. L. Lawson, and T. P. Klassen. 2003. “The inclusion of reports of randomised trials published\nin languages other than English in systematic reviews.”\nHealth Technol Assess 7: 1–90. https://doi.org/10.3310/hta7410.\n\n\nMorrison, Andra, Julie Polisena, Don Husereau, Kristen Moulton, Michelle\nClark, Michelle Fiander, Monika Mierzwinski-Urban, et al. 2012.\n“The effect of English-language restriction\non systematic review-based meta-analyses: a systematic review of\nempirical studies.” Int J Technol Assess Health\nCare 28 (2): 138–44. https://doi.org/10.1017/S0266462312000086.\n\n\nMunn, Z., C. Stern, E. Aromataris, C. Lockwood, and Z. Jordan. 2018.\n“What kind of systematic review should I\nconduct? A proposed typology and guidance for systematic reviewers in\nthe medical and health sciences.” Journal Article. BMC\nMed Res Methodol 18 (1): 5. https://doi.org/10.1186/s12874-017-0468-4.\n\n\nNévéol, Aurélie, Rezarta Islamaj Doğan, and Zhiyong Lu. 2010.\n“Author Keywords in Biomedical Journal\nArticles.” AMIA Annu Symp Proc 2010 (November):\n537–41. https://pubmed.ncbi.nlm.nih.gov/21347036/.\n\n\nO’Regan, Gerard. 2012. A Brief History of\nComputing. Second. Springer, London. https://doi.org/10.1007/978-1-4471-2359-0.\n\n\nOdgaard‐Jensen, Jan, Gunn E. Vist, Antje Timmer, R. Kunz, Elie A. Akl,\nHolger Schünemann, Matthias Briel, Alain J. Nordmann, Silvia Pregno, and\nAndrew D. Oxman. 2011. “Randomisation to Protect Against Selection\nBias in Healthcare Trials.” Cochrane Database Syst Rev  \n(4). https://doi.org/10.1002/14651858.MR000012.pub3.\n\n\nPage, Matthew J., Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle\nBoutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al.\n2021. “The PRISMA 2020 statement: an updated\nguideline for reporting systematic reviews.” BMJ\n372. https://doi.org/10.1136/bmj.n71.\n\n\nPage, Matthew J., David Moher, Patrick M. Bossuyt, Isabelle Boutron,\nTammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021.\n“PRISMA 2020 explanation and elaboration:\nupdated guidance and exemplars for reporting systematic\nreviews.” BMJ 372. https://doi.org/10.1136/bmj.n160.\n\n\nPitkin, Roy M., and Mary Ann Branagan. 1998. “Can the Accuracy of Abstracts Be Improved by Providing\nSpecific Instructions? A Randomized Controlled Trial.”\nJAMA 280 (3): 267–69. https://doi.org/10.1001/jama.280.3.267.\n\n\nRethlefsen, Melissa L., Shona Kirtley, Siw Waffenschmidt, Ana Patricia\nAyala, David Moher, Matthew J. Page, Jonathan B. Koffel, et al. 2021.\n“PRISMA-S: an extension to the PRISMA\nStatement for Reporting Literature Searches in Systematic\nReviews.” Syst Rev 10 (1): 39. https://doi.org/10.1186/s13643-020-01542-z.\n\n\nRethlefsen, Melissa, and Matthew J. Page. 2021. “PRISMA 2020 and PRISMA-S: Common Questions on Tracking\nRecords and the Flow Diagram.” MetaArXiv. https://doi.org/10.31222/osf.io/439ju.\n\n\nSalvador-Oliván, José Antonio, Gonzalo Marco-Cuenca, and Rosario\nArquero-Avilés. 2021. “Development of an\nefficient search filter to retrieve systematic reviews from\nPubMed.” J Med Libr Assoc 109 (4). https://doi.org/10.5195/jmla.2021.1223.\n\n\nTricco, A. C., E. Lillie, W. Zarin, K. K. O’Brien, H. Colquhoun, D.\nLevac, D. Moher, et al. 2018. “PRISMA\nExtension for Scoping Reviews (PRISMA-ScR): Checklist and\nExplanation.” Journal Article. Ann Intern Med 169\n(7): 467–73. https://doi.org/10.7326/M18-0850.\n\n\nWaffenschmidt, Siw, Tamara Navarro-Ruan, Nick Hobson, Elke Hausner,\nStefan Sauerland, and R. Brian Haynes. 2020. “Development and validation of study filters for\nidentifying controlled non-randomized studies in PubMed and Ovid\nMEDLINE.” Res Syn Meth 11 (5): 617–26. https://doi.org/10.1002/jrsm.1425.\n\n\nWanner, Amanda, and Niki Baumann. 2019. “Design and implementation of a tool for conversion of\nsearch strategies between PubMed and Ovid MEDLINE.”\nRes Syn Meth 10 (2): 154–60. https://doi.org/10.1002/jrsm.1314.",
    "crumbs": [
      "References"
    ]
  }
]